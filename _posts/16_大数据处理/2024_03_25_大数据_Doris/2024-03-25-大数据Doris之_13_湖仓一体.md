---
title: 大数据Doris之_13_湖仓一体
date: 2025-03-25 00:00:00
tags: 
- BigData
- Doris
category: 
- BigData
- Doris
description: 大数据Doris之_13_湖仓一体
---

**前言**     

 Github：[https://github.com/HealerJean](https://github.com/HealerJean)         

 博客：[http://blog.healerjean.com](http://HealerJean.github.io)          



# 一、湖仓一体概念与 `Doris` 的定位



## 1、 传统数据架构痛点

- **数据湖：** **通常指存储海量原始数据的集中式存储系统**（如 `AWS` `S3`、`MinIO`、阿里云 `OSS` 等），数据湖中的数据可能结构各异（结构化、半结构化、非结构化）。

- **数据孤岛**：数据分散在数据湖（如 `S3`、`HDFS`）和数据仓库（如 `Doris`、`ClickHouse`）中，需重复 `ETL` （全称为 **`Extract`（抽取）、`Transform`（转换）、`Load`（加载）**）
- **处理链路复杂**：数据湖用于存储，数仓用于分析，需维护两套系统
- **成本高**：存储和计算资源无法弹性共享



## 2、湖仓一体核心理念

- **统一存储**：数据只需存储一份，同时支持事务性写入和分析型查询
- **统一元数据**：湖和仓使用同一套元数据管理，避免数据冗余和不一致
- **统一计算引擎**：提供统一的 `SQL` 接口，屏蔽底层存储差异





## 3、`Doris` 湖仓一体的优势

- **高性能**：基于向量化执行引擎和 `Morsel-Driven` 并行计算，单表查询性能优于 `Spark SQL`
- **低延迟**：支持实时数据摄入和亚秒级查询响应
- **易集成**：无缝对接 `Hive`、`Iceberg`、`Hudi` 等数据湖格式
- **弹性扩展**：计算和存储分离架构，支持资源弹性伸缩





## 4、数据湖联邦查询

> 数据湖联邦查询：是数据管理与分析领域的重要概念，其核心在于解决数据湖环境下的跨源数据查询难题。以下从定义、核心价值、技术实现及典型场景等方面展开说明：    
>
> > 数据湖联邦查询的本质是 “让数据不动，计算动”，通过统一引擎打破数据孤岛，实现跨源数据的实时分析。在企业数字化转型中，这一能力可大幅提升数据利用率，降低数据整合成本



### 1）定义：打破数据孤岛的跨源查询能力

> 数据湖联邦查询指通过一套统一的查询引擎，对分布在不同存储系统（如对象存储、`HDFS`、数据库、数据湖等）中的数据进行**跨源、无缝的联合查询**，而无需将数据进行物理迁移或复制。



**联邦**：强调 “**分布式、多源整合**”，类似联邦政府对各州的统一管理，不同数据源保持独立存储，但可被统一访问。

**数据湖：** **通常指存储海量原始数据的集中式存储系统**（如 `AWS` `S3`、`MinIO`、阿里云 `OSS` 等），数据湖中的数据可能结构各异（结构化、半结构化、非结构化）。



### 2）核心价值：解决数据湖场景的三大痛点

| 痛点                         | 传统方案的局限                                               | 联邦查询的解决方案                                           |
| ---------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **数据分散，无法统一分析**   | 数据存储在对象存储、`Hive`、`MySQL` 等多处，需手动同步数据，耗时耗资源。 | 过统一 `SQL` 接口直接查询多源数据，如同时查询 `S3` 中的日志文件和 `MySQL` 中的业务数据。 |
| **数据格式复杂，查询困难**   | 非结构化数据（如 `JSON`、日志）需先清洗转换为结构化格式才能分析。 | 支持直接解析多种格式数据（如 Parquet、ORC、JSON、CSV 等），无需预处理。 |
| **计算与存储耦合，资源浪费** | 数据迁移至计算引擎本地存储，占用大量存储资源，且无法复用原始数据。 | 计算与存储分离，查询时仅读取所需数据，减少存储成本和数据冗余 |





# 二、`Doris` 湖仓一体技术架构

## 1、整体架构

```plaintext
┌───────────────────────────────────────────────────────────┐
│                      用户接口层                             │
│  (SQL Client / ODBC / JDBC / REST API / BI Tools)          │
├───────────────────────────────────────────────────────────┤
│                     查询引擎层                              │
│  (Parser → Planner → Optimizer → Vectorized Execution)     │
├───────────────────────────────────────────────────────────┤
│                     存储引擎层                              │
│  ┌───────────────┐  ┌───────────────────────────────────┐  │
│  │  本地存储引擎   │  │         外部存储连接器            │  │
│  │ (RowSet / Columnar) │  │ (HDFS / S3 / Iceberg / Hudi / Parquet) │  │
│  └───────────────┘  └───────────────────────────────────┘  │
└───────────────────────────────────────────────────────────┘
```



## 2、核心组件

- **`FE` (`Frontend`)**：负责 `SQL` 解析、查询规划、元数据管理
- **`BE` (`Backend`)**：负责数据存储、查询执行和计算
- **`Broker`**：外部存储连接器，支持 `HDFS`、`S3` 等
- **`MetaService`**：统一元数据管理，支持湖仓元数据互通



## 3、技术实现：联邦查询的核心组件与流程

### 1）**关键技术组件**

- **统一查询引擎**：如 `Apache` `Doris`、`Trino`（`PrestoSQL`）、`Spark` `SQL `等，提供标准化 `SQL` 接口。
- **数据源连接器（`Connector`）**：适配不同存储系统的驱动（如 `S3` `Connector`、`Hive` `Connector`、`JDBC` `Connector` 等）。
- **查询优化器**：自动规划跨源查询路径，减少数据传输量（如推下过滤条件到数据源执行）。



### 2）查询流程示例

```plaintext
用户提交SQL查询 → 引擎解析SQL → 通过Connector访问不同数据源 → 优化器规划执行计划（如并行查询S3和Hive）→ 结果合并返回
```





# 三、`Doris` 湖仓一体核心特性

## 1、外部表功能

> `Doris` 支持创建指向外部数据湖的 "外部表"，无需导入数据即可直接查询：

```sql
-- 创建指向 Hive 表的外部表
CREATE EXTERNAL TABLE hive_table (
    id INT,
    name STRING,
    age INT
)
ENGINE=hive
PROPERTIES (
    "hive.metastore.uris" = "thrift://hive-metastore:9083",
    "database" = "default",
    "table" = "user_table"
);

-- 直接查询外部表
SELECT * FROM hive_table WHERE age > 18;
```



## 2、数据湖格式支持

`Doris` 支持多种数据湖格式：

- **`Parquet`**：默认列式存储格式，支持谓词下推
- **`ORC`**：高性能列式存储格式
- **`Iceberg`**：支持 ACID 事务和时间旅行查询
- **`Hudi`**：支持增量数据处理和数据湖索引



## 3、统一 `SQL` 接口

用户可以通过同一套 `SQL` 语法查询 `Doris`  内部表和外部湖表，无需关心数据存储位置：

```sql
-- 关联查询内部表和外部表
SELECT t1.id, t1.name, t2.order_amount
FROM internal_table t1
JOIN hive_table t2 ON t1.id = t2.user_id;
```



## 4、数据导入与导出

- **`Broker` `Load`**：从 `HDFS/S3` 批量导入数据
- **`Stream Load`：**实时数据流导入（如 `Kafka`、`Pulsar`）
- **`INSERT INTO`**：支持从外部表导入数据到 Doris 内部表



## 5、混合分析能力

> 支持在同一查询中同时处理热数据（`Doris` 本地存储）和冷数据（外部存储）：

```sql
-- 冷热数据混合查询
SELECT *
FROM hot_data_table  -- 热数据存储在 Doris
UNION ALL
SELECT *
FROM cold_data_external_table;  -- 冷数据存储在 S3
```



## 6、`Doris` 湖仓一体应用场景

### 1） 企业级数据仓库

- **场景**：整合企业内部分散在不同系统的数据
- **优势**：统一查询接口，减少 `ETL` 复杂度



### 2）实时数据分析

- **场景**：结合 `Kafka` 实时摄入数据，实时分析
- **优势**：支持高并发、低延迟查询



### 3）历史数据分析

- **场景**：分析历史归档数据（如年 / 季度报表）
- **优势**：直接查询外部存储，无需导入



### 4）多源数据关联分析

- **场景**：关联分析 `Hive`、`Iceberg` 等不同数据源的数据
- **优势**：统一 `SQL` 接口，简化开发





































![ContactAuthor](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/assets/img/artical_bottom.jpg)



<!-- Gitalk 评论 start  -->

<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">

<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script> 
<div id="gitalk-container"></div>    
 <script type="text/javascript">
    var gitalk = new Gitalk({
		clientID: `1d164cd85549874d0e3a`,
		clientSecret: `527c3d223d1e6608953e835b547061037d140355`,
		repo: `HealerJean.github.io`,
		owner: 'HealerJean',
		admin: ['HealerJean'],
		id: 'U8HO0M49wF7L2zxA',
    });
    gitalk.render('gitalk-container');
</script> 





<!-- Gitalk end -->




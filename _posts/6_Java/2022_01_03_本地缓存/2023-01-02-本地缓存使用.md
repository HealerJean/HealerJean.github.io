---
title: 本地缓存使用
date: 2023-01-02 00:00:00
tags: 
- Java
category: 
- Java
description: 本地缓存
---

**前言**     

 Github：[https://github.com/HealerJean](https://github.com/HealerJean)         

 博客：[http://blog.healerjean.com](http://HealerJean.github.io)          

# 一、`JVM` 缓存

## 1、简单本地缓存

```java
@Slf4j
@Service
public class BypassTaskCacheImpl implements BypassTaskCacheService {

    /**
     * key 为版本号，value为旁路配置
     */
    private Map<String, BypassTaskConfigDto> bypassTaskMap;

    /**
     * 实时旁路 realtimeBypass
     */
    private List<BypassTaskConfigDto> realtimeBypassList;

    /**
     * 历史旁路 historyBypass
     */
    private List<BypassTaskConfigDto> historyBypassList;

    /**
     * bypassTaskMapper
     */
    @Resource
    private BypassTaskMapper bypassTaskMapper;

    /**
     * umpAlarmService
     */
    @Resource
    private UmpAlarmService umpAlarmService;

    /**
     * 启动就加载
     */
    @PostConstruct
    public void init() {
        try {
            log.info("[BypassTaskSwitchCache#init]：start");
            BypassTaskQuery taskQuery = new BypassTaskQuery();
            taskQuery.setType(BypassEnum.BypassTypeEnum.REALTIME.getCode());
            taskQuery.setTaskStatus(BypassEnum.BypassTaskStatusEnum.EXECUTING.getCode());
            taskQuery.setStatus(StatusEnum.VALID.getCode());
            Map<String, BypassTaskConfigDto> newMap = new HashMap<>(8);
            List<BypassTask> dbRealtimeBypassTasks = bypassTaskMapper.selectByExample(taskQuery);
            List<BypassTaskConfigDto> newRealtimeBypassList = new ArrayList<>();
            if (!CollectionUtils.isEmpty(dbRealtimeBypassTasks)) {
                for (BypassTask bypassTask : dbRealtimeBypassTasks) {
                    BypassTaskConfigDto bypassTaskConfigDto = BeanUtils.bypassTaskToConfigDto(bypassTask);
                    newRealtimeBypassList.add(bypassTaskConfigDto);
                    newMap.put(bypassTask.getVersion(), bypassTaskConfigDto);
                }
            }

            taskQuery = new BypassTaskQuery();
            taskQuery.setType(BypassEnum.BypassTypeEnum.HISTORY.getCode());
            taskQuery.setTaskStatusList(Arrays.asList(BypassEnum.BypassTaskStatusEnum.CREATED.getCode(), BypassEnum.BypassTaskStatusEnum.EXECUTING.getCode()));
            taskQuery.setStatus(StatusEnum.VALID.getCode());
            List<BypassTask> dbHistoryBypassTasks = bypassTaskMapper.selectByExample(taskQuery);
            List<BypassTaskConfigDto> newHistoryBypassList = new ArrayList<>();
            if (!CollectionUtils.isEmpty(dbHistoryBypassTasks)) {
                for (BypassTask bypassTask : dbHistoryBypassTasks) {
                    BypassTaskConfigDto bypassTaskConfigDto = BeanUtils.bypassTaskToConfigDto(bypassTask);
                    newHistoryBypassList.add(bypassTaskConfigDto);
                    newMap.put(bypassTask.getVersion(), bypassTaskConfigDto);
                }
            }

            bypassTaskMap = newMap;
            realtimeBypassList = newRealtimeBypassList;
            historyBypassList = newHistoryBypassList;
            log.info("[BypassTaskSwitchCache#init]：end");

        } catch (Exception e) {
            log.error("[BypassTaskSwitchCache#init] error", e);
            umpAlarmService.businessAlarm("旁路[BypassTaskSwitchCache] 失败，请关注");
        }
    }

    /**
     * 任务执行( 1分钟执行 1次)
     */
    @Scheduled(cron = "0 0/1 * * * ?")
    public void refresh() {
        log.info("[BypassTaskSwitchCache#refresh]：start");
        init();
        log.info("[BypassTaskSwitchCache#refresh]：end");
    }


    /**
     * getBypassTaskMap
     *
     * @return bypassTaskMap
     */
    @Override
    public Map<String, BypassTaskConfigDto> getBypassTaskMap() {
        return bypassTaskMap;
    }

    /**
     * getRealtimeBypassList
     *
     * @return realtimeBypassList
     */
    @Override
    public List<BypassTaskConfigDto> getRealtimeBypassList() {
        return realtimeBypassList;
    }

    /**
     * getHistoryBypassList
     *
     * @return historyBypassList
     */
    @Override
    public List<BypassTaskConfigDto> getHistoryBypassList() {
        return historyBypassList;
    }

    /**
     * getBypassTaskByVersion
     *
     * @param version version
     * @return BypassTaskConfigDto
     */
    @Override
    public BypassTaskConfigDto getBypassTaskByVersion(String version) {
        Map<String, BypassTaskConfigDto> bypassTaskMap = getBypassTaskMap();
        if (CollectionUtils.isEmpty(bypassTaskMap)) {
            return null;
        }
        return bypassTaskMap.get(version);
    }

    /**
     * 险种获取开关状态
     * 1、判断开关状态
     * 2、判断险种是否存在
     *
     * @param version       旁路版本
     * @param insuranceId   险种Id
     * @param insuranceType 子险种Id
     * @return
     */
    @Override
    public boolean getSwitch(String version, String insuranceId, String insuranceType) {
        BypassTaskConfigDto bypassTaskByVersion = getBypassTaskByVersion(version);
        if (Objects.isNull(bypassTaskByVersion)) {
            return false;
        }
        List<BypassInsuranceDto> insurances = bypassTaskByVersion.getInsurances();
        return insurances.stream().anyMatch(item -> {
            if (StringUtils.isNotBlank(item.getInsuranceType())){
                return item.getInsuranceId().equals(insuranceId) && item.getInsuranceType().equals(insuranceType);
            }
            return item.getInsuranceId().equals(insuranceId);
        });
    }


    /**
     * 获取旁路数据
     * @param version  版本号
     * @param insuranceId 险种Id
     * @param insuranceType 子险种Id
     * @return
     */
    @Override
    public MerchantBypassDto getMerchantBypassDto(String version, String insuranceId, String insuranceType) {
        BypassTaskConfigDto bypassTaskByVersion = getBypassTaskByVersion(version);
        if (Objects.isNull(bypassTaskByVersion)) {
            return null;
        }
        List<BypassInsuranceDto> insurances = bypassTaskByVersion.getInsurances();
        boolean switchFlag = insurances.stream().anyMatch(item -> {
            if (StringUtils.isNotBlank(item.getInsuranceType())) {
                return item.getInsuranceId().equals(insuranceId) && item.getInsuranceType().equals(insuranceType);
            }
            return item.getInsuranceId().equals(insuranceId);
        });
        if (Boolean.FALSE.equals(switchFlag)) {
            return null;
        }
        MerchantBypassDto merchantBypassDto = new MerchantBypassDto();
        merchantBypassDto.setVersion(bypassTaskByVersion.getVersion());
        merchantBypassDto.setBypassTaskBusinessConfigDto(bypassTaskByVersion.getBypassTaskBusinessConfig());
        return merchantBypassDto;
    }

}
```



## 1、`HashMap`

### 1）`LRUCache`

```java

import java.util.LinkedHashMap;
import java.util.Map;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

/**
 * LRUCache
 * 优点：简单粗暴，不需要引入第三方包，比较适合一些比较简单的场景。
 * 缺点：没有缓存淘汰策略，定制化开发成本高。
 *
 * @author zhangyujin
 * @date 2023/1/3  13:54.
 */

public class LRUCache<K, V> extends LinkedHashMap<K, V> {

    /**
     * 可重入读写锁，保证并发读写安全性
     */
    private final ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock();
    /**
     * readLock
     */
    private final Lock readLock = readWriteLock.readLock();
    /**
     * writeLock
     */
    private final Lock writeLock = readWriteLock.writeLock();

    /**
     * 缓存大小限制
     */
    private final int maxSize;

    public LRUCache(int maxSize) {
        super(maxSize + 1, 1.0f, true);
        this.maxSize = maxSize;
    }

    /**
     * @param key key
     * @return Object
     */
    @Override
    public V get(Object key) {
        readLock.lock();
        try {
            return super.get(key);
        } finally {
            readLock.unlock();
        }
    }

    /**
     * put
     *
     * @param key   key
     * @param value value
     * @return Object
     */
    @Override
    public V put(K key, V value) {
        writeLock.lock();
        try {
            return super.put(key, value);
        } finally {
            writeLock.unlock();
        }
    }

    /**
     * removeEldestEntry
     *
     * @param eldest eldest
     * @return boolean
     */
    @Override
    protected boolean removeEldestEntry(Map.Entry eldest) {
        return this.size() > maxSize;
    }
}
```





# 二、`GuavaCache`

## 1、`GuavaCache-定时刷新`

> 本方式适用于，缓存不经常变化，切已知要缓存的数据的情况（缓存不过期，通过定时进行刷新）

### 1）、`AbstractLocalCacheManager`

```java
@Slf4j
@EnableScheduling
public abstract class AbstractLocalCacheManager<K, V> implements LocalCacheManage<K, V> {


    /**
     * IGNORE_kEY
     */
    private Set<K> ignoreKey;

    /**
     * AbstractLocalCacheManager
     */
    public AbstractLocalCacheManager() {
    }

    /**
     * AbstractLocalCacheManager
     *
     * @param ignoreKey ignoreKey
     */
    public AbstractLocalCacheManager(Set<K> ignoreKey) {
        this.ignoreKey = ignoreKey;
    }


    /**
     * 缓存容器
     */
    private final Cache<String, V> localCache = CacheBuilder.newBuilder()
            .maximumSize(200000)
            .recordStats()
            .build();


    /**
     * 初始化数据
     */
    @PostConstruct
    public void init() {
        refreshAll();
    }


    /**
     * 获取全部缓存信息
     *
     * @return Map<String, V>
     */
    @Override
    public Map<String, V> getAllLocalCache() {
        ConcurrentMap<String, V> concurrentMap = localCache.asMap();
        if (CollectionUtils.isEmpty(concurrentMap)) {
            refreshAll();
        }
        return localCache.asMap();
    }


    /**
     * 获取多个Keys结果
     *
     * @param keys keys
     * @return Map<K, V>
     */
    @Override
    public Map<K, V> getLocalCache(Set<K> keys) {
        if (CollectionUtils.isEmpty(keys)) {
            return Collections.emptyMap();
        }
        if (!CollectionUtils.isEmpty(ignoreKey)) {
            keys.removeAll(ignoreKey);
        }
        if (CollectionUtils.isEmpty(keys)) {
            return Collections.emptyMap();
        }

        // 转成本地key
        Map<String, K> localKeyMap = keys.stream().collect(Collectors.toMap(this::toLocalKey, k -> k));
        // 先获取本地结果
        Map<String, V> localResultMap = localCache.getAllPresent(localKeyMap.keySet());
        // 获取除本地缓存之外的其余信息
        Map<K, V> loadResultMap = Collections.emptyMap();
        if (localKeyMap.size() > localResultMap.size()) {
            Set<String> absentLocalKeys = Sets.difference(localKeyMap.keySet(), localResultMap.keySet());
            Set<K> absentKeys = absentLocalKeys.stream().map(localKeyMap::get).collect(Collectors.toSet());
            // 存在失效的key
            if (!absentKeys.isEmpty()) {
                loadResultMap = refresh(absentKeys);
            }
        }
        // 合并结果
        Map<K, V> retMap = new HashMap<>(loadResultMap);
        localResultMap.forEach((localKey, v) -> {
            K k = localKeyMap.get(localKey);
            retMap.put(k, v);
        });
        return retMap;
    }

    /**
     * 获取单个Key
     *
     * @param k k
     * @return V
     */
    public V getLocalCache(K k) {
        if (k == null) {
            return null;
        }
        if (!CollectionUtils.isEmpty(ignoreKey) && ignoreKey.contains(k)) {
            return null;
        }
        String localKey = toLocalKey(k);
        V ret = localCache.getIfPresent(localKey);
        if (ret == null) {
            return refresh(k);
        }
        return ret;
    }

    /**
     * 重新加载Key,会对历史缓存进行清理
     *
     * @param key key
     * @return @return
     */
    public V refresh(K key) {
        try {
            V v = load(key);
            localCache.invalidate(key);
            if (v != null) {
                writeCache(key, v);
            }
            return v;
        } catch (Exception ex) {
            String errorMsg = MessageFormatter.format("加载:{}.loadKey({})到内存-异常:", new Object[]{this.getClass().getSimpleName(), key}).getMessage();
            log.error(errorMsg, ex);
            throw new RuntimeException(errorMsg);
        }
    }

    /**
     * 重新加载多个Key,会对历史缓存进行清理
     *
     * @param keys keys
     * @return Map<K, V>
     */
    public Map<K, V> refresh(Set<K> keys) {
        try {
            Map<K, V> map = load(keys);
            localCache.invalidateAll(keys);
            if (!CollectionUtils.isEmpty(map)) {
                map.forEach(this::writeCache);
            }
            return map;
        } catch (Exception ex) {
            String errorMsg = MessageFormatter.format("加载:{}.loadKeys({})到内存-异常:", new Object[]{this.getClass().getSimpleName(), JsonUtils.toJsonString(keys)}).getMessage();
            log.error(errorMsg, ex);
            throw new RuntimeException(errorMsg);
        }

    }

    /**
     * 刷新所有Key,会对历史缓存进行清理
     */
    @Override
    public void refreshAll() {
        try {
            long t1 = System.currentTimeMillis();
            Map<K, V> map = loadAll();
            localCache.invalidateAll();
            if (!CollectionUtils.isEmpty(map)) {
                map.forEach(this::writeCache);
            }
            log.info("加载:{}.loadAll() success, stats:{},cost:{}ms", this.getClass().getSimpleName(), localCache.stats(), System.currentTimeMillis() - t1);
        } catch (Exception ex) {
            String errorMsg = MessageFormatter.format("加载:{}.loadAll()到内存-异常:", new Object[]{this.getClass().getSimpleName()}).getMessage();
            log.error(errorMsg, ex);
            throw new RuntimeException(errorMsg);
        }
    }


    /**
     * 子类实现,缓存数据加载,单Key
     *
     * @param keys
     * @return
     */
    protected abstract Map<K, V> load(Set<K> keys);

    /**
     * 子类实现,缓存数据加载,多Key
     *
     * @param key
     * @return
     */
    protected abstract V load(K key);

    /**
     * 子类实现,缓存数据加载,全部Key
     *
     * @return Map<K, V>
     */
    protected abstract Map<K, V> loadAll();

    /**
     * 缓存Key转换
     *
     * @param k k
     * @return String
     */
    private String toLocalKey(K k) {
        return k.toString();
    }

    /**
     * 写入缓存
     *
     * @param k k
     * @param v v
     */
    private void writeCache(K k, V v) {
        String localKey = toLocalKey(k);
        localCache.put(localKey, v);
    }

    /**
     * 删除缓存key
     *
     * @param k key
     */
    public void remove(K k) {
        localCache.invalidate(k);
    }
}

```

### 2）`StringLocalCache`

```java

import java.util.List;
import java.util.Map;
import java.util.Set;

/**
 *
 * StringLocalCache
 * @author zhangyujin
 * @date 2023/1/3  13:30.
 */
@Slf4j
@Component
public class StringLocalCache extends AbstractLocalCacheManager<String, List<String>> {

    /**
     * @param s s
     * @return load
     */
    @Override
    protected List<String> load(String s) {
        return null;
    }

    /**
     * load
     *
     * @param keys keys
     * @return Map<String, String>
     */
    @Override
    protected Map<String, List<String>> load(Set<String> keys) {
        return null;
    }


    /**
     * loadAll
     *
     * @return Map<String, String>
     */
    @Override
    protected Map<String, List<String>> loadAll() {
        return null;
    }


    /**
     * 每5分钟更新一次缓存
     */
    @Scheduled(fixedRate = 5 * 60 * 1000)
    @Override
    public void refreshAll() {
        super.refreshAll();
    }

}

```





# 三、`Caffeine`

> ⬤  `Guava` `Cache` 是由 `Google` 开源的基于 `LRU` 替换算法的缓存技术。但 `Guava`  `Cache`由于被下面即将介绍的 `Caffeine`全面超越而被取代，其和 `Caffeine` 方法基本一致      
>
> ⬤  通过对 `guava` `cache` 和 `caffeine` 从性能到算法及使用的对比中，可以发现 `Caffeine` 基本是在 `Guava` 的基础上进行优化而来的，提供的功能基本一致，但是通过对算法和部分逻辑的优化，完成了对性能极大的提升，而且我们可以发现，两者切换几乎没有成本，毕竟 `caffeine` 就是以替换 `guava` `cache` 为目的而来的。      
>
> ⬤  那么为什么这么好的东西需要被淘汰呢，如果对于本地 `Cache` 有过深入研究的人应该知道 `LRU `算法基本可以满足大部分的场景，但是很多人为了精益求精，基于 `LRU`的算法，又在此基础上提出了一系列更好的，更有效果的淘汰策略。比如有 `ARC`，`LIRS` 和 `W-TinyLFU` 等都提供了接近最理想的命中率，他们这些算法进一步提高了本地缓存的效率 （`Caffein`e 采用了一种结合 `LRU`、`LFU` 优点的算法：`W-TinyLFU`，其特点是：高命中率、低内存占用。）
>
> **注意：**
>
> > ⬤  需要注意的是，在使用 `Guava` 的 `get()` 方法时，当缓存的 `load()` 方法返回 `null` 时，会抛出 `ExecutionException`。切换到`Caffeine` 后，`get()` 方法不会抛出异常，允许返回为` null` 。



## 1、`Caffeine` — 定时刷新

### 1）`AbstractLocalCacheManager`

```java
@Slf4j
@EnableScheduling
public abstract class AbstractLocalCacheManager<K, V> implements LocalCacheManage<K, V> {

    /**
     * IGNORE_kEY
     */
    private Set<K> ignoreKey;

    /**
     * AbstractLocalCacheManager
     */
    public AbstractLocalCacheManager() {
    }

    /**
     * AbstractLocalCacheManager
     *
     * @param ignoreKey ignoreKey
     */
    public AbstractLocalCacheManager(Set<K> ignoreKey) {
        this.ignoreKey = ignoreKey;
    }


    /**
     * 缓存容器
     */
    private final Cache<String, V> localCache = Caffeine.newBuilder()
            .maximumSize(200000)
            .recordStats()
            .build();

    /**
     * 初始化数据
     */
    @PostConstruct
    public void init() {
        refreshAll();
    }


    /**
     * 获取全部缓存信息
     *
     * @return Map<String, V>
     */
    @Override
    public Map<String, V> getAllLocalCache() {
        ConcurrentMap<String, V> concurrentMap = localCache.asMap();
        if (CollectionUtils.isEmpty(concurrentMap)) {
            refreshAll();
        }
        return localCache.asMap();
    }


    /**
     * 获取多个Keys结果
     *
     * @param keys keys
     * @return Map<K, V>
     */
    @Override
    public Map<K, V> getLocalCache(Set<K> keys) {
        if (CollectionUtils.isEmpty(keys)) {
            return Collections.emptyMap();
        }
        if (!CollectionUtils.isEmpty(ignoreKey)) {
            keys.removeAll(ignoreKey);
        }
        if (CollectionUtils.isEmpty(keys)) {
            return Collections.emptyMap();
        }

        // 转成本地key
        Map<String, K> localKeyMap = keys.stream().collect(Collectors.toMap(this::toLocalKey, k -> k));
        // 先获取本地结果
        Map<String, V> localResultMap = localCache.getAllPresent(localKeyMap.keySet());
        // 获取除本地缓存之外的其余信息
        Map<K, V> loadResultMap = Collections.emptyMap();
        if (localKeyMap.size() > localResultMap.size()) {
            Set<String> absentLocalKeys = Sets.difference(localKeyMap.keySet(), localResultMap.keySet());
            Set<K> absentKeys = absentLocalKeys.stream().map(localKeyMap::get).collect(Collectors.toSet());
            // 存在失效的key
            if (!absentKeys.isEmpty()) {
                loadResultMap = refresh(absentKeys);
            }
        }
        // 合并结果
        Map<K, V> retMap = new HashMap<>(loadResultMap);
        localResultMap.forEach((localKey, v) -> {
            K k = localKeyMap.get(localKey);
            retMap.put(k, v);
        });
        return retMap;
    }

    /**
     * 获取单个Key
     *
     * @param k k
     * @return V
     */
    public V getLocalCache(K k) {
        if (k == null) {
            return null;
        }
        if (!CollectionUtils.isEmpty(ignoreKey) && ignoreKey.contains(k)) {
            return null;
        }
        String localKey = toLocalKey(k);
        V ret = localCache.getIfPresent(localKey);
        if (ret == null) {
            return refresh(k);
        }
        return ret;
    }

    /**
     * 重新加载Key,会对历史缓存进行清理
     *
     * @param key key
     * @return @return
     */
    public V refresh(K key) {
        try {
            V v = load(key);
            localCache.invalidate(key);
            if (v != null) {
                writeCache(key, v);
            }
            return v;
        } catch (Exception ex) {
            String errorMsg = MessageFormatter.format("加载:{}.loadKey({})到内存-异常:", new Object[]{this.getClass().getSimpleName(), key}).getMessage();
            log.error(errorMsg, ex);
            throw new RuntimeException(errorMsg);
        }
    }

    /**
     * 重新加载多个Key,会对历史缓存进行清理
     *
     * @param keys keys
     * @return Map<K, V>
     */
    public Map<K, V> refresh(Set<K> keys) {
        try {
            Map<K, V> map = load(keys);
            localCache.invalidateAll(keys);
            if (!CollectionUtils.isEmpty(map)) {
                map.forEach(this::writeCache);
            }
            return map;
        } catch (Exception ex) {
            String errorMsg = MessageFormatter.format("加载:{}.loadKeys({})到内存-异常:", new Object[]{this.getClass().getSimpleName(), JsonUtils.toJsonString(keys)}).getMessage();
            log.error(errorMsg, ex);
            throw new RuntimeException(errorMsg);
        }

    }

    /**
     * 刷新所有Key,会对历史缓存进行清理
     */
    @Override
    public void refreshAll() {
        try {
            long t1 = System.currentTimeMillis();
            Map<K, V> map = loadAll();
            localCache.invalidateAll();
            if (!CollectionUtils.isEmpty(map)) {
                map.forEach(this::writeCache);
            }
            log.info("加载:{}.loadAll() success, stats:{},cost:{}ms", this.getClass().getSimpleName(), localCache.stats(), System.currentTimeMillis() - t1);
        } catch (Exception ex) {
            String errorMsg = MessageFormatter.format("加载:{}.loadAll()到内存-异常:", new Object[]{this.getClass().getSimpleName()}).getMessage();
            log.error(errorMsg, ex);
            throw new RuntimeException(errorMsg);
        }
    }


    /**
     * 子类实现,缓存数据加载,单Key
     *
     * @param keys
     * @return
     */
    protected abstract Map<K, V> load(Set<K> keys);

    /**
     * 子类实现,缓存数据加载,多Key
     *
     * @param key
     * @return
     */
    protected abstract V load(K key);

    /**
     * 子类实现,缓存数据加载,全部Key
     *
     * @return Map<K, V>
     */
    protected abstract Map<K, V> loadAll();

    /**
     * 缓存Key转换
     *
     * @param k k
     * @return String
     */
    private String toLocalKey(K k) {
        return k.toString();
    }

    /**
     * 写入缓存
     *
     * @param k k
     * @param v v
     */
    private void writeCache(K k, V v) {
        String localKey = toLocalKey(k);
        localCache.put(localKey, v);
    }

    /**
     * 删除缓存key
     *
     * @param k key
     */
    public void remove(K k) {
        localCache.invalidate(k);
    }

}
```



### 2）`StringLocalCache`

```java

import lombok.extern.slf4j.Slf4j;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

import java.util.List;
import java.util.Map;
import java.util.Set;

/**
 *
 * StringLocalCache
 * @author zhangyujin
 * @date 2023/1/3  13:30.
 */
@Slf4j
@Component
public class StringLocalCache extends AbstractLocalCacheManager<String, List<String>> {

    /**
     * @param s s
     * @return load
     */
    @Override
    protected List<String> load(String s) {
        return null;
    }

    /**
     * load
     *
     * @param keys keys
     * @return Map<String, String>
     */
    @Override
    protected Map<String, List<String>> load(Set<String> keys) {
        return null;
    }


    /**
     * loadAll
     *
     * @return Map<String, String>
     */
    @Override
    protected Map<String, List<String>> loadAll() {
        return null;
    }


    /**
     * 每5分钟更新一次缓存
     */
    @Scheduled(fixedRate = 1 * 60 * 1000)
    @Override
    public void refreshAll() {
        super.refreshAll();
    }

}

```





# 三、多级缓存

> ⬤ 缓存，就是让数据更接近使用者，让访问速度加快，从而提升系统性能。工作机制大概是先从缓存中加载数据，如果没有，再从慢速设备(eg:数据库)中加载数据并同步到缓存中。    
>
> ⬤ 多级缓存，是指在整个系统架构的不同系统层面进行数据缓存，以提升访问速度。主要分为三层缓存：网关 `nginx`缓存、分布式缓存、本地缓存。这里的多级缓存就是用 `redis` 分布式缓存 + `caffeine` 本地缓存整合而来。

平时我们在开发过程中，一般都是使用 `redis` 实现分布式缓存、`caffeine` 操作本地缓存，但是发现只使用 `redis` 或者是 `caffeine`实现缓存都有一些问题：

⬤ 一级缓存：`Caffeine` 是一个一个高性能的 `Java` 缓存库；使用 `Window` `TinyLfu` 回收策略，提供了一个近乎最佳的命中率。优点数据就在应用内存所以速度快。缺点受应用内存的限制，所以容量有限；没有持久化，重启服务后缓存数据会丢失；在分布式环境下缓存数据数据无法同步；    

⬤ 二级缓存：`redis` 是一高性能、高可用的 `key` - `value` 数据库，支持多种数据类型，支持集群，和应用服务器分开部署易于横向扩展。优点支持多种数据类型，扩容方便；有持久化，重启应用服务器缓存数据不会丢失；他是一个集中式缓存，不存在在应用服务器之间同步数据的问题。缺点每次都需要访问 `redis` 存在 `IO` 浪费的情况。

综上所述，我们可以通过整合 `redis` 和 `caffeine` 实现多级缓存，解决上面单一缓存的痛点，从而做到相互补足。

## 1、`redis` 和 `caffeine` 多级缓存

### 1）技术方案

![image-20231109174523409](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/blogImages/image-20231109174523409.png)







# 四、`OHC`

​	在现代高并发、大数据量的应用场景中，缓存技术是提升系统性能的重要手段之一。传统的堆内缓存（如 Java 的 `HashMap`）虽然简单易用，但在面对大规模数据时，容易导致 `Java` 堆内存的频繁 `GC`，从而影响系统性能。

​        堆外缓存（`Off`-`Heap` `Cache`）通过将数据存储在 `JVM` 堆外内存中，有效避免了这一问题。`OHCache`（`Off`-`Heap` `Cache`）是一款高性能的堆外缓存框架，专为 `Java` 应用设计，旨在减少垃圾回收（`GC`）对性能的影响，同时提供低延迟、高吞吐量的缓存解决方案。它特别适合处理大规模数据缓存，如广告检索系统、推荐服务等场景。



## 1、堆外缓存概述

> 堆外缓存 是指将缓存数据存储在 `JVM` 堆外内存中的缓存技术。堆外内存不受` JVM` 垃圾回收机制的管理，因此可以避免频繁的 `GC` 操作，特别适合存储大规模数据。

### 1） `OHC` 的特点

`OHC` 是一个开源的 `Java` 堆外缓存库，具有以下特点：

- **堆外存储**：数据存储在 `JVM` 堆外内存中，仅少量元数据存储在堆内，避免频繁 `GC` 对性能的影响。
- **高性能**：读写速度在微秒级别，能够支撑高并发场景。

- **大容量**：可维护百万级以上的缓存条目，支持 `GB` 级别的缓存容量。

- **灵活配置**
  - 支持为每个缓存项设置过期时间。
  - 提供 `LRU`、`W-TinyLFU` 等缓存逐出策略。
  - 支持异步加载缓存。

### 2）`OHC`  的核心组件

- 缓存存储：使用堆外内存存储缓存数据。

- 缓存淘汰策略：支持 `LRU`、`LFU` 等淘汰策略。

- 并发控制：通过分段锁实现高并发访问。



### 3）优缺点

#### a、优点

- **减少 `GC` 压力：**堆外内存不受 `JVM` 管理，避免了频繁的 `GC`。

- **支持大数据量：**堆外内存可以分配更大的空间，适合存储大规模数据。

- **高性能：**直接操作堆外内存，减少了数据拷贝的开销。



#### b、缺点

- **开发复杂度高：**需要手动管理内存，容易导致内存泄漏。

- **数据序列化开销：**堆外缓存通常需要将数据序列化为字节数组，增加了额外的开销。



### 4）常见问题

#### a、`OHC` 解决了什么问题？

- **堆内缓存的 `GC` 困境**
  - 传统堆内缓存（如 `HashMap`、`Guava` `Cache` ）将数据存储在 `JVM` 堆内存中，当缓存数据量达到 `GB` 级别时，`GC`（垃圾回收）会频繁扫描堆内存，导致应用线程暂停（`Stop`-`The`-`World`），引发性能抖动。

- **堆外缓存的突破**
  - `OHC` 将数据序列化后存储在堆外内存（`Direct` `Memory` ），完全绕过 `JVM` 堆管理，避免了 `GC` 对缓存数据的扫描，从而消除`GC` 导致的性能抖动。
  - 堆外内存的分配和释放由应用程序直接控制（通过`Unsafe`或`ByteBuffer`），适合高频读写场景。



**问题背景：**用户访问商品详情页时，系统需实时推荐“相似商品”和“你可能喜欢的商品”，推荐结果需在`100ms` 内返回。

- **技术架构：**
  - 后端服务使用Java（Spring Boot）实现。
  - 推荐数据（如商品特征向量、用户画像）原本存储在堆内缓存（Guava Cache）中，缓存大小约5GB。
  - 当缓存未命中时，回源到Redis集群获取数据（网络延迟约5ms）。
- **痛点爆发**
  - **`GC` 停顿导致雪崩：**
    - 每日高峰期（`QPS` 5万+），堆内缓存触发频繁 `Full` `GC`（每 `10` 分钟一次），每次停顿 `300ms` ~ `1s`。
    - `GC` 期间所有推荐请求阻塞，导致超时率飙升至 `20%` ，用户流失严重。
  - **内存浪费：**`Java` 对象头（`Object` `Header`）和内存对齐导致实际内存占用比原始数据大 `30%`（ `5GB` 缓存占用 `7GB`堆内存）。
  - **扩展性受限**：增加缓存数据量会加剧 `GC` 压力，无法支持未来业务增长（如增加个性化推荐维度）。

- **`OHC` 解决方案：堆外缓存重构**

  - **数据迁移**：
    - 将推荐数据（商品特征、用户画像）从Guava Cache迁移到OHC堆外缓存。
    - 使用Kryo序列化框架压缩数据，序列化后大小比原始对象减少50%。

  - 缓存策略优化：
    - 分层缓存：
      - **热数据**（Top 1%高频访问商品）永久驻留OHC，不设置过期时间。
      - **温数据**（长尾商品）使用LRU驱逐策略，TTL 1小时。
    - 异步预热：系统启动时通过多线程异步加载 `Redis` 中的推荐数据到 `OHC`，避免启动延迟。



#### b、**`OHC`  核心优势 是什么？**

- **低延迟读写：**`OHC` 的读写速度稳定在微秒级别（如 `10` 微秒），远优于堆内缓存的毫秒级延迟，尤其适合实时性要求高的场景。
- **海量数据支撑：**单应用可管理 `10GB` 以上堆外缓存，支持百万级缓存条目，且内存开销低于堆内缓存（因无需存储对象头信息）。
- **智能缓存管理**：过期策略：支持 `TTL`（Time To Live）和绝对过期时间，确保数据时效性。
- **驱逐策略**：提供 `LRU`（最近最少使用）和 `W-TinyLFU`（基于频率统计的优化算法）两种驱逐策略，减少有效数据被误删。
- **异步加载支持：**允许异步加载缓存数据，避免阻塞主线程，提升系统响应速度。



#### c、适用场景是什么

- **堆内缓存引发的 `GC` 性能瓶颈**（如高并发、大数据量场景）。

- **对延迟敏感的实时系统**（如推荐、风控、实时计算）。
- **需要降低内存成本的场景**（如序列化后数据密度更高的场景）。
- **分布式缓存：**在分布式系统中，使用 `OHC` 作为本地缓存，与分布式缓存（如 `Redis`）结合使用。

- **大数据处理：**在大数据处理场景中，使用 OHC 缓存中间计算结果，加速数据处理。
- **高并发应用：**在高并发，使用 `OHC` 缓存热点数据，减少数据库压力。





## 2、使用

```xml
<dependency>
    <groupId>org.caffinitas.ohc</groupId>
    <artifactId>ohc-core</artifactId>
    <version>0.7.4</version> <!-- 根据实际情况选择版本 -->
</dependency>
```



### 1） 实现

#### a、序列化器

> `OHCache` 需要将缓存的键值对序列化为二进制数据存储在堆外内存中。因此，需要实现 `org.caffinitas.ohc.CacheSerializer`接口来定义键和值的序列化与反序列化逻辑。

```java
import org.caffinitas.ohc.CacheSerializer;
import java.nio.ByteBuffer;

public class StringSerializer implements CacheSerializer<String> {

    @Override
    public int serializedSize(String value) {
        byte[] bytes = value.getBytes(StandardCharsets.UTF_8);
        if (bytes.length > 65535) {
            throw new RuntimeException("String too long");
        }
        return bytes.length + 2; // 2 bytes for length
    }

    @Override
    public void serialize(String value, ByteBuffer buf) {
        byte[] bytes = value.getBytes(StandardCharsets.UTF_8);
        buf.put((byte) ((bytes.length >> 8) & 0xFF));
        buf.put((byte) (bytes.length & 0xFF));
        buf.put(bytes);
    }

    @Override
    public String deserialize(ByteBuffer buf) {
        int length = (((buf.get() & 0xFF) << 8) | (buf.get() & 0xFF));
        byte[] bytes = new byte[length];
        buf.get(bytes);
        return new String(bytes, StandardCharsets.UTF_8);
    }
}
```

#### b、创建 `OHCache` 实例

```java
import org.caffinitas.ohc.OHCache;
import org.caffinitas.ohc.OHCacheBuilder;
import org.caffinitas.ohc.Eviction;

public class OHCacheExample {

    public static void main(String[] args) {
        // 创建OHCache实例
        OHCache<String, String> ohCache = OHCacheBuilder.<String, String>newBuilder()
                .keySerializer(new StringSerializer()) // 设置键序列化器
                .valueSerializer(new StringSerializer()) // 设置值序列化器
                .capacity(1024 * 1024 * 1024) // 设置缓存容量为1GB
                .eviction(Eviction.LRU) // 设置缓存逐出策略为LRU
                .segmentCount(512) // 设置分段数，提高并发性能
                .build();

        // 使用OHCache
        ohCache.put("key1", "value1");
        String value = ohCache.get("key1");
        System.out.println("Value for key1: " + value);
    }
}
```



### 2）参数介绍

#### a、基本参数

| 参数                | 说明                                                |
| ------------------- | --------------------------------------------------- |
| `capacity`          | 缓存容量，单位为字节。                              |
| `segmentCount`      | 缓存分段数，提高并发性能。默认值为CPU核心数的两倍。 |
| `hashTableSize`     | 哈希表大小，影响缓存的查找性能。                    |
| `eviction`          | 缓存逐出策略，支持LRU、W-TinyLFU等。                |
| `timeouts`          | 是否启用缓存项过期时间。                            |
| `expireAfterAccess` | 设置缓存项在最后一次访问后的过期时间。              |
| `expireAfterWrite`  | 设置缓存项在写入后的过期时间。                      |



#### b、基本操作

```java
添加缓存：ohCache.put("key1", "value1");

获取缓存：String value = ohCache.get("key1");

删除缓存：ohCache.remove("key1");
```



#### c、 **缓存的配置与调优**

```java
设置缓存大小：OHCacheBuilder.newBuilder() .capacity(1024 * 1024 * 1024) // 1GB .build();

设置淘汰策略：OHCacheBuilder.newBuilder() .eviction(Eviction.LRU) .build();
```



#### b、缓存监控和统计

> `OHCache` 提供了缓存命中率、缓存大小等统计信息，帮助开发者监控缓存性能。

```sql
// 获取缓存统计信息
long hitCount = ohCache.stats().hitCount();
long missCount = ohCache.stats().missCount();
double hitRate = (double) hitCount / (hitCount + missCount);
System.out.println("Cache Hit Rate: " + hitRate);
```



## 3、实战建议

- **内存配置**
  - **预分配足够内存**：通过 `memoryCapacity` 设置足够的内存，减少动态扩容带来的性能损耗。
  
  - **合理设置缓存容量**：根据应用的实际需求和数据规模，合理设置缓存容量，避免内存浪费或不足。
  
  - **减少内存碎片：**通过合理设置缓存大小和内存分配策略，减少内存碎片。
  - **内存泄漏风险：**堆外内存不受 `JVM` 管理，使用完毕后需调用 `cache.close()` 释放资源。
  
- **逐出策略**：根据数据的访问模式，选择合适的缓存逐出策略，如LRU适合访问频率相对均匀的数据，W-TinyLFU适合访问频率差异较大的数据。

  - `LRU`（最近最少使用）：简单高效，适合访问模式稳定的场景。

  - `W_TINY_LFU`：结合频率和时间，更适合热点数据频繁访问的场景。

- **性能问题：**

  - **考虑线程安全**：`OHCache` 本身是线程安全的，但在多线程环境下使用时，仍需注意缓存操作的原子性和一致性。频繁的 `put`/`remove` 可能导致锁竞争，建议优先使用 `putIfAbsent` 等原子操作
  - **监控缓存性能**：定期监控缓存的命中率、加载时间等指标，及时调整缓存配置，优化性能。
  - **处理序列化异常**：在实现序列化器时，需处理可能的序列化异常，确保缓存的健壮性。
    - **序列化兼容性**：若启用持久化，需确保序列化器在不同版本间兼容，否则可能无法正确恢复数据。
  - **预热缓存：**提前加载热点数据。
  - **合理设置序列化器**：自定义序列化器（如使用 `ByteBuffer` 直接操作二进制数据）比 Java 内置序列化更高效。
  - **批量操作**：使用 `asMap().entrySet()` 进行批量处理，减少锁竞争。

- **内存释放：**
  - `OHC` 提供两种堆外内存分配器：
    - `JNANativeAllocator`：基于`Native.malloc(size)`，兼容性更好。
    - `UnsafeAllocator`：基于`Unsafe.allocateMemory(size)`，性能更高（但需处理安全限制）。
  - 推荐使用 `jemalloc` 优化内存分配，减少碎片（在 `Linux` 系统中，`Java` 操作堆外内存默认使用的是 `glibc` 来操作内存，`glibc`  从 `2.11` 开始对每个线程引入内存池，会造成内存碎片化和缓存无法及时释放的问题）





### 1）内存配置

堆外内存总量：总容量加上哈希表。每个哈希桶（当前）需要 8 个字节，因此公式为 `capacity` + `segment_count` * `hash_table_size` * `8`。例：总容量 = `1G`（`capacity`） + `1G`（`512*256*1024*8` ） =` 2G`

-  `segmentCount` 太小会带来分段锁竞争导致 `cpu` 升高，性能下降；太大会占用内存开销，需要查询的分段也更多，耗时也会增加

```java
.segmentCount(512) // 分段数量
.hashTableSize(256 * 1024)// 哈希表大小
.capacity(1024 * 1024 * 1024L) //缓存容量1GB
```



### 2）`ohc` 过期机制：

> 时间轮参数配置，`timeoutsSlots` * `timeoutsPrecision`：这个乘积实际上代表了缓存系统能够管理的最大超时时间范围， 应该大于或等于 `defaultTTLmillis` ，如小于会可能导致回收不及时，例：`128*8`=`1024 > 60*15` = `900` 可以覆盖到过期

```java
.timeouts(true) // 过期时间，根据业务自己选择
.timeoutsSlots(128) // 分片  时间轮槽位
  
// 8s检测一次  128 * 8 = 1024 > 60 * 15= 900 
// 可以覆盖到过期  // 每个槽位的时间跨度（多长时间检查一次）  若需支持长过期（如小时级），需增大槽位数或降低精度
.timeoutsPrecision(8000) 
  
// 15分钟  如果设置了一个值> 0，支持 TTL 的实现将用给定的 TTL（以毫秒为单位）标记所有条目。  
.defaultTTLmillis(1000 * 60 * 15)
```









# 缓存对象占用观察

```xml
<dependency>
    <groupId>org.apache.lucene</groupId>
    <artifactId>lucene-core</artifactId>
    <version>8.11.2</version>
</dependency>

RamUsageEstimator就是根据java对象在堆内存中的存储格式，通过计算Java对象头、实例数据、引用等的大小，相加而得，如果有引用，还能递归计算引用对象的大小。RamUsageEstimator的源码并不多，几百行，清晰可读。这里不进行一一解读了。它在初始化的时候会根据当前JVM运行环境、CPU架构、运行参数、是否开启指针压缩、JDK版本等综合计算对象头的大小，而实例数据部分则按照java基础数据类型的标准大小进行计


使用该第三方工具比较简单直接，主要依靠JVM本身环境、参数及CPU架构计算头信息，再依据数据类型的标准计算实例字段大小，计算速度很快，另外使用较方便。如果非要说这种方式有什么缺点的话，那就是这种方式计算所得的对象头大小是基于JVM声明规范的，并不是通过运行时内存地址计算而得，存在与实际大小不符的这种可能性。

```

```java
public static void main(String[] args) {
    Map<String, String> map = new HashMap<>();
    System.out.println("map init value is " +  RamUsageEstimator.sizeOfObject(map));
    for (int i = 1000000; i < 6000000; i++) {
        map.put(String.valueOf(i), String.valueOf(i+1000000));
    }

    System.out.println("map size: 1  is " + RamUsageEstimator.sizeOfObject(map.get("1000000"))+ " byte");
    System.out.println("map size: " +map.size() +"  is " + RamUsageEstimator.sizeOfMap(map)+ " byte");
    System.out.println("map size: " +map.size() +"  is " + RamUsageEstimator.sizeOfObject(map)+ " byte");

    // JDK自带
    System.out.println("map size: " +map.size() +" is " + ObjectSizeCalculator.getObjectSize(map) + " byte");
}



map init value is 48
map size: 1  is 56 byte
map size: 5000000  is 720000048 byte
map size: 5000000  is 720000048 byte
map size: 5000000 is 753554512 byte
```

















![ContactAuthor](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/assets/img/artical_bottom.jpg)



<!-- Gitalk 评论 start  -->

<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">

<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script> 
<div id="gitalk-container"></div>    
 <script type="text/javascript">
    var gitalk = new Gitalk({
		clientID: `1d164cd85549874d0e3a`,
		clientSecret: `527c3d223d1e6608953e835b547061037d140355`,
		repo: `HealerJean.github.io`,
		owner: 'HealerJean',
		admin: ['HealerJean'],
		id: 'GPNnLjIcWlVfrtFs',
    });
    gitalk.render('gitalk-container');
</script> 



<!-- Gitalk end -->




---
title: 分布式之_4_限流
date: 2022-04-01 00:00:00
tags: 
- Distributed
category: 
- Distributed
description: 分布式之_4_限流

---

**前言**     

 Github：[https://github.com/HealerJean](https://github.com/HealerJean)         

 博客：[http://blog.healerjean.com](http://HealerJean.github.io)          



# 1、为什么要限流

> 任务系统都有一个上限，如果超过了这个上限，会对系统造成毁灭性的打击，因此在任何时刻都应该保证系统的并发请求数量不要超过某个阈值，限流就是这一目的



## 1.1、场见的限流算法

| 策略     | 原理描述                                                     | 优缺点                                                     |
| -------- | ------------------------------------------------------------ | ---------------------------------------------------------- |
| 令牌桶   | ⬤ 令牌按照恒定速率入桶，桶满则丢弃多余令牌<br>⬤ 请求来临时从桶中获取令牌，桶空则等待令牌或者拒绝当前请求 | 优点：速率可变，能够应对突发流量<br>缺点：复杂度高         |
| 漏桶     | ⬤ 以任意速率生成令牌放入桶中<br>⬤ 桶流出（消费）令牌的速率是固定的<br>⬤ 若流入的令牌超过了桶的容量，则被丢弃，桶的容量不变 | 优点：速率稳定<br>缺点：应对突发流量需要等待令牌           |
| 计数器   | ⬤ 对一个时间窗口设置一个可以访问的量<br>⬤ 下一个时间窗口清零计数<br>⬤ 单位时间超出阈值的请求，可以设置不同的策略，等待或者丢弃 | 优点：容易实现，复杂度第<br>缺点：容易瞬间造成流量突刺现象 |
| 滑动窗口 |                                                              |                                                            |



# 2、基于令牌桶的 `Guava-RateLimiter`

## 2.1、实例

> `acq 1`时并没有任何等待直接预消费了1个令牌；      
>
> `acq 6`时，由于之前预消费了1个令牌，故而等待了2秒（上一个预消费令牌数1），之后又预消费了6个令牌；    
>
> `acq 2`时同理，由于之前预消费了6个令牌，故而等待了12秒（上一个预消费令牌数6）；      
>
> > **`RateLimiter`通过限制后面请求的等待时间，来支持一定程度的突发请求(预消费)**。

```java
@Test
public void test_1(){
    // 1、创建一个RateLimiter，指定每秒放0.5个令牌（2秒放1个令牌
    RateLimiter rateLimiter = RateLimiter.create(0.5);

    int[] a = {1, 6, 2};
    for (int i = 0 ; i < a.length; i++){
        log.info("时间戳：{}, 获取 {} 个令牌需要 {}s", System.currentTimeMillis(), a[i], rateLimiter.acquire(a[i]));
    }

    // 1516166482561 acq 1: wait 0.0s
    // 1516166482563 acq 6: wait 1.997664s
    // 1516166484569 acq 2: wait 11.991958s
}
```

## 2.2、源码分析

### 2.1.1、两种模式

> Guava有两种限流模式    
>
> ⬤ 一种为稳定模式 (`SmoothBursty`: 令牌生成速度恒定) 
>
> ⬤ 一种为渐进模式 (`SmoothWarmingUp`: 令牌生成速度缓慢提升直到维持在一个稳定值)

![image-20220415202624561](/Users/healerjean/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20220415202624561.png)

### 2.1.2、核心思想

> `RateLimiter` 核心思想有   
>
> > 1、响应本次请求后，**动态计算下次可用服务的时间， 如果下次请求在可用时间之前，则需要等待**，`SmoothRateLimiter` 类中 `nextFreeTicketMicros` 表示下次可用服务的时间，例如，如果我们配置 `QPS` 为1，本次请求处理完成之后，下次请求的时间需要在1s中之后       
> >
> > 2、`RateLimiter` 的子类 `SmoothBursty` 支持处理突发请求流量，例如，我们设置 `QPS`为1，在 `10s`中之内没有请求，那么令牌桶中就有`10`个空闲令牌，如果下次请求是`acquire(20)`，那么就不需要等待20s了，因为令牌桶中已经有10个令牌了，`SmoothRateLimiter`  中 `storedPermits` 就是用来存储当前令牌桶中空闲的令牌数      
> >
> > 3、`SmoothWarmingUp` 提出一种 “热身模式” 和 “冷区期” ，具体详情再说吧，先慢慢俩



### 2.1.3、`SmoothRateLimiter` 重要属性解析

```java
@GwtIncompatible
abstract class SmoothRateLimiter extends RateLimiter {
  //当前持有的令牌数
  double storedPermits;
  
  //令牌数上限
  double maxPermits;
  
  //生成一个令牌需要的时间
  double stableIntervalMicros;
  
  //下次请求能获取令牌的时间，是个时间戳
  private long nextFreeTicketMicros;

```

### 2.1.4、`SmoothBursty` 具体实现

#### 2.1.4.1、`create`

> 根据指定的 `QPS` 数创建 `RateLimiter`，底层调用如下：     
>
> `SmoothBursty` 的 `maxBurstSeconds` 构造函数参数，主要用于计算 `maxPermits`，  **`maxPermits` =  `maxBurstSeconds` * `permitsPerSecond`**

```java
//根据指定的 QPS 数创建  RateLimiter
public static RateLimiter create(double permitsPerSecond) {
  return create(RateLimiter.SleepingStopwatch.createFromSystemTimer(), permitsPerSecond);
}

@VisibleForTesting
static RateLimiter create(RateLimiter.SleepingStopwatch stopwatch, double permitsPerSecond) {
  // 1、创建 SmoothBursty 限流器
  RateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0D /* maxBurstSeconds */);
  
  // 2、设置限流速率
  rateLimiter.setRate(permitsPerSecond);
  return rateLimiter;
}
```



再看 `setRate` 方法，最终会调用 `doSetRate`, `doSetRate`是一个抽象方法，

![image-20220415204834107](/Users/healerjean/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20220415204834107.png)

```java
final void doSetRate(double permitsPerSecond, long nowMicros) {
  this.resync(nowMicros);
  //生成一个令牌需要的时间 
  double stableIntervalMicros = (double)TimeUnit.SECONDS.toMicros(1L) / permitsPerSecond;
  this.stableIntervalMicros = stableIntervalMicros;
  this.doSetRate(permitsPerSecond, stableIntervalMicros);
}

```

![image-20220415204932057](/Users/healerjean/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20220415204932057.png)



实现如下

```java
void doSetRate(double permitsPerSecond, double stableIntervalMicros) {
  double oldMaxPermits = this.maxPermits;
  //设置最大令牌数
  this.maxPermits = this.maxBurstSeconds * permitsPerSecond;
  if (oldMaxPermits == 1.0D / 0.0) {
    this.storedPermits = this.maxPermits;
  } else {
    this.storedPermits = oldMaxPermits == 0.0D ? 0.0D : this.storedPermits * this.maxPermits / oldMaxPermits;
  }

}
```



#### 2.1.4.2、`acquire`

> `acquire(int permits)` 从 `RateLimiter` 中获取x个令牌，该方法会一直阻塞，直到获取令牌，主要做了如下3件事

```java
public double acquire(int permits) {
  // 1、获取当前请求需要等待的时间（惰性计算）
  long microsToWait = this.reserve(permits);

  // 2、seleep.microToWait （时间窗口）
  this.stopwatch.sleepMicrosUninterruptibly(microsToWait);

  // 3、返回 microToWait 对应的秒级时间
  return 1.0D * (double)microsToWait / (double)TimeUnit.SECONDS.toMicros(1L);
}


final long reserve(int permits) {
  //检查参数是否ok
  checkPermits(permits);
  synchronized(this.mutex()) {
    //计算需要等待的诗句
    return this.reserveAndGetWaitLength(permits, this.stopwatch.readMicros());
  }
}
```



#### 2.1.4.3、核心接口 `reserveAndGetWaitLength`

> **该方法需要返回等待的时间，是 `RateLimiter` 的核心接口**     
>
>  `RateLimiter` 支持突发流量的本质是，将当前需要的令牌数量 `requiredPermits` 拆分成 `storedPermitsToSpend`（持有令牌中可用的数量）和 `freshPermits`（需要预支的令牌数量）；分别计算需要等待的时间，然后更新 `nextFreeTicketMicros` 下次获取令牌的时间     
>
> 什么意思呢？举个例子吧：   
>
> > 当前 `RateLimiter` 持有 4 个令牌，当前请求需要 6 个令牌；则 6 个令牌中 4 个是可以从持有的令牌中直接获取，而另外两个需要预支的令牌则需要单独计算时间；     
> >
> > 伪代码：`getReqWaitTime(6)` = `getWaitTime(4) `+ `getFreshWait(6 - 4) `     
> >
> > `SmoothBursty  `模式：        
> >
> > ⬤  `getWaitTime(4)` 是可以直接获取的，即 `time` = `0`；        
> >
> > ⬤ `getFreshWait(6 - 4)` 则等于 **`freshPermits ` \* `stableIntervalMicros`** （预支令牌数 * 生成一个令牌需要的时间）



```java
@Override
final long reserveEarliestAvailable(int requiredPermits, long nowMicros) {
  //1.根据当前时间和预计下一秒时间判断有无新令牌产生，有则更新持有令牌数storedPermits 和 下次请求时间nextFreeTicketMicros
  resync(nowMicros); 
  long returnValue = nextFreeTicketMicros;

  //2.以下两句，根据请求需要的令牌数requiredPermits和storedPermits当前持有的令牌数storedPermits分别计算 持有令牌中可用的数量storedPermitsToSpend和需要预支的令牌数量freshPermits
  double storedPermitsToSpend = min(requiredPermits, this.storedPermits); 
  double freshPermits = requiredPermits - storedPermitsToSpend;

  //3.分别计算storedPermitsToSpend和freshPermits的等待时间
  long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend)
    + (long) (freshPermits * stableIntervalMicros);

  try {
    //4.更新nextFreeTicketMicros
    this.nextFreeTicketMicros = LongMath.checkedAdd(nextFreeTicketMicros, waitMicros); 
  } catch (ArithmeticException e) {
    this.nextFreeTicketMicros = Long.MAX_VALUE;
  }

  //5.更新storedPermits 
  this.storedPermits -= storedPermitsToSpend; 

  return returnValue;
}
```



### 2.1.5、`SmoothWarmingUp` 具体实现

> `WarmingUp` 是 `RateLimite`r 的另一种实例不同于 `SmoothBursty` ，它存在一个 “热身” 的概念。     
>
> 即：如果当前系统处于 “ 冷却期”（ 即一段时间没有获取令牌，即：当前持有的令牌数量大于某个阈值），则下一次获取令牌需要等待的时间比 `SmoothBursty` 模式下的线性时间要大，并且逐步下降到一个稳定的数值。     
>
> > 大致原理：将 `storedPermits` 分成两个区间值：[0, `thresholdPermits`) 和 [`thresholdPermits`, `maxPermits`]。当请求进来时，如果当前系统处于 "`cold`" 的冷却期状态，从 [`thresholdPermits`, `maxPermits`] 区间去拿令牌，所需要等待的时间会长于从区间 [0, `thresholdPermits`) 拿相同令牌所需要等待的时间。当请求增多，`storedPermits` 减少到 `thresholdPermits` 以下时，此时拿令牌所需要等待的时间趋于稳定。这也就是所谓 “热身” 的过程。

反应到代码上，和 `SmoothBursty` 的不同有两点       

⬤ `create` 方法不同；该方法指定了 “热身” 模型需要的关键参数          

⬤ `acquire` 底层的 `storedPermitsToWaitTime`；由于 1 的缘故，获取当前令牌中可用令牌 `storedPermitsToSpend` 的等待时间，需要依据热身模型来计算



```java
@Test
public void test_2() throws InterruptedException {
  //预热模式,设置预热时间和QPS，即在正式acquire前，限流器已经持有 5 * 4 = 20个令牌
  RateLimiter rateLimiter = RateLimiter.create(5, 4000, TimeUnit.MILLISECONDS);
  for (int i = 1; i < 50; i++) {
    System.out.println(System.currentTimeMillis() + " acq " + i + ": wait " + rateLimiter.acquire() + "s");
    if (i == 15) {
      Thread.sleep(2000);
      System.out.println(System.currentTimeMillis() + " acq " + 15 + ": wait " + rateLimiter.acquire() + "s");
    }
  }
}

1552395652026 acq 1: wait 0.0s
1552395652028 acq 2: wait 0.578357s
1552395652612 acq 3: wait 0.533835s
1552395653151 acq 4: wait 0.495191s
1552395653649 acq 5: wait 0.457239s
1552395654110 acq 6: wait 0.41631s
1552395654528 acq 7: wait 0.377524s
1552395654912 acq 8: wait 0.334018s
1552395655248 acq 9: wait 0.298249s
1552395655550 acq 10: wait 0.256165s
1552395655808 acq 11: wait 0.217752s
1552395656028 acq 12: wait 0.197672s
1552395656231 acq 13: wait 0.19451s
1552395656429 acq 14: wait 0.196465s
1552395656630 acq 15: wait 0.195714s
1552395658834 acq 15: wait 0.0s
1552395658834 acq 16: wait 0.34158s
1552395659180 acq 17: wait 0.296628s
1552395659482 acq 18: wait 0.256914s
1552395659744 acq 19: wait 0.216517s
1552395659965 acq 20: wait 0.195077s
1552395660164 acq 21: wait 0.195953s
1552395660365 acq 22: wait 0.195196s
1552395660564 acq 23: wait 0.196015s
1552395660764 acq 24: wait 0.195972s

```

⬤ `acq 1` 时并没有任何等待直接预消费了 1 个令牌    

⬤ `acq 2～11` 时，由于当前系统处于冷却期，因此开始等待的时间较长，并且逐步下降到一个稳定值     acq 12～15 时，等待时间趋于稳定的 0.2 秒，即 1/QPS      

⬤ `acq 15` 同时，`sleep2` 秒，即在当前基础上，又新增 `5*2` 个令牌；将系统过渡到冷却期       

⬤ `acq 15`～结束，重复 acq 2～15 的过程。



#### 2.1.5.1、`SmoothWarmingUp` & 预热模型

> `SmoothWarmingUp` 是 `SmoothRateLimiter` 的子类，它相对于 `SmoothRateLimiter` 多了几个属性：

```java
static final class SmoothWarmingUp extends SmoothRateLimiter {
  //预热时间
  private final long warmupPeriodMicros;

  //预热区斜率
  private double slope;

  //区分冷区期和稳定器的阈值
  private double thresholdPermits;

  //code inteval/ stable inteval 的固定数值 硬编码写死的是 3
  private double coldFactor;

```

`SmoothRateLimiter` 类的注释文档中有对预热模型的详细解释

![image-20220418173609666](/Users/healerjean/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20220418173609666.png)



**横坐标：**是当前令牌桶中的令牌 `storedPermits`，前面说过 `SmoothWarmingUp` 将 `storedPermits` 分为两个区间：[0, `thresholdPermits`) 和 [`thresholdPermits`, `maxPermits`]。

**纵坐标：**请求的间隔时间，`stableInterval` 就是 1 / `QPS`，例如设置的 `QPS` 为 5，则 `stableInterval` 就是 200ms，`coldInterval` = `stableInterval` * `coldFactor`，这里的 `coldFactor` 硬编码写死的是 3。      

**当系统请求增多，图像会像左移动，直到 `storedPermits` 为 0。等待一段时间后，随着令牌的生成当系统进入 `cold` 阶段时，图像会向右移，直到 `storedPermits` 等于 `maxPermits`。**        



#### 2.1.5.2、`create`

> `create(double permitsPerSecond, long warmupPeriod, TimeUnit unit)`       
>
> 根据指定的 ` QPS ` 和预热期来创建 `RateLimiter`，在这段预热时间内，`RateLimiter  `每秒分配的许可数会平稳地增长直到预热期结束时达到其最大速率。

```java
@VisibleForTesting
static RateLimiter create(
  SleepingStopwatch stopwatch, double permitsPerSecond, long warmupPeriod, TimeUnit unit,
  double coldFactor) {
  //1.创建SmoothWarmingUp限流器
  RateLimiter rateLimiter = new SmoothWarmingUp(stopwatch, warmupPeriod, unit, coldFactor);

  //2.设置限流速率
  rateLimiter.setRate(permitsPerSecond);
  return rateLimiter;
}


public final void setRate(double permitsPerSecond) {
  Preconditions.checkArgument(permitsPerSecond > 0.0D && !Double.isNaN(permitsPerSecond), "rate must be positive");
  synchronized(this.mutex()) {
    this.doSetRate(permitsPerSecond, this.stopwatch.readMicros());
  }
}

public static RateLimiter create(double permitsPerSecond, long warmupPeriod, TimeUnit unit) {
  checkArgument(warmupPeriod >= 0, "warmupPeriod must not be negative: %s", warmupPeriod);
  return create(SleepingStopwatch.createFromSystemTimer(), permitsPerSecond, warmupPeriod, unit,
                3.0);
}

SmoothWarmingUp(
  SleepingStopwatch stopwatch, long warmupPeriod, TimeUnit timeUnit, double coldFactor) {
  super(stopwatch);

  //1.设置预热时间
  this.warmupPeriodMicros = timeUnit.toMicros(warmupPeriod); 

  //3.设置coldFactor为3
  this.coldFactor = coldFactor;
}

final void doSetRate(double permitsPerSecond, long nowMicros) {
  this.resync(nowMicros);
  // 如果QPS为5 则 stableIntervalMicros  = 1s/5 = 200ms
  double stableIntervalMicros = (double)TimeUnit.SECONDS.toMicros(1L) / permitsPerSecond;
  this.stableIntervalMicros = stableIntervalMicros;
  this.doSetRate(permitsPerSecond, stableIntervalMicros);
}


@Override
void doSetRate(double permitsPerSecond, double stableIntervalMicros) {
  double oldMaxPermits = maxPermits;

  //1.设置冷却期等待时间数值 coldIntervalMicros
  double coldIntervalMicros = stableIntervalMicros * coldFactor; 

  //2.设置冷却期的阈值，thresholdPermits 等于预热期产生令牌数的 一半 （4000000/200000 = 20 ， 20 * 0.5 = 10）
  thresholdPermits = 0.5 * warmupPeriodMicros / stableIntervalMicros;

  //3.设置持有令牌的最大值，为thresholdPermits的2倍 为20
  maxPermits = thresholdPermits + 2.0 * warmupPeriodMicros / (stableIntervalMicros + coldIntervalMicros);

  //4.设置预热区的斜率；纵坐标之差／横坐标之差 
  slope = (coldIntervalMicros - stableIntervalMicros) / (maxPermits - thresholdPermits);

  if (oldMaxPermits == Double.POSITIVE_INFINITY) {
    storedPermits = 0.0;
  } else {
    storedPermits = (oldMaxPermits == 0.0)
      ? maxPermits 
      : storedPermits * maxPermits / oldMaxPermits;
  }
}

```



#### 2.1.5.3、`storedPermitsToWaitTime`

> 前面说到，`SmoothWarmingUp` 和 `SmoothBursty` 的一个重要区别就在于 “获取当前令牌中可用令牌的等待时间”`storedPermitsToWaitTime` 方法, 而 “获取预支令牌的等待时间” 和之前一致。**

```java
@Override
long storedPermitsToWaitTime(double storedPermits, double permitsToTake) {

  //1.获取当前持有令牌数和阈值的差值availablePermitsAboveThreshold
  double availablePermitsAboveThreshold = storedPermits - thresholdPermits;
  long micros = 0;

  //2.如果availablePermitsAboveThreshold>0,即当前持有令牌数>阈值，即到达冷区期；计算等待时间
  if (availablePermitsAboveThreshold > 0.0) {

    //3.计算WARM UP PERIOD部分计算的方法，这部分是一个梯形，梯形的面积计算公式是 “（上底 + 下底） * 高 / 2”
    double permitsAboveThresholdToTake = min(availablePermitsAboveThreshold, permitsToTake);
    micros = (long) (permitsAboveThresholdToTake * (permitsToTime(availablePermitsAboveThreshold)
                                                    + permitsToTime(availablePermitsAboveThreshold - permitsAboveThresholdToTake)) / 2.0);

    //4.剩余的令牌从 stable部分拿
    permitsToTake -= permitsAboveThresholdToTake;
  }
  //5.stable 部分令牌获取花费的时间
  micros += (stableIntervalMicros * permitsToTake);
  return micros;
}
```



举个例子：创建限流器时 `create(5, 4000, TimeUnit.MILLISECONDS)`；预热了 20 个令牌

**场景1：当前持有 20 个令牌，请求一个令牌；需要等待的时间为**

![image-20220418182916589](/Users/healerjean/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20220418182916589.png)



**场景 2：当前持有 18 个令牌，请求 1 个令牌；需要等待的时间为：**

![image-20220418183026895](/Users/healerjean/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20220418183026895.png)



**场景3：当前持有 20 个令牌，一次性请求 11 个令牌；需要等待的时间为：**

![image-20220418183113660](/Users/healerjean/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20220418183113660.png)

**场景4：当前持有 10 个令牌，一次性请求 1 个令牌；需要等待的时间为：**

![image-20220418183133770](/Users/healerjean/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20220418183133770.png)



##### 2.1.5.4、小结

1、当 `storedPermits` -` thresholdPermits` = `availablePermitsAboveThreshold` > 0 （冷却期）且 `permitsToTake` < `availablePermitsAboveThreshold` 时，等待时间是 `WARM` `UP` `PERIOD` 中的一个梯形面积；**`permitsToTake` 是持有令牌中可用的数量**       

2、当 `storedPermits`   -  `thresholdPermits` = `availablePermitsAboveThreshold` > 0 （冷却期）且 `permitsToTake` > `availablePermitsAboveThreshold` 时，等待时间是 1+ （`permitsToTake` - `availablePermitsAboveThreshold`）* stable；即梯形 + 矩形的面积      

3、当 `storedPermits` - `thresholdPermits` = `availablePermitsAboveThreshold` < 0 时（稳定期），等待时间是 `permitsToTake` * `stable`；即矩形的面积      

4、当 `storedPermits` 等于 `0` 后，系统创建新的令牌后，获取等待时间的顺序为 4->2->1；即前文说的**当系统请求增多，图像会像左移动，直到 `storedPermits` 为 `0`。等待一段时间后，随着令牌的生成当系统进入 `cold` 阶段时，图像会向右移，直到 `storedPermits` 等于 `maxPermits`。是一个动态调整的过程。**

## 2.3、`RateLimiter` 流程总结

> 总结一下 `SmoothWarmingUp` 和 `SmoothBursty` 的创建和使用令牌的过程：     
>
> **1、`SmoothWarmingUp` 和 `SmoothBursty` 的最大区别就在于，“获取已持有令牌中可用令牌的等待时间” 不同，`SmoothBursty` 是直接返回的，`SmoothWarmingUp` 则是基于 “热身模型” 和 “冷却期”（即一段时间没有获取令牌，衡量指标：当前持有的令牌数量大于某个阈值）的机制进行动态调整（冷却期按照梯形区域返回，否则按照矩形区域返回）**       
>
> 2、预支令牌的等待时间算法一致，`waitTime`  =  预支令牌数量 * 生成一个令牌需要的时间（1/`QPS`）`SmoothWarmingUp` 为系统提供一种冷启动的可能，例如：某系统底层使用缓存中间件，假如没有 “热身”，突发流量很可能造成缓存击穿等问题；`WarmingUp` 让系统应对突发流量有一个 “渐进准备资源” 的过程，`Rhino` 使用的令牌桶的平滑限流，即` WarmingUp` 模式









# 3、基于漏桶的 `ngx_http_limit_req_module`

`nginx` 有两个限流模块，从 `github` 上 `clone` 代码，位置在 `nginx/src/http/modules` 目录下：

⬤ `ngx_http_limit_req_module.c` （`nginx` 的 `limit_req` 模块，用来 限制时间窗口内的平均速率）      

⬤ `ngx_http_limit_conn_module.c` （`nginx` 的 `limit_conn` 模块，用来限制并发连接数）        

两者都是按照 IP 或者域名限制的

## 3.1、核心思想

### 3.1.1、`ngx_http_limit_req_module` 限流核心思想：         

1、当用户第一次请求时，会新增一条记录（主要记录访问计数、访问时间、上次访问时间、剩余待处理请求），以客户端 IP 地址的 `hash `值作为 `key` 存储在红黑树中（快速查找）       

2、`limit_req` 根据配置的限流 `QPS` 数值，将 1 秒钟分层多个时间窗口；通过限制**单个时间窗口的请求量**来进行漏桶的恒定限流，该时间窗口等于 `1/QPS`，即**单个令牌的创建时间**         

3、限制的手段是通过比较 **相邻两次请求的时间间隔和单个令牌的创建时间** 来计算，属于一种 “惰性计算”       

4、`limit_req` 指定了一个 `burst` 来应对突发流量，即漏桶的容量 1000，默认不配置为 0（由于请求时间的精度是毫秒，这里 `1000` 是 `nginx` 单位换算使用的，相关的变量数值均 `1000`）        

5、`IP` 或者域名维度限流，因此是**一 `IP` 一个桶**        

通俗来讲：**就是创建一个令牌的时间，只能接收并处理一个请求，其他的排队或者直接丢弃**



## 3.2、漏桶算法实现

> 用户可能同时配置若干限流，因此对于 `HTTP` 请求，`nginx` 需要遍历所有限流策略，判断是否需要限流；`ngx_http_limit_req_lookup` 方法实现了漏桶算法，方法返回 3 种结果：

`NGX_BUSY`：请求速率超出限流配置，拒绝请求；      

`NGX_AGAIN`：请求通过了当前限流策略校验，继续校验下一个限流策略；     

`NGX_OK`：请求已经通过了所有限流策略的校验，可以执行下一阶段；     

`NGX_ERROR`：出错



当一个新请求进入` Nginx` 的限流流程大致如下：

1、计算当前请求 `IP` 地址 `hash` 值（`hash` 值相等后进而使用 `IP` 内容判断），在存放请求 `IP` 的红黑树中查找对应位置     

2、计算当前请求和上次请求时间 (保存在红黑树节点的 `value` 中) 的差值 ms     

3、根据公式 “**excess = lr->excess - ctx->rate \* ms / 1000 + 1000**” 计算（漏桶算法的核心）       

4、更新当前节点信息（上一次请求时间等），根据限流结果返回响应

##### 2.2.1、excess = lr->excess - ctx->rate * ms / 1000 + 1000

解释一下相关的变量：



| 变量        | 说明                                                         |
| ----------- | ------------------------------------------------------------ |
| `excess`    | 积压等待处理的请求数量（也就是桶中积压的令牌数量） 乘 1000（nginx 计算的时候单位换算乘 1000） |
| `ctx->rate` | 限流的速率乘 1000（例如：设置当前的 IP 限流速率为 5 / 秒，则 rate 等于 5000；乘 1000 是 Nginx 内部的单位换算）<br/>`ms` 是当前请求和上次成功请求时间的差值，单位毫秒 |



怎么理解这个表达式呢？
假设场景：

- case1: 当漏桶的令牌以恒定消费的周期为 T，若当前请求和上一次请求的时间间隔 ms 大于等于 T（即 ms 时间期间创造的令牌数量等于 1）；则桶中积压的令牌永远为 0
- case2: 当 ms 小于 T 时（即 ms 时间期间创造的令牌数量小于 1），筒中会逐渐积压令牌

ms / 1000 的意思是本次请求在 1s 中的占比，ctx->rate * ms / 1000 意思是这段时间可以流过的请求数
1000 代表当次请求，即为 1（nginx 计算的时候单位换算乘 1000）
lr->excess - ctx->rate * ms / 1000 + 1000：的意思就是 **当前积压令牌数 = 上次积压令牌数 - 这段时间可以产生的令牌数 + 本次请求（1 个令牌）**

**漏斗的本质：当 excess > limit->burst；即积压令牌 excess > 桶的最大容量，拒绝当前请求**

举个例子，假设：
lr->excess 初始化为 0*1000
burst（桶最大容量）为 0*1000
令牌产生周期为 T，请求如下图所示















![ContactAuthor](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/assets/img/artical_bottom.jpg)



<!-- Gitalk 评论 start  -->

<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">

<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script> 
<div id="gitalk-container"></div>    
 <script type="text/javascript">
    var gitalk = new Gitalk({
		clientID: `1d164cd85549874d0e3a`,
		clientSecret: `527c3d223d1e6608953e835b547061037d140355`,
		repo: `HealerJean.github.io`,
		owner: 'HealerJean',
		admin: ['HealerJean'],
		id: 'mqNeDsw2gjlyAofR',
    });
    gitalk.render('gitalk-container');
</script> 





<!-- Gitalk end -->




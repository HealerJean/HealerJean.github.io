---
title: 项目经验_之_服务器
date: 2020-01-01 03:33:00
tags: 
- Experience
category: 
- Experience
description: 项目经验_之_服务器
---

**前言**     

 Github：[https://github.com/HealerJean](https://github.com/HealerJean)         

 博客：[http://blog.healerjean.com](http://HealerJean.github.io)          



# 一、线程和进程

## 1、批处理操作系统

> **批处理操作系统**就是把一系列需要操作的指令写下来，形成一个清单，一次性交给计算机。用户将多个需要执行的程序写在磁带上，然后交由计算机去读取并逐个执行这些程序，并将输出结果写在另一个磁带上。       
>
> 批处理操作系统在一定程度上提高了计算机的效率，但是由于**批处理操作系统的指令运行方式仍然是串行的，内存中始终只有一个程序在运行**，后面的程序需要等待前面的程序执行完成后才能开始执行，而前面的**程序有时会由于I/O操作、网络等原因阻塞，导致CPU闲置所以批处理操作效率也不高**。





## 2、进程的提出

> 批处理操作系统的瓶颈在于内存中只存在一个程序，进程的提出，可以让内存中存在多个程序，每个程序对应一个进程，**进程是操作系统资源分配的最小单位。**       
>
> 1、`CPU` 采用时间片轮转的方式运行进程：       
>
> 2、`CPU` 为每个进程分配一个时间段，称作它的时间片。         
>
> 3、如果在时间片结束时进程还在运行，则暂停这个进程的运行，并且`CPU` 分配给另一个进程（这个过程叫做上下文切换）。             
>
> 4、如果进程在时间片结束前阻塞或结束，则 `CPU`立即进行切换，不用等待时间片用完。多进程的好处在于一个在进行`IO`操作时可以让出 `CPU` 时间片，让 `CPU` 执行其他进程的任务。





## 3、线程的提出

> 随着计算机的发展，对`CPU`的要求越来越高，进程之间的切换开销较大，已经无法满足越来越复杂的程序的要求了。于是就发明了线程，**线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元**，是处理器调度和分派的基本单位。**一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间(也就是所在进程的内存空间)。**



## 2、进程和线程的区别

进程是计算机中已运行程序的实体，进程是操作系统资源分配的最小单位。而线程是在进程中执行的一个任务，是`CPU`调度和执行的最小单位。他们两个本质的区别是是否**单独占有内存地址空间及其它系统资源（比如I/O）**：       

⬤ **进程单独占有一定的内存地址空间，所以进程间存在内存隔离，数据是分开的，数据共享复杂但是同步简单，各个进程之间互不干扰；而线程共享所属进程占有的内存地址空间和资源，数据共享简单，但是同步复杂**。      

⬤ 进程单独占有一定的内存地址空间，一个进程出现问题不会影响其他进程，不影响主程序的稳定性，可靠性高；**一个线程崩溃可能影响整个程序的稳定性，可靠性较低**。      

⬤ 进程单独占有一定的内存地址空间，进程的创建和销毁不仅需要保存寄存器和栈信息，还需要资源的分配回收以及页调度，开销较大；**线程只需要保存寄存器和栈信息，开销较小**。         

另外一个重要区别是，**进程是操作系统进行资源分配的基本单位，而线程是操作系统进行调度的基本单位，即CPU分配时间的单位** 。







# 二、`CPU` 和 `LOAD`

> ⬤  `load average` 表示的是 `CPU`的负载，包含的信息不是`CPU`的使用率状况，**而是在一段时间内 `CPU` 正在处理以及等待 `CPU ` 处理的进程数之和的统计信息，也就是是一段时间内正在使用和等待使用 `CPU` 的平均任务数。这个数字越小越好，`CPU` 利用率高，并不意味着负载就一定大**。            
>
> > **如果 `load average` 值长期大于系统 `CPU `的个数则说明`CPU`很繁忙，负载很高，可能会影响系统性能，导致系统卡顿响应时间长等等**。    
> >
> > 举例来说： 
> >
> > ◯ 如果我有一个程序它需要一直使用 `cpu` 的运算功能，那么此时 `cpu` 的使用率可能达到`100%`，但是 `cpu` 的工作负载则是趋近于 “1”，因为 `cpu`  仅负责一个工作嘛！             
> >
> > ◯ 如果同时执行这样的程序两个呢？`cpu` 的使用率还是 `100%` ，但是工作负载则变成`2`了。所以也就 是说，当`cpu`的工作负载越大，代表 `cpu` 必须要在不同的工作之间进行频繁的工作切换。



## 1、处理器

### 1）单核处理器的情况      

  　**行车过桥**：   **一只单核的处理器可以形象得比喻成一条单车道。**     

　　设想下，你现在需要收取这条道路的过桥费 ，忙于处理那些将要过桥的车辆。你首先当然需要了解些信息，例如车辆的载重、以及 还有多少车辆正在等待过桥。如果前面没有车辆在等待，那么你可以告诉后面的司机通过。 如果车辆众多，那么需要告知他们可能需要稍等一会。     

　　0.00 表示目前桥面上没有任何的车流，过往的车辆可以丝毫不用等待的通过。
　　1.00 表示刚好是在这座桥的承受范围内。 这种情况不算糟糕，只是车流会有些堵，不过这种情况可能会造成交通越来越慢。
　　超过 1.00，那么说明这座桥已经超出负荷，交通严重的拥堵。 那么情况有多糟糕? 例如 2.00 的情况说明车流已经超出了桥所能承受的一倍，那么将有多余过桥一倍的车辆正在焦急的等待。3.00 的话情况就更不妙了，说明这座桥基本上已经快承受不了，还有超出桥负载两倍多的车辆正在等待。

  　　上面的情况和处理器的负载情况非常相似。一辆汽车的过桥时间就好比是处理器处理某线程的实际时间。Unix 系统定义的进程运行时长为所有处理器内核的处理时间加上线程 在队列中等待的时间。    

　　**在实际情况中，有经验的系统管理员都会将这条线划在 0.70：所以你说的理想负荷为 1.00 ?”，负荷 1.00 说明系统已经没有剩余的资源了。 **       

　　“**需要进行调查法则**”： **如果长期你的系统负载在 0.70 上下**，那么你需要在事情变得更糟糕之前，花些时间了解其原因。     

　　“**现在就要修复法则**”：**1.00** 。 如果你的服务器系统负载长期徘徊于 1.00，那么就应该马上解决这个问题。否则，你将半夜接到你上司的电话，这可不是件令人愉快的事情。     

　　“**凌晨三点半锻炼身体法则**”：5.00。 如果你的服务器负载超过了 5.00 这个数字，那么你将失去你的睡眠，还得在会议中说明这情况发生的原因，总之千万不要让它发生。



### 3）多个处理器的情况

　　**那么多个处理器呢?我的均值是 3.00，但是系统运行正常!，你有四个处理器的主机？那么它的负载均值在 3.00 是很正常的**      

​		对于具有多个 `CPU` 核心的系统，`Load Avg`的值应该与 `CPU` 核心数相乘来理解。例如，在一个拥有 `4` 个 `CPU` 核心的系统上，如果`Load Avg`的值为 `4.0`，那么这通常表示系统的负载是平衡的，每个核心都在满负荷工作，但没有过载。如果这个值大于 `4.0`，比如`6.0`，那么表示系统平均有 `6.0` / `4` = `1.5`个进程在等待 `CPU` 资源，即系统可能处于过载状态。



### 3）多核与多处理器

　　我们来讨论下多核心处理器与多处理器的区别。从性能的角度上理解，**一台主机拥有多核心的处理器与另台拥有同样数目的处理器性能基本上可以认为是相差无几。当然实际情况会复杂得多**,　　**但即便这些因素造成的实际性能稍有不同，其实系统还是以处理器的核心数量计算负载均值** 。这使我们有了两个新的法则：     

　　核心分布在分别几个单个物理处理中并不重要，**其实两个四核的处理器 等于四个双核处理器 等于 八个单处理器。所以，它应该有八个处理器内核。** **<font color = "red">在多核处理中，你的系统均值不应该高于处理器核心的总数量。</font>**     



## 2、分析

> 一般能够被接受的值是 `load average` <=  `CPU核数`  * `0.7`。

　　<font color = "red">很多人会这样理解负载均值：三个数分别代表不同时间段的系统平均负载(一分钟、五 分钟、以及十五分钟)，它们的数字当然是越小越好。数字越高，说明服务器的负载越 大，这也可能是服务器出现某种问题的信号。  </font>    

　　**<font color = "red">而事实不完全如此，是什么因素构成了负载均值的大小，以及如何区分它们目前的状况是 “好”还是“糟糕”?什么时候应该注意哪些不正常的数值?</font>**          

　　**<font color = "red">最后一个问题，"load average"一共返回三个平均值----1分钟系统负荷、5分钟系统负荷，15分钟系统负荷，----应该参考哪个值？</font>**    

如果只有1分钟的系统负荷大于处理器内核，其他两个时间段都小于，这表明只是暂时现象，问题不大。      

如果15分钟内，平均系统负荷大于处理器内核，表明问题持续存在，不是暂时现象。所以，你**应该主要观察"15分钟系统负荷"，将它作为电脑正常运行的指标**。





# 三、`RSS`

> `RSS`（`Resident` `Set` `Size`）内存使用率表示的是一个进程在物理内存中实际占用的空间量。当限制堆内存的情况下，RSS内存使用率的最高值会受到多个因素的影响，包括但不限于以下几点：

**1、堆内存限制 直接因素：**首先，`RSS` 会包含 `JVM` （或其他运行时环境）为堆内存分配的物理内存。因此，如果堆内存被限制在某个特定大小（如通过 `JVM` 的 `-Xmx` 参数设置），那么这部分内存将是 `RSS` 的一个固定上限（或主要部分）。        

**2、非堆内存 间接因素：**`RSS` 不仅包含堆内存，还包含非堆内存区域（如方法区、线程栈、本地方法栈、直接内存等）以及JVM进程所需的其他操作系统资源（如内核栈、进程管理数据结构等）。这些非堆内存区域的大小也会影响RSS的总量。      

**3、线程数量 影响因素：**`JVM` 中线程的数量会直接影响 `RSS`，因为每个线程的栈都需要分配物理内存。因此，如果应用创建了大量的线程，即使堆内存被限制，`RSS` 也可能因为线程栈的增加而上升。    





**问题1：如果 `4C8G`，`-Xmx` 配置了 `6G` `RSS` 会最少是 `75` 吗？**

**答案：**在大多数情况下，当 `-Xmx` 设置为 `6G` 时，`JVM` 进程的RSS内存使用率会超过 `75%` 。然而，不意味着 `JVM` 进程在操作系统中实际占用的物理内存（即RSS内存）就恰好是 `6G`。在极少数特殊情况下（如非堆内存非常小、内存共享和重用、系统其他进程的内存使用等），`RSS` 内存使用率可能会低于 `75%` 。但请注意，这些情况在实际应用中较为罕见，且通常不会显著影响 `RSS` 的值。   







# 后：服务器问题

## 1、一台服务器最大能打开的文件数

### 1）限制参数

> 我们知道在 `Linux` 中一切皆文件，那么一台服务器最大能打开多少个文件呢？`Linux` 上能打开的最大文件数量受三个参数影响，分别是：

| 参数          | 级别 | 说明                                                         |
| ------------- | ---- | ------------------------------------------------------------ |
| `fs.file-max` | 系统 | 该参数描述了整个系统可以打开的最大文件数量。但是 `root` 用户不会受该参数限制（比如：现在整个系统打开的文件描述符数量已达到 `fs.file-max` ，此时 `root` 用户仍然可以使用 `ps`、`kill` 等命令或打开其他文件描述符） |
| `soft nofile` | 进程 | 限制单个进程上可以打开的最大文件数。只能在 `Linux` 上配置一次，不能针对不同用户配置不同的值 |
| `fs.nr_open`  | 进程 | 限制单个进程上可以打开的最大文件数。可以针对不同用户配置不同的值 |



**这三个参数之间还有耦合关系，所以配置值的时候还需要注意以下三点：**    

1、如果想加大 `soft nofile` ，那么 `hard nofile` 参数值也需要一起调整。如果因为 `hard` `nofile`参数值设置的低，那么`soft` `nofile` 参数的值设置的再高也没有用，实际生效的值会按照二者最低的来。    

2、如果增大了 `hard nofile`，那么 `fs.nr_open` 也都需要跟着一起调整（ `fs.nr_open` 参数值一定要大于 `hard nofile`参数值）。如果不小心把 `hard` `nofile` 的值设置的比 `fs.nr_open` 还大，那么后果比较严重。会导致该用户无法登录，如果设置的是*，那么所有用户都无法登录    

3、如果加大了 `fs.nr_open`，但是是用的 `echo "xxx" > ../fs/nr_open` 命令来修改的 `fs.nr_open` 的值，那么刚改完可能不会有问题，但是只要机器一重启，那么之前通过echo命令设置的fs.nr_open值便会失效，用户还是无法登录。**所以非常不建议使用echo的方式修改内核参数！！！**



### 2）调整服务器能打开的最大文件

> 假设想让进程可以打开 `100` 万个文件描述符，这里用修改 `conf` 文件的方式给出一个建议。如果日后工作里有类似的需求可以作为参考。

```sh
vim /etc/sysctl.conf
```

```sh
fs.file-max=1100000 // 系统级别设置成110万，多留点buffer
fs.nr_open=1100000 // 进程级别也设置成110万，因为要保证比 hard nofile大
```

**使上面的配置生效 `sysctl -p`**

```sh
vim /etc/security/limits.conf
```

```sh
// 用户进程级别都设置成100完
soft nofile 1000000
hard nofile 1000000
```



## 2、一台服务器最大能支持多少连接

> 我们知道 `TCP`连接，从根本上看其实就是 `client`  和 `server` 端在内存中维护的一组【`socket` 内核对象】（这里也对应着 `TCP`四元组：源 `IP`、源端口、目标 `IP`、目标端口），他们只要能够找到对方，那么就算是一条连接。那么一台服务器最大能建立多少条连接呢？   

**问题1：理论上能支持多少连接呢？**    

答案：理论值：由于 `TCP` 连接本质上可以理解为是 `client` - `server` 端的一对 `socket` 内核对象，那么从理论上将应该是【2^32 (ip数) * 2^16 (端口数)】条连接（约等于两百多万亿）    



**问题2：实际上能达到那么多的连接吗？**

答案：**实际值：但是实际上由于受其他软硬件的影响，我们一台服务器不可能能建立这么多连接（主要是受 `CPU` 和 内存限制）**。     



**问题3：那如果不传入数据，只建立连接能支持多少呢？**

答案：如果只以 `ESTABLISH` 状态的连接来算（这些连接只是建立，但是不收发数据也不处理相关的业务逻辑）那么一台服务器最大能建立多少连接呢？以一台 `4GB`内存的服务器为例！     

这种情况下，那么能建立的连接数量主要取决于【内存的大小】（因为如果是）`ESTABLISH` 状态的空闲连接，不会消耗 `CPU`（虽然有`TCP` 保活包传输，但这个影响非常小，可以忽略不计）       

我们知道一条 `ESTABLISH` 状态的连接大约消耗【`3.3KB`内存】，那么通过计算得知一台 `4GB` 内存的服务器，【可以建立 `100w+` 的 `TCP` 连接】（当然这里只是计算所有的连接都只建立连接但不发送和处理数据的情况，如果真实场景中有数据往来和处理（数据接收和发送都需要申请内存，数据处理便需要 `CPU` ），那便会消耗更高的内存以及占用更多的 `CPU`，并发不可能达到 `100w+`）    



**问题4：那建立连接后，又能支持多少呢？**

答案：上面讨论的都是进建立连接的理想情况，在现实中如果有频繁的数据收发和处理（比如：压缩、加密等），**那么一台服务器能支撑`1000` 连接都算好的了，所以一台服务器能支撑多少连接还要结合具体的场景去分析**，不能光靠理论值去算。抛开业务逻辑单纯的谈并发没有太大的实际意义。    

**最重要的是：服务器的开销大头往往并不是连接本身，而是每条连接上的数据收发，以及请求业务逻辑处理！！**！





## 3、一台客户端机器最多能发起多少条连接

**问题1：理论上能支持多少连接呢？**    

答案：我们知道客户端每和服务端建立一个连接便会消耗掉 `client` 端一个端口。一台机器的端口范围是【0 ~ 65535】，那么是不是说一台 `client` 机器最多和一台服务端机器建立 `65535` 个连接呢（这 `65535`个端口里还有很多保留端口，可用端口可能只有 `64000`个左右）？

**由 `TCP` 连接的四元组特性可知，只要四元组里某一个元素不同，那么就认为这是不同的 `TCP` 连接。所以需要分情况讨论**：    



【情况一】：如果一台 `client` 仅有一个 `IP`，`server` 端也仅有一个 `IP` 并且仅启动一个程序，监听一个端口的情况下，`client` 端和这台 `server` 端最大可建立的连接条数就是 `65535` 个。

原因：因为源 `IP` 固定，目标 `IP` 和端口固定，四元组中唯一可变化的就是【源端口】，【源端口】的可用范围又是【0 ~ 65535】，所以一台 `client` 机器最大能建立 `65535`个连接     



以现在的技术，给一个 `client` 分配多个 `IP` 是非常容易的事情，只需要去联系你们网管就可以做到。      

【情况二】：如果一台 `client`有多个`IP`（假设客户端有 `n` 个 `IP`），`server  `端仅有一个`IP`并且仅启动一个程序，监听一个端口的情况下，一台 `client` 机器最大能建立的连接条数是：`n`· * `65535` 个

原因：因为目标 `IP` 和端口固定，有 `n` 个源 `IP`，四元组中可变化的就是【源端口】+ 【源IP】，【源端口】的可用范围又是【0 ~ 65535】，所以一个`IP`最大能建立 `65535`个连接，那么 `n`个 `IP` 最大就能建立 `n` *`65535`个连接了     



【情况三】：如果一台 `client` 仅有一个 `IP`，`server` 端也仅有一个 `IP`  但是 `server` 端启动多个程序，每个程序监听一个端口的情况下（比如`server` 端启动了`m`个程序，监听了 `m` 个不同端口），一台 `client` 机器最大能建立的连接数量为：`65535` `* ` `m`   

原因：源 `IP` 固定，目标 `IP` 固定，目标端口数量为 `m`个，可变化的是源端口，而源端口变化范围是【0 ~ 65535】，所以一台 `client`机器最大能建立的 `TCP` 连接数量是 `6553` * `m`个     



其余情况类推，但是客户端的可用端口范围一般达不到 `65535`个，受内核参数 `net.ipv4.ip_local_port_range` 限制，如果要修改`client` 所能使用的端口范围，可以修改这个内核参数的值。      

所以，不光是一台 `server` 端可以接收 `100w+` 个 `TCP` 连接，一台 `client`照样能发出 `100w+`个连接



## 4、服务器连接其他问题

### 1）"`too many open files`" 报错是怎么回事，该如何解决

> 你在线上可能遇到过 `too many open files` 这个错误，那么你理解这个报错发生的原理吗？如果让你修复这个错误，应该如何处理呢？  **需要注意这三个参数之间的耦合关系！**   
>
> 1、因为每打开一个文件（包括 `socket`），都需要消耗一定的内存资源。为了避免个别进程不受控制的打开了过多文件而让整个服务器奔溃，`Linux` 对打开的文件描述符数量有限制。如果你的进程触发到内核的限制，那么" `too many open files`" 报错就产生了     
>
> 2、可以通过修改 `fs.file-max` 、`soft nofile`、`fs.nr_open` 这三个参数的值来修改进程能打开的最大文件描述符数量



### 2）一台服务端机器最大究竟能支持多少条连接

> 因为这里要考虑的是最大数，因此先不考虑连接上的数据收发和处理，仅考虑 `ESTABLISH` 状态的空连接。那么一台服务端机器上最大可以支持多少条 `TCP` 连接？这个连接数会受哪些因素的影响？    

1、在不考虑连接上数据的收发和处理的情况下，仅考虑 `ESTABLISH` 状态下的空连接情况下，一台服务器上最大可支持的TCP连接数量基本上可以说是由内存大小来决定的。        

2、四元组唯一确定一条连接，但服务端可以接收来自任意客户端的请求，所以根据这个理论计算出来的数字太大，没有实际意义。另外文件描述符限制其实也是内核为了防止某些应用程序不受限制的打开【文件句柄】而添加的限制。这个限制只要修改几个内核参数就可以加大。    

3、一个 `socket` 大约消耗 `3kb` 左右的内存，这样真正制约服务端机器最大并发数的就是内存，拿一台 `4GB` 内存的服务器来说，可以支持的 `TCP` 连接数量大约是 `100w+`



### 3）一条客户端机器最大究竟能支持多少条连接

> **和服务端不同的是，客户端每次建立一条连接都需要消耗一个端口**。在 `TCP` 协议中，端口是一个 `2` 字节的整数，因此范围只能是0~65535。那么客户端最大只能支持65535条连接吗？有没有办法突破这个限制，有的话有哪些办法？

1、客户度每次建立一条连接都需要消耗一个端口。从数字上来看，似乎最多只能建立 `65535`条连接。但实际上我们有两种办法破除`65535` 这个限制          

2、为客户端配置多 `IP` 方式二，分别连接不同的服务端          

3、 所以一台 `client`发起百万条连接是没有任何问题的



### 4）做一个长连接推送产品，支持1亿用户需要多少台机器

> 假设你是系统架构师，现在老板给你一个需求，让你做一个类似友盟 `upush` 这样的产品。要在服务端机器上保持一个和客户端的长连接，绝大部分情况下连接都是空闲的，每天也就顶多推送两三次左右。总用户规模预计是1亿。那么现在请你来评估一下需要多少台服务器可以支撑这1亿条长连接。

1、对于长连接推送模块这种服务来说，给客户端发送数据只是偶尔的，一般一天也就顶多一两次。绝大部分情况下 `TCP` 连接都是空闲的，`CPU` 开销可以忽略    

2、再基于内存来考虑，假设服务器内存是 `128G` 的，那么一台服务器可以考虑支持 `500w` 条并发。这样会消耗掉大约不到 `20GB` 内存用来保存这`500w` 条连接对应的 `socket` 。还剩下 `100GB` 以上的内存来应对接收、发送缓冲区等其他的开销足够了。所以，一亿用户，仅仅需要 `20`台服务器就差不多够用了！



















![ContactAuthor](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/assets/img/artical_bottom.jpg)



<!-- Gitalk 评论 start  -->

<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">

<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script> 
<div id="gitalk-container"></div>    
 <script type="text/javascript">
    var gitalk = new Gitalk({
		clientID: `1d164cd85549874d0e3a`,
		clientSecret: `527c3d223d1e6608953e835b547061037d140355`,
		repo: `HealerJean.github.io`,
		owner: 'HealerJean',
		admin: ['HealerJean'],
		id: '4xmPDKAZv25qyQNl',
    });
    gitalk.render('gitalk-container');
</script> 



<!-- Gitalk end -->




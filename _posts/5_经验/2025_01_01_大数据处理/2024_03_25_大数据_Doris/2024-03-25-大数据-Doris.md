---
title: 
date: 2025-01-01 00:00:00
tags: 
- 
category: 
- 
description: 
---

**前言**     

 Github：[https://github.com/HealerJean](https://github.com/HealerJean)         

 博客：[http://blog.healerjean.com](http://HealerJean.github.io)          



# 一、基本介绍

> `Apache` `Doris` 由百度大数据部研发（之前叫百度 `Palo`，`2018` 年贡献到 Apache 社区后， 更名为 `Doris` ），在百度内部，有超过 `200` 个产品线在使用，部署机器超过 `1000 台`，单一 业务最大可达到上百 `TB`。 `Apache` `Doris` 是一个现代化的 `MPP`（`Massively` `Parallel` `Processing`，即大规模并行处理）     

分析型（`OLAP`）数据库产品。**仅需亚秒级 （小于 1 秒但大于 1 微秒）响应时间即可获得查询结果**，有效地支持实时数据分析。     

`Apache` `Doris` 的分布式架构非常简洁，易于运维，并且可以支持 `10PB` 以上的超大数据集。

`Apache` `Doris` 可以满足多种数据分析需求，**例如固定历史报表，实时数据分析，交互式数据分析和探索式数据分析**等。

﻿

**1、典型场景：**

- **互联网用户行为分析**：某电商平台使用 `Doris` 存储 `10PB` 级用户点击、交易数据，通过分区（按日期）+ 分桶（按用户 `ID`）策略，将数据打散到 `500` + `BE` 节点，复杂多维分析（如按地域、时间、商品类目聚合）可在 `10` 秒内完成。
- **日志分析与监控**：某云计算厂商用 `Doris` 管理 `10PB` 级系统日志，通过 TTL 策略将热数据（近 `7` 天）存 `SSD`，冷数据（历史数据）转储 `HDFS`，结合向量化查询，亿级日志检索可在秒级返回。



# 二、架构

> `Doris` 的架构很简洁，只设 `FE` ( `Frontend` )前端进程、`BE` ( `Backend` )后端进程两种角色、两个后台的服务进程，不依赖于外部组件，方便部署和运维，`FE`、`BE` 都可在线性扩展。  采用**无中心节点（`Shared`-`Nothing`）的分布式架构**，核心组件仅包含两类节点，避免了复杂的多层级架构带来的运维复杂度：

## **1、极简的两层架构设计**

- `FE`（`Frontend`）：**负责元数据管理、查询解析与优化、任务调度执行，返回查询结果**。   主要有三个角色：   
  -  `Leader`  和 `Follower` ：主要是用来达到元数据的高可用，保证单节点宕机的情况下,元数据能够实时地在线恢复，而不影响整个服务。    
  -  `Observer`：用来扩展查询节点，同时起到元数据备份的作用，可随时动态增减，扩展集群读能力。如果在发现集群压力非常大的情况下，需要去扩展整个查询的能力，，那么可以加 `observer` 的节点。`observer` 不参与任何的写入，只参与读取。

- `BE`（`Backend`）：**负责物理数据的存储和计算**；依据 FE 生成的物理计划，分布式地执行查询。数据的可靠性由 `BE` 保证，`BE` 会对整个数据存储多副本或者是三副本。副本数可根据需求动态调整。

- `MySQL` `Client:Doris` 借助 `MySQL` 协议，用户使用任意 `MySQL` 的 `ODBC/JDBC` 以及 `MySQL` 的客户端，都可以直接访问 `Doris`。

- `Broker` 一个独立的无状态进程。封装了文件系统接口，提供 `Doris` 读取远端存储系统中文件的能力，包括 `HDFS`，`S3`，`BOS` 等。

﻿

## **2、去中心化的架构优势**

- **无中心节点瓶颈**：传统架构中 协调节点（如 `HDFS` 的 `NameNode`）易成为性能瓶颈，而 `Doris` 的 `FE` 仅处理元数据，`BE` 节点自主承担数据存储与计算，架构扩展性更强。
- **简化运维复杂度**：无需管理多层级组件（如 `Hadoop` 生态中的 `NameNode`、`ResourceManager` 等），部署与扩缩容可通过简单命令完成（如添加 `BE` 节点自动触发数据重平衡）。



## **3**、支持 `10PB` 级数据的技术核心

### 1）**高效的数据分片与存储引擎**

#### a、**列式存储与分层压缩**

- 数据按列存储，配合字典编码、前缀压缩、位图索引等技术，压缩比可达 `10:1`~`20:1`，`10PB`  原始数据压缩后实际存储量可降至 `0.5PB` ~ `1PB`。
- 支持数据生命周期管理（`TTL` ），冷热数据自动分层存储（如热数据存 `SSD`，冷数据存 `HDD` 或对象存储），降低存储成本。

#### **b、分布式分片与副本机制**

- 数据按表分区（`Partition`）和分桶（`Bucket`）打散到多个 `BE` 节点，每个分片支持多副本（默认 `3` 副本），通过一致性哈希算法保证数据均衡分布。
- 新增 `BE` 节点时，系统自动触发数据重平衡，无需人工干预，确保存储与计算资源线性扩展。



### **2）向量化执行引擎与并行计算能力**

#### a、**向量化执行引擎**：

将传统的行处理模式改为列批处理（`Batch` `Processing`），单指令可处理一批数据（如 `1024` 行），`CPU` 缓存利用率提升 `300%` 以上，查询性能较传统数据库提升 `10`~`100` 倍。



#### b、**分布式并行计算**

- 查询任务自动拆分为多个子任务，分发到所有 `BE` 节点并行执行，利用集群全部计算资源（如 `1000` 个 `BE` 节点可提供数万核计算能力）。
- 支持 `MPP`（大规模并行处理）架构，复杂查询（如 `JOIN`、聚合）可在秒级至分钟级完成，满足 `10PB` 级数据的实时分析需求。



### **3）智能查询优化与缓存机制**

#### a、**`CBO`（成本优化器）**：

- 根据数据统计信息（如列基数、数据分布）自动生成最优查询计划，避免低效执行路径（如小表广播`JOIN`、大表分区裁剪）。

#### b、多级缓存策略

- `FE` 层缓存元数据与查询计划，`BE` 层缓存热点数据块与计算结果，减少重复 `IO` 与计算开销。
- 支持结果集缓存，相同查询可直接返回缓存结果，响应时间降至毫秒级。



## **4、易运维性的具体体现**

### **1）自动化的集群管理**

- **一键部署与扩缩容**：通过 `Ansible` 等工具可批量部署节点，新增 `BE` 节点时数据自动重平衡，无需停机或手动迁移数据。
- **故障自动恢复**：`BE` 节点故障时，系统自动从副本节点恢复数据，`FE` 节点通过 `Raft` 协议自动选举主节点，保证服务可用性。



### **2）统一的 `SQL` 接口与生态集成**

- **兼容 `MySQL `协议**：支持标准 `SQL` 语法，应用程序可直接通过 `JDBC/ODBC` 连接，无需学习新语言，降低迁移成本。
- **无缝对接大数据生态**：支持从 `Hive`、`Kafka`、`S3` 等数据源导入数据，结果可导出至 BI 工具（如 `Superset`、`Tableau`），简化数据链路运维。



### **3）可视化监控与诊断工具**

- 内置 `Admin` `Tool` 与 `WebUI`，实时监控集群负载、节点状态、查询性能等指标，支持慢查询分析与告警配置，运维人员可快速定位问题。



## 5、总结：**架构设计与能力的逻辑闭环**

`Apache` `Doris` 的分布式架构通过 “极简分层 + 去中心化” 降低运维复杂度 ，借助 “列式存储 + 向量化计算” 提升单机存储与计算效率，再通过 “分布式并行 + 自动化管理” 实现集群能力线性扩展，最终形成从单节点到 10PB 级集群的完整技术链路。这种设计既满足了企业对超大规模数据存储的需求，又通过架构简洁性降低了运维成本，使其在数据分析场景中具备较强的竞争力。



# 三、数据表设计

| 类型                          | 长度           | 范围                                                         |
| ----------------------------- | -------------- | ------------------------------------------------------------ |
| `INYINT`                      | 1 字节         | 范围：-2^7 + 1 ~ 2^7 - 1                                     |
| `SMALLINT`                    | 2 字节         | 范围：-2^15 + 1 ~ 2^15 - 1                                   |
| `INT`                         | 4 字节         | 范围：-2^31 + 1 ~ 2^31 - 1                                   |
| `BIGINT`                      | 8 字节         | 范围：-2^63 + 1 ~ 2^63 - 1                                   |
| `LARGEINT`                    | 16 字节        | 范围：-2^127 + 1 ~ 2^127 - 1                                 |
| `FLOAT`                       | 4 字节         | 支持科学计数法                                               |
| `DOUBLE`                      | 12 字节        | 支持科学计数法                                               |
| `DECIMAL[(precision, scale)]` | 16 字节        | 保证精度的小数类型。默认是DECIMAL(10, 0) ，precision: 1 ~ 27 ，scale: 0 ~ 9，其中整数部分为 1 ~ 18，不支持科学计数法 |
| `DATE`                        | 3 字节         | 范围：0000-01-01 ~ 9999-12-31                                |
| `DATETIME`                    | 8 字节         | 范围：0000-01-01 00:00:00 ~ 9999-12-31 23:59:59              |
| `CHAR[(length)]`              |                | 定长字符串。长度范围：1 ~ 255。默认为 1                      |
| `VARCHAR[(length)]`           |                | 变长字符串。长度范围：1 ~ 65533                              |
| `BOOLEAN`                     |                | 与 TINYINT 一样，0 代表 false，1 代表 true                   |
|                               |                |                                                              |
| `HLL`                         | 1~16385 个字节 | hll 列类型，不需要指定长度和默认值,长度根据数据的聚合程度系统内控制，并且 HLL 列只能通过 配套的 hll_union_agg、Hll_cardinality、hll_hash 进行查询或使用 |
| `BITMAP`                      |                | `bitmap` 列类型，不需要指定长度和默认值。表示整型的集合，元素最大支持到 2^64 - 1 |
| `STRING`                      |                | 变长字符串，0.15 版本支持，最大支持 2147483643 字节（2GB-4），长度还受 `be` 配置`string_type_soft_limit`, 实际能存储的最大长度取两者最小值。只能用在 `value` 列，不能用在 `key` 列和分区、分桶列 |



## 1、**`Row` & `Column`** 

> 一张表包括行（`Row`）和列（`Column`）；   
>
> - `Row` 即用户的一行数据。`Column` 用于描述一行数据中不同的字段。      
> - `doris` 中的列分为两类：`key` 列和 `value` 列   
>   -  `key` 列在 `doris` 中有两种作用：聚合表模型中，`key` 是聚合和排序的依据。其他表模型中，`key` 是排序依据



## **2、分区与分桶**

- `partition`（分区）：是在逻辑上将一张表按行 (横向) 划分

- `table`（又叫 `bucket`，分桶）：在物理上对一个分区再按行(横向)划分

![image-20250527143423539](/Users/zhangyujin1/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20250527143423539.png)

## **3、`Partition`**

- `Partition` 列可以指定一列或多列，在聚合模型中，分区列必须为 `KEY` 列。

- 不论分区列是什么类型，在写分区值时，都需要加双引号。

- 分区数量理论上没有上限。

- 当不使用 `Partition` 建表时，系统会自动生成一个和表名同名的，全值范围的 `Partition`。该 `Partition` 对用户不可见，并且不可删改。

- 创建分区时不可添加范围重叠的分区。



**问题1：复合分区与单分区的选择 ：**

复合分区 第一级称为 `Partition`，即分区。用户可以指定某一维度列作为分区列（当前只支持整型和时间类型的列），并指定每个分区的取值范围。第二级称为 `Distribution`，即分桶。用户可以指定一个或多个维度列以及桶数对数据进行 `HASH` 分布。  以下场景推荐使用复合分区有时间维度或类似带有有序值的维度，可以以这类维度列作为分区列。分区粒度可以根据导入频次、分区数据量等进行评估。地域、时间历史数据删除需求：如有删除历史数据的需求（比如仅保留最近 `N` 天的数据）。使用复合分区，可以通过删除历史分区来达到目的。也可以通过在指定分区内发送 `DELETE` 语句进行数据删除。    

改善数据倾斜问题：每个分区可以单独指定分桶数量。如按天分区，当每天的数据量差异很大时，可以通过指定分区的分桶数，合理划分不同分区的数据,分桶列建议选择区分度大的列。用户也可以不使用复合分区，即使用单分区。则数据只做 `HASH` 分布。





### **1）`Range` 分区**

> `range` 分区创建语法

```sql
-- Range Partition
drop table if exists test.expamle_range_tbl;
CREATE TABLE IF NOT EXISTS test.expamle_range_tbl
(
    `user_id` LARGEINT NOT NULL COMMENT "用户id",
    `date` DATE NOT NULL COMMENT "数据灌入日期时间",
    `timestamp` DATETIME NOT NULL COMMENT "数据灌入的时间戳",
    `city` VARCHAR(20) COMMENT "用户所在城市",
    `age` SMALLINT COMMENT "用户年龄",
    `sex` TINYINT COMMENT "用户性别"
)

ENGINE=OLAP
DUPLICATE KEY(`user_id`, `date`) -- 表模型

-- 分区的语法
PARTITION BY RANGE(`date`) -- 指定分区类型和分区列
(
    -- 指定分区名称，分区的上界   前闭后开
    PARTITION `p201701` VALUES LESS THAN ("2017-02-01"), 
    PARTITION `p201702` VALUES LESS THAN ("2017-03-01"),
    PARTITION `p201703` VALUES LESS THAN ("2017-04-01")
)
DISTRIBUTED BY HASH(`user_id`) BUCKETS 1;
```





![image-20250527144103298](/Users/zhangyujin1/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20250527144103298.png)

![image-20250527144047418](/Users/zhangyujin1/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20250527144047418.png)





![image-20250527144033840](/Users/zhangyujin1/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20250527144033840.png)



### 2）`List` 分区

> 分区列支持 `BOOLEAN`,  `TINYINT` ,  `SMALLINT` , `INT` ,  `BIGINT` , `LARGEINT` ,  `DATE`,`DATETIME` , `CHAR`, `VARCHAR` 数据类型，分区值为枚举值。只有当数据为目标分区枚举值其中之一时，才可以命中分区。   
>
> `Partition` 支持通过 `VALUES` `IN` (...) 来指定每个分区包含的枚举值。

```sql
- List Partition

CREATE TABLE IF NOT EXISTS test.expamle_list_tbl
(
    `user_id` LARGEINT NOT NULL COMMENT "用户id",
    `date` DATE NOT NULL COMMENT "数据灌入日期时间",
    `timestamp` DATETIME NOT NULL COMMENT "数据灌入的时间戳",
    `city` VARCHAR(20) NOT NULL COMMENT "用户所在城市",
    `age` SMALLINT NOT NULL COMMENT "用户年龄",
    `sex` TINYINT NOT NULL COMMENT "用户性别",
    `last_visit_date` DATETIME REPLACE DEFAULT "1970-01-01 00:00:00" COMMENT "用户最后一次访问时间",
    `cost` BIGINT SUM DEFAULT "0" COMMENT "用户总消费",
    `max_dwell_time` INT MAX DEFAULT "0" COMMENT "用户最大停留时间",
    `min_dwell_time` INT MIN DEFAULT "99999" COMMENT "用户最小停留时间"
)

ENGINE=olap
AGGREGATE KEY(`user_id`, `date`, `timestamp`, `city`, `age`, `sex`)

PARTITION BY LIST(`city`)
(
    PARTITION `p_cn` VALUES IN ("Beijing", "Shanghai", "Hong Kong"),
    PARTITION `p_usa` VALUES IN ("New York", "San Francisco"),
    PARTITION `p_jp` VALUES IN ("Tokyo")
)


-- 指定分桶的语法
DISTRIBUTED BY HASH(`user_id`) BUCKETS 1
PROPERTIES
(
    "replication_num" = "3"
);
```



#### **a、增加一个分区**

```sql
p_cn: ("Beijing", "Shanghai", "Hong Kong")
p_usa: ("New York", "San Francisco")
p_jp: ("Tokyo")
当我们增加一个分区 p_uk VALUES IN ("London")，分区结果如下：


p_cn: ("Beijing", "Shanghai", "Hong Kong")
p_usa: ("New York", "San Francisco")
p_jp: ("Tokyo")
p_uk: ("London")
```

#### **b、删除一个分区**

```sql
当我们删除分区 p_jp，分区结果如下：

p_cn: ("Beijing", "Shanghai", "Hong Kong")
p_usa: ("New York", "San Francisco")
p_uk: ("London")
```



#### **c、`List` 分区也支持多列分区，示例如下**

```sql
PARTITION BY LIST(`id`, `city`)
(
    PARTITION `p1_city` VALUES IN (("1", "Beijing"), ("2", "Shanghai")),
    PARTITION `p2_city` VALUES IN (("2", "Beijing"), ("1", "Shanghai")),
    PARTITION `p3_city` VALUES IN (("3", "Beijing"), ("4", "Shanghai"))
)
在以上示例中，我们指定 id(INT 类型) 和 city(VARCHAR 类型) 作为分区列。以上示例最终得到的分区如下：

* p1_city: [("1", "Beijing"), ("1", "Shanghai")]
* p2_city: [("2", "Beijing"), ("2", "Shanghai")]
* p3_city: [("3", "Beijing"), ("3", "Shanghai")]


当用户插入数据时，分区列值会按照顺序依次比较，最终得到对应的分区。举例如下：
* 数据  --->  分区
* 1, Beijing     ---> p1_city
* 1, Shanghai    ---> p1_city
* 2, Shanghai    ---> p2_city
* 3, Beijing     ---> p3_city
* 1, Tianjin     ---> 无法导入
* 4, Beijing     ---> 无法导入
```





## 4、**`Bucket`**

**1、`Bucket` 数量：分桶应该控制桶内数据量 ，不易过大或者过小  **单个 `Tablet`  的数据量理论上没有上下界，但建议在 `1G` - `10G` 的范围内。 

- 如果单个 `Tablet` 数据量过小，则数据的聚合效果不佳，且元数据管理压力大。    

- 如果数据量过大，则不利于副本的迁移、补齐，且会增加 `Schema` `Change` 或者 `Rollup` 操作失败重试的代价（这些操作失败重试的粒度是 `Tablet`）。

2、当 `Tablet` 的数据量原则和数量原则冲突时，建议优先考虑数据量原则。     

3、在建表时，每个分区的 `Bucket` 数量统一指定。但是在动态增加分区时（`ADD` `PARTITION`），可以单独指定新分区的 `Bucket` 数量。可以利用这个功能方便的应对数据缩小或膨胀。      





4、一个 `Partition` 的 `Bucket` 数量一旦指定，不可更改。所以在确定 `Bucket` 数量时，需要预先考虑集群扩容的情况。比如当前只有 `3` 台 `host`，每台 `host` 有 `1` 块盘。如果 `Bucket` 的数量只设置为 3 或更小，那么后期即使再增加机器，也不能提高并发度。

举例：假设在有`10` 台 `BE` ，每台 `BE` 一块磁盘的情况下。 ==> 总共有多少个磁盘数量  （表的数据量可以通过 SHOW DATA命令查看，结果除以副本数，即表的数据量。）

按照数据量分区：

| 单表总大小 | 分片数量建议                                               |
| ---------- | ---------------------------------------------------------- |
| `500MB`    | 4 - 8                                                      |
| `5G`       | 8-16                                                       |
| `50G`      | 32                                                         |
| `500GB`    | 每个分区大小在 `50GB` 左右，每个分区 `16` - `32` 个分片。  |
| `5TB`：    | 每个分区大小在 `500GB` 左右，每个分区 `16` - `32` 个分片。 |



## 5、`PROPERTIES`

> 在建表语句的最后，可以用 `PROPERTIES` 关键字来设置一些表的属性参数（参数有很多）

```
PROPERTIES(
  "参数名" = "参数值"
)
```



### 1）`replication_num`

> 每个 `Tablet` 的副本数量。默认为 `3`，建议保持默认即可。在建表语句中，所有 `Partition` 中的  `Tablet` 副本数量统一指定。而在增加新分区时，可以单独指定新分区中 `Tablet` 的副本数量。 

- **副本数量可以在运行时修改。强烈建议保持奇数。** 

- **最大副本数量取决于集群中独立 `IP` 的数量（注意不是 `BE` 数量）**。

`Doris` 中副本分布的原则是，不允许同一个 `Tablet` 的副本分布在同一台物理机上，而识别物理机即通过` IP`。所以，即使在同一台物理机上部署了 `3` 个或更多 `BE` 实例，如果这些 `BE` 的 `IP` 相同，则依然只能设置副本数为 1。 

对于一些小，并且更新不频繁的维度表，可以考虑设置更多的副本数。这样在 `Join` 查询时，可以有更大的概率进行本地数据` Join`。 



### 2）存储介质 和 热数据冷却时间

`storage_medium`、`storage_cooldown_time datetime`

默认初始存储介质可通过 `fe` 的配置文件 `fe.conf` 中指定 `default_storage_medium=xxx` , 如果没有指定，则默认为 `HDD`。如果指定为 `SSD`，则数据初始存放在 `SSD` 上。没设 `storage_cooldown_time`，则默认 `30` 天后，数据会从 `SSD` 自动迁移到 `HDD`上。如果指定了` storage_cooldown_time`，则在到达 `storage_cooldown_time` 时间后，数据才会迁移。

建表时，可以统一指定所有 `Partition` 初始存储的介质及热数据的冷却时间，如：

```
"storage_medium" = "SSD" 
"storage_cooldown_time" = "2023-04-20 00:00:00" 要在当前时间之后，并且是一个datetime类型 
```



# 四、数据标模型

> **`Doris` 的数据模型主要分为3类:**

| **对比维度**                         | **`UNIQUE` 模型**                                  | **`Aggregate` 模型**                          | **`Duplicate` 模型**                         |
| ------------------------------------ | -------------------------------------------------- | --------------------------------------------- | -------------------------------------------- |
| **核心特性**                         | 主键唯一性约束，REPLACE 语义                       | 预聚合统计，`SUM`/`COUNT` 等聚合函数支持      | 全量保留数据，无聚合逻辑                     |
| **适用场景**                         | 维度表、实时明细表、需唯一标识的场景               | 固定维度统计报表、历史数据趋势分析            | 灵活维度查询、明细数据追溯                   |
| **数据更新支持**                     | 支持主键冲突时部分字段更新                         | 仅支持追加聚合（如 SUM 累增），不支持单条更新 | 不支持自动更新，需全量重写                   |
| **查询性能**                         | 主键查询效率高（可走主键索引），复杂聚合需全量扫描 | 预聚合查询效率高，灵活维度查询效率低          | 列存优势支持按需读列，灵活查询效率高         |
| **存储成本**                         | 与原始数据量接近（无聚合压缩）                     | 存储成本低（聚合压缩后）                      | 存储成本高（全量保留）                       |
| **高效处理多表 Join 和复杂维度分析** | Unique Key（实时更新场景）                         | 优先选择 **Aggregate Key（实时聚合场景）**    | Duplicate Key 适合明细查询，但 Join 性能较弱 |



**选择建议**

- 若需求为 **固定模式的统计报表**，优先选**Aggregate**模型，利用预聚合提升查询效率。
- 若数据需 **唯一主键约束 **且需维护最新状态，选**Uniq**模型（如用户、订单主数据）。
- 若查询维度 **灵活多变**（如 BI 分析、临时查询），选**Duplicate**模型，发挥列存按需读列的优势。



## 1、`Aggregate` 模型

> 是 **相同 `key`** 的 数据进行**自动聚合**的表模型。表中的列按照是否设置了 `AggregationType`，分为 `Key`（维度列）和 `Value`（指标列），没有设置 `AggregationType` 的称为 `Key`，设置了 `AggregationType` 的称为 `Value`。当我们导入数据时，对于 `Key` 列相同的行会聚合成一行，而 `Value` 列会按照设置的 `AggregationType` 进行聚合。`AggregationType` 目前有以下四种聚合方式： 

| 聚合方式              | 说明                                                         |
| --------------------- | ------------------------------------------------------------ |
| `SUM`                 | 求和，多行的 `Value` 进行累加。                              |
| `REPLACE`             | 替代，下一批数据中的 `Value` 会替换之前导入过的行中的 `Value`。 |
| `REPLACE_IF_NOT_NULL` | 当遇到 null 值则不更新。                                     |
| `MAX`                 | 保留最大值                                                   |
| `MIN`                 | 保留最小值。                                                 |

### **1）核心特性**：

- **预聚合机制**：在数据写入时按指定维度（`Key` 列）进行预聚合（如 `SUM`、COUNT 等），将相同维度的数据聚合为一条记录。
- **数据压缩**：通过预聚合减少数据量，降低存储成本和查询时的扫描开销。
- **查询优势**：对固定模式的报表类查询（如按时间、地域分组的统计）效率极高，无需扫描全量数据即可直接返回聚合结果。

### **2）适用场景**：

- 固定维度的统计报表（如日活、销售额按地区汇总）。
- 历史数据的趋势分析（如按月 / 季度的指标同比、环比）。

### **3）优缺点**：

- **优势**：查询性能显著提升，存储效率高。
- **局限**：若查询维度超出预聚合范围（如临时新增分组维度），需扫描全量数据，性能可能下降。



### 4）案例

有如下场景：需要创建一个表，来记录公司每个用户的每一次消费行为信息，有如下字段

| 用户id | 数据插入日期 | 城市 | 年龄 | 性别 | 访问时间            | 每次消费金额 | 用户的停留时长                                               |
| ------ | ------------ | ---- | ---- | ---- | ------------------- | ------------ | ------------------------------------------------------------ |
| 10000  | 2017/10/1    | 北京 | 20   | 0    | 2017/10/01 06:00:00 | 20           | 10                                                           |
| 10000  | 2017/10/1    | 北京 | 20   | 0    | 2017/10/01 07:00:00 | 15           | 2                                                            |
| 10000  | 2017/10/1    | 北京 | 20   | 0    | 2017/10/01 08:00:00 | 30           | 15                                                           |
| 10001  | 2017/10/1    | 北京 | 30   | 1    | 2017/10/01 17:05:45 | 2            | 22 而且，公司对这份数据，特别关心一个报表   每一个用户最后一次访问我们页面的时间，用户消费的总金额，用户停留在我们页面上的最大最小时长 |

```sql
Select
    user_id,data,city,age,gender,
    max(visit_data) as last_visit_data,
    sum(cost) as cost,
    max(dwell_time) as max_dwell_time,
    min(dwell_time) as min_dwell_time
From  t
Group by  user_id,data,city,age,gender  -- 对应的是聚合模型型key
```



| 用户id | 数据插入日期 | 城市 | 年龄 | 性别 | 最后一次访问的时间  | 该用户的总消费额 | 该用户的最大停留时长 | 该用户的最小停留时长                                |
| ------ | ------------ | ---- | ---- | ---- | ------------------- | ---------------- | -------------------- | --------------------------------------------------- |
| 10000  | 2017/10/1    | 北京 | 20   | 0    | 2017/10/01 08:00:00 | 65               | 15                   | 2                                                   |
| 10001  | 2017/10/1    | 北京 | 30   | 1    | 2017/10/01 17:05:45 | 2                | 22                   | 22                                                  |
|        |              |      |      |      |                     |                  |                      | 每次要看这个报表，都需要在“明细表”上运行一个统计sql |



```sql
-- 这是一个用户消费和行为记录的数据表
CREATE TABLE IF NOT EXISTS test.ex_user
(
 `user_id` LARGEINT NOT NULL COMMENT "用户 id",
 `date` DATE NOT NULL COMMENT "数据灌入日期时间",
 `city` VARCHAR(20) COMMENT "用户所在城市",
 `age` SMALLINT COMMENT "用户年龄",
 `sex` TINYINT COMMENT "用户性别",
 
 `last_visit_date` DATETIME REPLACE  DEFAULT "1970-01-01 00:00:00" COMMENT "用户最后一次访问时间",
 `cost` BIGINT SUM DEFAULT "0" COMMENT "用户总消费",
 `max_dwell_time` INT MAX DEFAULT "0" COMMENT "用户最大停留时间",
 `min_dwell_time` INT MIN DEFAULT "99999" COMMENT "用户最小停留时间" 
 )
ENGINE=olap
AGGREGATE KEY(`user_id`, `date`, `city`, `age`, `sex`)
-- 分区
-- 分桶
DISTRIBUTED BY HASH(`user_id`) BUCKETS 1;
```

数据的聚合，在 `Doris` 中有如下三个阶段发生：

1.每一批次数据导入的 `ETL` 阶段。该阶段会在每一批次导入的数据内部进行聚合。

2.底层 `BE` 进行数据 `Compaction` 的阶段。`BE` 会对已导入的不同批次的数据进行进一步的聚合。

3.数据查询阶段。在数据查询时，对于查询涉及到的数据，会进行对应的聚合。





## 2、**`UNIQUE` 模型**

> 是**相同 `key`**的数据进行**自动去重**的表模型。在某些多维分析场景下，用户更关注的是如何保证 `Key` 的唯一性，即如何获得 `Primary` `Key` 唯一性约束。因此，引入了 `Uniq` 的数据模型。该模型本质上是聚合模型的一个特例，也是一种简化的表结构表示方式。

### **1）核心特性**：

- **主键唯一性**：以指定列作为唯一主键，新数据写入时若主键冲突，会替换旧记录（本质为 `REPLACE` 操作）。
- **聚合限制**：不支持 `SUM`、`COUNT`  等聚合操作，仅保证主键唯一性，无法利用 `ROLLUP` 等预聚合优化。



### **2）适用场景**：

- 需唯一标识记录的场景（如用户信息表、订单主表）。
- 数据需实时更新且保证最新状态（如用户画像、设备状态追踪）。
- **与 `Aggregate` 模型结合使用**：在维度表使用 `UNIQUE` 保证唯一性，在事实表使用 `Aggregate` 进行统计聚合，通过 `JOIN` 实现 “唯一维度 + 聚合事实” 的分析场景。



#### **a、维度表与字典表的唯一性保障**

- **场景**：用户信息表（用户 ID 为主键）、商品维度表（商品 SKU 为主键）、地区维度表（地区编码为主键）。

- 优势：

  - 确保维度数据唯一性，避免因重复主键导致的分析误差（如同一用户 ID 对应不同姓名）。
  - 支持实时更新维度属性（如用户修改手机号），通过主键冲突触发数据替换，保证维度表实时性。

- **案例**：电商平台的商品维度表，使用 `UNIQUE` 模型以 `SKU` 为主键，当商品价格、库存更新时，新数据自动覆盖旧数据，确保下游报表查询到最新商品信息。

  

#### **b、需要唯一标识的实时明细表**

- **场景**：订单详情表（订单 `ID` 为主键）、用户行为明细表（用户 `ID` + 行为时间戳为主键）。
- 优势
  - 保证每条记录的唯一性，避免重复数据干扰（如同一订单被多次导入）。
  - 支持部分字段更新（如订单状态从 “待支付” 更新为 “已支付”），无需全量更新记录。
- **注意**：与 `Duplicate` 模型相比，`UNIQUE`  模型在数据重复时会自动去重，而 `Duplicate` 会保留所有记录，因此 `UNIQUE` 更适合 “每条记录必须唯一” 的场景。



#### **c、实时数据同步与增量更新**

- 在 `CDC`（变更数据捕获）场景中，`UNIQUE` 模型可直接对接上游数据库（如 `MySQL`）的主键约束，通过 `Doris` 的 **`Stream Load`** 或 **`Spark Load`**  实现增量数据的实时同步，确保数据一致性。
- **案例**：将 `MySQL` 中的用户表同步至 `Doris` 时，以用户 `ID` 为 `UNIQUE` 主键，当 `MySQL` 中用户信息更新时，`Doris` 自动替换旧记录，避免手动去重。



#### **d、优缺点**：

- **优势**：确保数据唯一性，适合需要维护最新状态的场景。
- **局限**：查询时无法利用预聚合加速，且需读取所有 `Key` 列，列存优势受限。



#### e、案例

```sql
drop table if exists test.user;
CREATE TABLE IF NOT EXISTS test.user
(
-- key列
 `user_id` LARGEINT NOT NULL COMMENT "用户 id",
 `username` VARCHAR(50) NOT NULL COMMENT "用户昵称",
 -- value列
 `city` VARCHAR(20) COMMENT "用户所在城市",
 `age` SMALLINT COMMENT "用户年龄",
 `sex` TINYINT COMMENT "用户性别",
 `phone` LARGEINT COMMENT "用户电话",
 `address` VARCHAR(500) COMMENT "用户地址",
 `register_time` DATETIME COMMENT "用户注册时间"
  )
UNIQUE KEY(`user_id`, `username`)
DISTRIBUTED BY HASH(`user_id`) BUCKETS 1;



insert into test.user values
(10000,'zss','北京',18,0,12345678910,'北京朝阳区 ','2017-10-01 07:00:00'),\
(10000,'zss','北京',19,0,12345678910,'北京顺义区 ','2018-10-01 07:00:00'),\
(10000,'lss','北京',20,0,12345678910,'北京海淀区','2017-11-15 06:10:20');


insert into test.user1 values
(10000,'zss','北京',18,0,12345678910,'北京朝阳区 ','2017-10-01 07:00:00'),\
(10000,'zss','北京',19,0,12345678910,'北京顺义区 ','2018-10-01 07:00:00'),\
(10000,'lss','北京',20,0,12345678910,'北京海淀区','2017-11-15 06:10:20');
```

查询结果后发现，`select *  from user` 相同的数据就会被替换掉，

`unique` 模型完全可以用聚合模型中的 `REPLACE` 方式替代。其内部的实现方式和数据存储方式也完全一样。







## 3、**`Duplicate` 模型**

> 就是存**明细数据的表模型**，既不做聚合也不做去重。在某些多维分析场景下，数据既没有主键，也没有聚合需求。`Duplicate` 数据模型可以满足这类需求。数据完全按照导入文件中的数据进行存储，不会有任何聚合。即使两行数据完全相同，也都会保留。 而在建表语句中指定的 `DUPLICATE` `KEY`，只是用来指明底层数据按照那些列进行排序。 



### **1）核心特性**：

- **无聚合约束**：数据按原始格式存储，不进行预聚合，每条记录独立存在。
- **列存优势**：查询时仅读取所需列，而非全部 `Key` 列，适合多维度灵活查询。
- **灵活性**：支持任意维度的组合查询，不受预聚合模型限制。



### **2）适用场景**：

- 多维分析（如用户行为分析中临时组合时间、渠道、用户标签等维度）。
- 探索性查询（需频繁变更查询条件的场景）。



### **3）优缺点**：

- **优势**：查询维度灵活，列存效率高（按需读列）。
- **局限**：无预聚合优化，大规模数据查询时扫描量较大，性能依赖列存索引。



### 4）案例

```sql
CREATE TABLE IF NOT EXISTS test.log_detail
(
 `timestamp` DATETIME NOT NULL COMMENT "日志时间",
 `type` INT NOT NULL COMMENT "日志类型",
 `error_code` INT COMMENT "错误码",
 `error_msg` VARCHAR(1024) COMMENT "错误详细信息",
 `op_id` BIGINT COMMENT "负责人 id",
 `op_time` DATETIME COMMENT "处理时间" 
 )
DUPLICATE KEY(`timestamp`, `type`) -- 为啥他还要分key列和value列   排序
DISTRIBUTED BY HASH(`timestamp`) BUCKETS 1;
```

插入部分数据

```sql
insert into test.log_detail values
('2017-10-01 08:00:05',1,404,'not found page', 101, '2017-10-01 08:00:05'),
('2017-10-01 08:00:05',1,404,'not found page', 101, '2017-10-01 08:00:05'),
('2017-10-01 08:00:05',2,404,'not found page', 101, '2017-10-01 08:00:06'),
('2017-10-01 08:00:06',2,404,'not found page', 101, '2017-10-01 08:00:07');
```

查询结果后发现，插入的数据全部会被保留，即使两条数据一模一样，也会保留，这种表模型可以用来存储业务系统的数据过程数据；





# 五、问题递进

## 1、**为什么不能直接替换 `MySQL`**

### **1）核心优势场景**

- **海量数据分析**：10PB 级存储 + 亚秒级查询（聚合 / OLAP 场景），适合数据仓库、BI 报表、实时分析。
- **`MySQL` 协议兼容**：无缝对接现有 MySQL 生态工具（如 Navicat、Sqlyog），降低迁移成本。
- **极简架构**：无复杂组件依赖（对比 Hadoop 生态），运维成本低，适合快速迭代的业务。

### **2）不可忽视的边界**

- **事务支持有限**：仅支持单表主键唯一性约束，不支持跨表事务（对比 `MySQL` `InnoDB`）。
- **非结构化数据处理弱**：无法直接处理文档、图片等非结构化数据（需预处理）。
- **实时写入性能瓶颈**：高并发小批量写入（如每秒 10 万 + 单条记录）时效率低于专用实时系统（存储原因导致）。

| 维度         | MySQL（OLTP）                 | Apache Doris（OLAP）           |
| ------------ | ----------------------------- | ------------------------------ |
| **数据模型** | 行存为主，支持复杂事务和索引  | 列存为主，面向分析场景优化     |
| **写入模式** | 支持实时增删改（`ACID` 保障） | 批量导入为主（支持分区级更新） |
| **查询场景** | 低延迟单条 / 小批量数据查询   | 大规模聚合、多维度分析查询     |
| **典型场景** | 订单系统、用户中心等核心业务  | 订单统计报表、用户行为分析     |



## 2、和 `mysql` 正确协同方式是什么？

**1、正确的协同方式：`MySQL` 处理实时交易，`Doris` 负责历史数据聚合分析，通过中间件同步数据。**

```
业务系统（MySQL） → 数据同步（Canal/MaxCompute） → Doris（分析层）
```

**2、读写分离优化：**高频查询（如最近 `7` 天数据）仍由 `MySQL` 承担，历史数据（>30 天）迁移至 `Doris` 降低 `MySQL` 负载。



## 3、**`Doris` 与 `ES` / ``HBase`**

### 1）**对比 `Elasticsearch`（`ES`）**

- **`ES` 的不可替代性**：
  - **全文检索**：分词、模糊查询、相关性排序（如电商搜索、日志分析）。
  - **半结构化数据**：`JSON` 文档灵活存储（如用户画像标签、传感器数据）。
  - **实时数据流处理**：配合 `Logstash` / `Kafka` 实现秒级索引更新。
- **`Doris` 的适配场景**：
  - **当 `ES` 查询变慢时**：`Doris`可承接 `ES` 中聚合分析需求（如 “按地区统计搜索频次”），`ES` 专注全文检索。
  - **多维度分析**：`ES` 擅长 “找数据”，`Doris` 擅长 “算数据”，两者结合实现 “搜索 + 分析” 闭环。

| 维度         | `Elasticsearch`                            | `Apache` `Doris`                               |
| ------------ | ------------------------------------------ | ---------------------------------------------- |
| **数据存储** | 倒排索引（适合检索）+ 列式存储（部分版本） | 列式存储（按列压缩，分析场景优化）             |
| **计算引擎** | 单节点串行计算为主（可分布式但协调开销大） | 向量化执行引擎 + 分布式 `MPP` 架构（并行计算） |
| **聚合优化** | 依赖分片合并，易出现 “热分片”              | 分区裁剪 + 谓词下推 + 聚合下推，减少数据扫描量 |
| **典型场景** | **数据量较小（亿级以下）+ 简单聚合**       | **海量数据 + 复杂聚合**                        |
|              | **聚合结果需与检索条件强绑定**             | **多表关联聚合**                               |
|              |                                            | **需要 `SQL` 兼容与生态工具**                  |



### 2）**对比 `HBase`**

- **`HBase` 的核心能力**：

  - **超大规模稀疏数据**：`PB` 级非结构化数据存储（如物联网设备日志、用户行为轨迹）。
  - **高并发随机读写**：支持每秒百万级单条记录读写（如实时推荐系统的特征存储）。
  - **灵活 `schema`**：列族设计支持动态添加列（适合快速迭代的业务）。

- **`Doris` 与 `HBase` 的协同**：

  - `HBase` 存储原始数据，`Doris` 作为分析层：

  ```plaintext
  设备数据 → HBase（实时写入） → 定期同步至Doris（离线分析）
  ```

  - **`HBase` + `Doris` 联合查询**：通过外表功能（`Doris` `1.2`+）直接查询 `HBase` 数据，避免数据冗余。



### 3）**真实场景中的技术组合案例**

#### a、**电商平台架构**

> **`Doris` 的角色**：承接 `Flink` 计算结果，提供多维度分析（如 “按地域 + 时间 + 商品类目统计 `GMV`”）。

```
[业务层] MySQL（订单交易） + Redis（缓存）
[实时层] Kafka（数据流） + Flink（实时计算） + ES（商品搜索）
[分析层] Doris（用户行为分析、订单统计） + Hive（离线数仓）
[存储层] HBase（用户画像标签） + 对象存储（图片/视频）
```



#### b、**日志分析场景**

> `ES` 快速定位具体日志，`Doris` 提供趋势分析，两者互补。

```
日志采集 → Kafka → Flink（清洗） → 双写：
  - ES（实时检索）
  - Doris（聚合分析，如“按小时统计错误日志占比”）
```









![ContactAuthor](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/assets/img/artical_bottom.jpg)



<!-- Gitalk 评论 start  -->

<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">

<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script> 
<div id="gitalk-container"></div>    
 <script type="text/javascript">
    var gitalk = new Gitalk({
		clientID: `1d164cd85549874d0e3a`,
		clientSecret: `527c3d223d1e6608953e835b547061037d140355`,
		repo: `HealerJean.github.io`,
		owner: 'HealerJean',
		admin: ['HealerJean'],
		id: 'AAAAAAAAAAAAAAAAAA',
    });
    gitalk.render('gitalk-container');
</script> 



<!-- Gitalk end -->




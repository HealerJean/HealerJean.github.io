---
title: 大数据Doris之_12_查询加速
date: 2025-03-25 00:00:00
tags: 
- BigData
- Doris
category: 
- BigData
- Doris
description: 数据Doris之_12_查询加速
---

**前言**     

 Github：[https://github.com/HealerJean](https://github.com/HealerJean)         

 博客：[http://blog.healerjean.com](http://HealerJean.github.io)          



# 一、查询缓存

> `Doris` 的 `SQL` `Cache` 是一种通过缓存查询结果来加速重复查询的机制，其核心设计目标是**减少重复计算**和**降低网络传输开销**。它通过**`FE`（`Frontend`）与 `BE`（`Backend`）协同工作**，结合**一致性哈希**和**元数据版本校验**实现高效缓存。以下从**BE 实现原理**和**FE 实现原理**两方面展开说明。



## 1、原理



### **1）`FE`（Frontend）实现原理**

> `FE` 是查询的入口，负责缓存的**元数据管理**和**路由控制**，其核心逻辑是**通过元数据版本校验决定是否复用缓存**。

#### **a、 缓存元数据管理**

- 元数据存储：FE 内存中维护一个 `Map<SQLHash, QueryMeta>` 结构，记录已执行查询的元信息：
  - **`SQLHash`**：`SQL` 字符串的哈希值（用于快速匹配）。
  - **`QueryMeta`**：包含查询涉及的表列表、表版本号、分区版本号、参数列表等。
- **元数据同步**：`FE` 会定期与 `BE` 同步表版本信息，确保缓存有效性。



#### **b、 查询路由流程**

**步骤1：`SQL` 匹配与元数据校验**

1. 收到查询请求后，计算 `SQL` 的 `SQLHash`。
2. 在 `FE` 内存的 `Map`中查找 `SQLHash`：
   - **未找到**：执行完整查询流程（解析、优化、下发到 BE）。
   - 找到：检查 `QueryMeta`中的表版本和分区版本是否与当前一致：
     - **不一致**：说明数据已变更，执行完整查询流程。
     - **一致**：进入步骤 2（缓存路由）。可跳过解析和优化

**步骤2：缓存路由与结果返回**

1. 根据 `QueryMeta` 中的 `CacheKey` 通过一致性哈希定位到目标 `BE`。
2. 向目标 `BE` 发送缓存检索请求：
   - **`BE` 命中缓存**：直接返回 `CachedResult`，FE 封装后响应客户端。
   - **`BE` 未命中缓存**：执行完整查询流程，并将结果写入 `BE` 缓存。



### **2）`BE`（`Backend`）实现原理**

> `BE` 是实际执行查询并存储缓存结果的节点，其缓存机制的核心是**内存中的 `HashMap` 结构**，结合**一致性哈希**实现缓存的分布式存储与快速检索。

#### **a、 缓存存储结构**

- 数据结构：`BE` 使用 `HashMap<CacheKey, CachedResult>`存储缓存结果，其中：
  - **`CacheKey`**：由查询的 `SQL` 字符串、参数（如 `LIMIT` 值）、表版本号、分区版本号等元数据通过哈希算法生成。
  - **`CachedResult`**：存储查询结果数据（如 `ResultSet`）及结果元信息（如数据大小、过期时间）。
- **存储位置**：缓存数据存放在 `BE` 的**堆内存**中，受 `mem_limit` 参数限制（默认无上限，需监控避免 `OOM`）。



#### **b、 一致性哈希定位**

- 哈希算法：当 `FE` 发起查询时，会根据 `SQL` 的 `CacheKey`通过一致性哈希算法选择一个` BE` 节点存储或检索缓存。

  - **目的**：确保相同查询的缓存始终落在同一 `BE`，避免分布式缓存一致性问题。

  - 示例：

    ```java
    // 伪代码：一致性哈希选择BE
    int beId = consistentHash(cacheKey) % beNodeCount;
    ```

#### **c、 缓存读写流程**

**写入缓存（`Query` `Execution` `Aftermath`）**

1. `BE` 执行查询后，将结果封装为 `CachedResult`。
2. 计算当前查询的 `CacheKey`（包含表版本、分区版本等）。
3. 通过一致性哈希定位到目标 `BE`（可能是自身或其他节点）。
4. 将 `(CacheKey, CachedResult)` 存入目标 `BE` 的 `HashMap`。



**读取缓存（`Query` `Execution` `Beginning`）**

1. 收到查询请求后，计算 `CacheKey`。
2. 通过一致性哈希定位到目标 `BE`。
3. 在目标 `BE` 的 `HashMap`中查找 `CacheKey`：
   - **命中**：直接返回 `CachedResult`，跳过执行计划。
   - **未命中**：执行完整查询流程，并将结果写入缓存。



#### **d、 缓存失效机制**

- 表/分区变更

  ：当表或分区的数据变更时，其版本号会递增。此时：

  - 旧版本的 `CacheKey` 会失效（因包含旧版本号）。
  - 后续查询会重新计算并写入新缓存。

- 手动清理：通过 `ADMIN CLEAR CACHE` 命令强制清理缓存：

  ```sql
  ADMIN CLEAR CACHE FOR TABLE db_name.table_name;
  ```



## 2、缓存管理

### 1）开启和关闭 `SQL` `Cache`

```sql
-- 在当前 Session 打开 SQL Cache, 默认是关闭状态
set enable_sql_cache=true;
-- 在当前 Session 关闭 SQL Cache
set enable_sql_cache=false;

-- 全局打开 SQL Cache, 默认是关闭状态
set global enable_sql_cache=true;
-- 全局关闭 SQL Cache
set global enable_sql_cache=false;
```



### 2）检查查询是否命中 `SQL` `Cache`

用户能够通过执行`explain plan`语句检查当前查询是否能够成功命中 SQL Cache，当查询计划树中出现`LogicalSqlCache`或`PhysicalSqlCache`节点时，即表明查询已命中 `SQL` `Cache`



### 3）内存控制

#### a、`FE` 内存控制

> 在 `FE` 中，`Cache` 的元数据信息被设置为弱引用。当 `FE` 内存不足时，系统会自动释放最近最久未使用的 `Cache` 元数据。此外，用户还可以通过执行以下 `SQL` 语句，进一步限制 `FE` 内存的使用量。此配置实时生效，且每个 `FE` 都需要进行配置。若需持久化配置，则需将其保存在 `fe.conf` 文件中。

```sql
-- 最多存放 100 个 Cache 元数据，超过时自动释放最近最久未使用的元数据。默认值为 100。  
ADMIN SET FRONTEND CONFIG ('sql_cache_manage_num'='100');  
  
-- 当 300 秒未访问该 Cache 元数据后，自动进行释放。默认值为 300。  
ADMIN SET FRONTEND CONFIG ('expire_sql_cache_in_fe_second'='300');
```

另外还可以在 `FE` 中配置，当结果行数或大小超过某个阈值时，不创建 SQL Cache：

```sql
-- 默认超过 3000 行结果时，不创建 SQL Cache。  
ADMIN SET FRONTEND CONFIG ('cache_result_max_row_count'='3000');  
  
-- 默认超过 30M 时，不创建 SQL Cache。  
ADMIN SET FRONTEND CONFIG ('cache_result_max_data_size'='31457280');
```



#### b、`BE` 内存控制 

> 在 `be.conf `文件中进行以下配置更改，重启 `BE` 后生效：

```sql
-- 当 Cache 的内存空间超过 query_cache_max_size_mb + query_cache_elasticity_size_mb 时，  
-- 释放最近最久未使用的 Cache，直至占用内存低于 query_cache_max_size_mb。  
query_cache_max_size_mb = 256  
query_cache_elasticity_size_mb = 128
```



### 4）排查缓存失效原因

1. 表/视图的结构发生了变化，例如执行了 `drop table`、`replace table`、`alter table` 或 `alter view` 等操作。
2. 表数据发生了变化，例如执行了 `insert`、`delete`、`update` 或 `truncate` 等操作。
3. 用户权限被移除，例如执行了 `revoke` 操作。
4. 使用了非确定函数，并且函数的评估值发生了变化，例如执行了 `select random()`。
5. 使用了变量，并且变量的值发生了变化，例如执行了 `select * from tbl where dt = @dt_var`。
6. Row Policy 或 Data Masking 发生了变化，例如设置了用户对某些表的部分数据不可见。
7. 结果行数超过了 FE 配置的 `cache_result_max_row_count`，默认值为 3000 行。
8. 结果大小超过了 FE 配置的 `cache_result_max_data_size`，默认值为 30MB。

## 3、关键特性

#### **a、缓存粒度控制**

- **细粒度缓存**：缓存基于完整的 SQL 字符串、参数和元数据版本，确保相同语义的查询复用缓存。
- **避免缓存雪崩**：通过一致性哈希分散缓存压力，避免单个 `BE` 内存过载。



#### **b、 缓存一致性保障**

- **强一致性**：通过表版本和分区版本校验，确保缓存与数据实时一致。
- **自动失效**：数据变更时自动淘汰旧缓存，无需手动干预。



#### **c、性能优化**

- **减少解析开销**：`FE` 跳过 `SQL` 解析和优化阶段，直接路由到 `BE`。
- **降低网络传输**：`BE` 本地缓存结果，避免重复计算和数据传输。



#### **d、适用场景与限制**

- 适用场景：
  - 重复查询频繁（如仪表盘、定时报表）。
  - 查询结果数据量小（缓存内存占用低）。
  - 数据变更不频繁（缓存命中率高）。
- 限制：
  - **高并发写入场景**：频繁的数据变更会导致缓存频繁失效，降低命中率。
  - **超大结果集**：缓存会占用大量 `BE` 内存，可能引发 OOM。
  - **复杂查询**：包含 `UDF`、`SUBQUERY` 的查询可能无法命中缓存（因 `CacheKey` 难以精确匹配）。























![ContactAuthor](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/assets/img/artical_bottom.jpg)



<!-- Gitalk 评论 start  -->

<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">

<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script> 
<div id="gitalk-container"></div>    
 <script type="text/javascript">
    var gitalk = new Gitalk({
		clientID: `1d164cd85549874d0e3a`,
		clientSecret: `527c3d223d1e6608953e835b547061037d140355`,
		repo: `HealerJean.github.io`,
		owner: 'HealerJean',
		admin: ['HealerJean'],
		id: 'U8HO0M49wF7L2zxA',
    });
    gitalk.render('gitalk-container');
</script> 





<!-- Gitalk end -->




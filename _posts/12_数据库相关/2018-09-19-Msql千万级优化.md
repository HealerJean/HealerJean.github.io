---
title: Msql千万级优化
date: 2018-09-19 03:33:00
tags: 
- Database
category: 
- Database
description: Msql千万级优化
---
**前言**     

 Github：[https://github.com/HealerJean](https://github.com/HealerJean)         

 博客：[http://blog.healerjean.com](http://HealerJean.github.io)          



# 1、分页查询优化

## 1.1、数据准备

```sql
CREATE TABLE `demo_entity`
(
    `id`      bigint(20) NOT NULL AUTO_INCREMENT,
    `name`    varchar(128)        DEFAULT NULL,
    `age`     bigint(20)          DEFAULT '0',
    `country` varchar(50)         DEFAULT NULL,
    `a`   varchar(20)         DEFAULT NULL,
    `b`   varchar(20)         DEFAULT NULL,
    `c`   varchar(20)         DEFAULT NULL,
    `d`   varchar(20)         DEFAULT NULL,
    `e`   varchar(20)         DEFAULT NULL,
    `f`   varchar(20)         DEFAULT NULL,
    `g`   varchar(20)         DEFAULT NULL,
    `h`   varchar(20)         DEFAULT NULL,
    `i`   varchar(20)         DEFAULT NULL,
    `j`   varchar(20)         DEFAULT NULL,
    `k`   varchar(20)         DEFAULT NULL,
    `l`   varchar(20)         DEFAULT NULL,
    `m`   varchar(20)         DEFAULT NULL,
    `n`   varchar(20)         DEFAULT NULL,
    `o`   varchar(20)         DEFAULT NULL,
    `p`   varchar(20)         DEFAULT NULL,
    `q`   varchar(20)         DEFAULT NULL,
    `r`   varchar(20)         DEFAULT NULL,
    `s`   varchar(20)         DEFAULT NULL,
    `t`   varchar(20)         DEFAULT NULL,
    `u`   varchar(20)         DEFAULT NULL,
    `v`   varchar(20)         DEFAULT NULL,
    `w`   varchar(20)         DEFAULT NULL,
    `x`   varchar(20)         DEFAULT NULL,
    `y`   varchar(20)         DEFAULT NULL,
    `z`   varchar(20)         DEFAULT NULL,
    `cdate`   timestamp  NOT NULL DEFAULT CURRENT_TIMESTAMP,
    `udate`   timestamp  NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    PRIMARY KEY (`id`)
) ;



create procedure aa()
begin
  DECLARE i INT DEFAULT 1;
  SET AUTOCOMMIT=0;
    WHILE (i <= 10000000) DO
    INSERT INTO demo_entity
    (name, age, country, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u,
     v, w, x, y, z)
    VALUES (concat('name',i ), i, concat('country',i ) , ROUND(10*rand()), ROUND(10*rand()), ROUND(100*rand()), ROUND(100*rand()), ROUND(1000*rand()), ROUND(1000*rand()), ROUND(1000*rand()), ROUND(10000*rand()), ROUND(10000*rand()), ROUND(100000*rand()), ROUND(100000*rand()), ROUND(100000*rand()), ROUND(1000000*rand()), ROUND(10000000*rand()), ROUND(10000000*rand()), ROUND(100000000*rand()), ROUND(10000000000*rand()), ROUND(10000000000*rand()), ROUND(100000000*rand()),
            '1', '1', '1', '1', '1', '1', '1');
    SET i = i + 1;
    END WHILE;
  SET AUTOCOMMIT=1;
end;

call aa(); 


```



## 1.2、问题SQL

> 解释：表中的字段越多下面的优化越明显，否则即使使用了下面的优化，也可能没有那么明显   
>
> 通过下面的可以观察到 当达到1000万的时候，查询时间到了37s，太可怕了    
>

```sql
select * from tb_ams_inf_repay_stat limit 0,10 ; 
#  0.003s

select * from tb_ams_inf_repay_stat  limit 10000,10 ;  
# 1万 0.023s

select * from tb_ams_inf_repay_stat  limit 100000,10 ;
# 10万 0.191s

select * from tb_ams_inf_repay_stat limit 1000000,10 ;
# 100万 1.942s

select * from tb_ams_inf_repay_stat limit 10000000,10 ;
# 1000万 37.323s

```

### 1.2.1、简单优化

#### 1.2.1.1、方法1（子查询）

> 0.23s 简直要飞起来了

```sql
0.23s 

select *
from tb_ams_inf_repay_stat
where id > (select id from tb_ams_inf_repay_stat limit 1000000, 1)
limit 0,10 ;


--推荐使用 
select * from table where id>243800 order by id limit 10;
```



**原理：**      

   **1、先使用覆盖索引index查询 ，我们只查询id索引这一个字段，比`select * ` 或者多个字段快多了，因为只要我们写上这些字段，我们只需要10个，但是从第一条开始到 1000万条其实是都要去扫描的**     

**2、然后再进行索引范围内range查询** 


<table border="1" style="border-collapse:collapse">
<tr><th>id</th><th>select_type</th><th>table</th><th>type</th><th>possible_keys</th><th>key</th><th>key_len</th><th>ref</th><th>rows</th><th>Extra</th></tr>
<tr><td>1</td><td>PRIMARY</td><td>tb_ams_inf_repay_stat</td><td>range</td><td>PRIMARY</td><td>PRIMARY</td><td>8</td><td>NULL</td><td>3258410</td><td>Using where</td></tr>
<tr><td>2</td><td>SUBQUERY</td><td>tb_ams_inf_repay_stat</td><td>index</td><td>NULL</td><td>idx_orgcd_loannum</td><td>216</td><td>NULL</td><td>19753500</td><td>Using index</td></tr></table>


#### 1.2.1.2、方法2（Join连接）

#### 1.3.2、优化2: 0.31  jon

```sql
SELECT *
FROM tb_ams_inf_repay_stat a
       JOIN (select id from tb_ams_inf_repay_stat limit 1000010, 10) b ON a.ID = b.id
```

<table border="1" style="border-collapse:collapse">
<tr><th>id</th><th>select_type</th><th>table</th><th>type</th><th>possible_keys</th><th>key</th><th>key_len</th><th>ref</th><th>rows</th><th>Extra</th></tr>
<tr><td>1</td><td>PRIMARY</td><td>&lt;derived2&gt;</td><td>ALL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>1000020</td><td>NULL</td></tr>
<tr><td>1</td><td>PRIMARY</td><td>a</td><td>eq_ref</td><td>PRIMARY</td><td>PRIMARY</td><td>8</td><td>b.id</td><td>1</td><td>NULL</td></tr>
<tr><td>2</td><td>DERIVED</td><td>tb_ams_inf_repay_stat</td><td>index</td><td>NULL</td><td>idx_orgcd_loannum</td><td>216</td><td>NULL</td><td>19753500</td><td>Using index</td></tr></table>


## 1.3、其他优化

### 1.3.1、带有条件的，id连续的查询（between）

```sql
0.03s 
select * from tb_ams_inf_repay_stat  where id  between 1000000 and 1000010  	 ;
```

### 1.3.2、带有条件，id不连续的查询，考虑建立索引

```sql
20s 慢死了
select * from tb_ams_inf_repay_stat  	where org_cd = 'xmsd'  	limit 1000000,10 ;
```

```java
-- org_cd建立索引

select *
from tb_ams_inf_repay_stat
where org_cd = 'xmsd'
  and id > (select id from tb_ams_inf_repay_stat where org_cd = 'xmsd' limit 1000000,1)
limit 0,10 ;

0.2s 可以说相当的快了 
```




<table>
<tr><th>id</th><th>select_type</th><th>table</th><th>type</th><th>possible_keys</th><th>key</th><th>key_len</th><th>ref</th><th>rows</th><th>Extra</th></tr>
<tr><td>1</td><td>PRIMARY</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>~~~~</td></tr>
<tr><td>2</td><td>SUBQUERY</td><td>tb_ams_inf_repay_stat</td><td>ref</td><td>idx_orgcd_loannum</td><td>idx_orgcd_loannum</td><td>93</td><td>const</td><td>1</td><td>Using where; Using index</td></tr></table>


### 1.3.2、 是否有必要进行left join查询

```
from scf_credit_bill  cb
left join scf_user_company credit on  cb.ref_credit_company_id = credit.id
left join scf_user_company core on  cb.ref_core_company_id = core.id
left join scf_user_company buyer on cb.buyer_company_id = buyer.id
left join scf_user_company seller on cb.seller_company_id = seller.id
```



项目中遇到一种情况，有一个表要和另外一张表做4从Join查询，比如我们要的`scf_credit_bill` 的行数有100行, 虽然要每行有4个字段是 `scf_user_company `中的，但是 `scf_user_company `  只需要50个id就够了，我们没有必要每次都要对这100行做leftjoin查询，因为这样会查询 100 * 4 = 400 次，而其实我们只要50个，那么解决方法是

```java
select * from scf_credit_bill 

查询池涉及企业
 List<Long> idList = 
Stream.concat(
	data.stream().map(CreditBill::getRefCoreCompanyId), 			
    data.stream().map(CreditBill::getRefCreditCompanyId))
.collect(Collectors.toList());
           
Map<Long,String > companyName = companyService.queryCompanyNameList(idList);


//让遍历data，讲取出对应的值再放入
```





# 2、Mysql慢查询

>  MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过`long_query_time`值的SQL，则会被记录到慢查询日志中。`long_query_time`的默认值为10，意思是运行10S以上的语句。慢查询日志支持将日志记录写入文件，也支持将日志记录写入数据库表。       
>
> **默认情况下，Mysql数据库并不启动慢查询日志，需要我们手动来设置这个参数，当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。**



## 2.1、慢查询日志相关参数

MySQL 慢查询的相关参数解释：   

`long_query_time` ：慢查询阈值，当查询时间多于设定的阈值时，记录日志。



`slow_query_log`  ：是否开启慢查询日志，1表示开启，0表示关闭。     



`slow-query-log-file`：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件`host_name-slow.log`      



`log_queries_not_using_indexes`：未使用索引的查询也被记录到慢查询日志中（可选项）。



`log_outpu`t：日志存储方式。   

`log_output='FILE'`表示将日志存入文件，默认值是`'FILE'`。   

`log_output='TABLE`'表示将日志存入数据库，这样日志信息就会被写入到`mysql.slow_log`表中。    

MySQL数据库支持同时两种日志存储方式，配置的时候以逗号隔开即可，如：`log_output='FILE,TABLE'`。**日志记录到系统的专用日志表中，比记录到文件耗费更多的系统资源**，**因此对于需要启用慢查询日志，又需要能够获得更高的系统性能，那么建议优先记录到文件。**

 



## 2.2、慢查询日志配置

### 2.2.1、查看慢查询是否开启以及日志目录 

> 使用`set global slow_query_log=1`开启了慢查询日志只对当前数据库生效，如果MySQL重启后则会失效。    
>
> 如果要永久生效，就必须修改配置文件`my.cnf`（其它系统变量也是如此）。例如如下所示：  

```sql
mysql>  show variables  like '%slow_query_log%';
+------------------------------------+-------------------------------+
| Variable_name                      | Value                         |
+------------------------------------+-------------------------------+
| slow_query_log                     | ON                            |
| slow_query_log_always_write_time   | 10.000000                     |
| slow_query_log_file                | /home/work/mysql/log/slow.log |
| slow_query_log_timestamp_always    | OFF                           |
| slow_query_log_timestamp_precision | second                        |
| slow_query_log_use_global_control  |                               |
+------------------------------------+-------------------------------+
6 rows in set (0.02 sec)

mysql> 
```



### 2.2.2、查看慢查询时间  

> 默认情况下`long_query_time`的值为10秒，可以使用命令修改，也可以在my.cnf参数里面修改。关于运行时间正好等于long_query_time的情况，并不会被记录下来。也就是说，在mysql源码里是判断大于`long_query_time`，而非大于等于。    
>
> 从`MySQL 5.1`开始，`long_query_time`开始以微秒记录SQL语句运行时间，之前仅用秒为单位记录。如果记录到表里面，只会记录整数部分，不会记录微秒部分。



```sqal
mysql> show variables like 'long_query_time%';
+-----------------+----------+
| Variable_name   | Value    |
+-----------------+----------+
| long_query_time | 0.200000 |
+-----------------+----------+
1 row in set (0.02 sec)

mysql> 
```



修改了变量`long_query_time`，但是查询变量`long_query_tim`e的值还是10，难道没有修改到呢？   

注意：使用命令 `set global long_query_time=4`修改后，需要重新连接或新开一个会话才能看到修改值。



## 2.3、日志分析工具:`mysqldumpslow`

```
-s, 是表示按照何种方式排序，
    c: 访问计数
    l: 锁定时间
    r: 返回记录
    t: 查询时间
    al:平均锁定时间
    ar:平均返回记录数
    at:平均查询时间
-t, 是top n的意思，即为返回前面多少条的数据；
-g, 后边可以写一个正则匹配模式，大小写不敏感的；

```

### 2.3.1、常用命令

#### 2.3.1.1、得到返回记录集最多的10个SQL。

```sql
mysqldumpslow -s r -t 10 /database/mysql/mysql06_slow.log
```



#### 2.3.1.2、得到访问次数最多的10个SQL

```sql
mysqldumpslow -s c -t 10 /database/mysql/mysql06_slow.log
```



#### 2.3.1.3、得到按照时间排序的前10条里面含有左连接的查询语句。

```java
mysqldumpslow -s t -t 10 -g “left join” /database/mysql/mysql06_slow.log
```



#### 2.3.1.4、另外建议在使用这些命令时结合 | 和more 使用 ，否则有可能出现刷屏的情况。

```sql
mysqldumpslow -s r -t 20 /mysqldata/mysql/mysql06-slow.log | more
```





# 3、数据库卡死

> 博主在使用使用大量定时器任务对数据库操作的时候，中间接到一个任务，需要直接对库里的字段进行修改，随性使用了一个alter table name drop column 命令结果卡主了。      
>
> **卡主，我们可以使用命令来看看到底是哪个操作卡主了，然后将它kill掉**



## 3.1、解决方法

### 3.1.1、命令查看，是哪台服务器上运行了什么命令

```sql
select id, db, user, host, command, time, state, info
from information_schema.processlist
where command != 'Sleep'
order by time desc ;
```

![WX20180717-155913](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/blogImages/WX20180717-155913.png)



> mysql查看正在执行的sql

```sql
show full processlist;
```

![WX20180910-134650](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/blogImages/WX20180910-134650.png)



### 3.1.2、查看哪个线程运行了命令和命令执行的开始时间

```sql
innodb_trx         ## 当前运行的所有事务
innodb_locks       ## 当前出现的锁
innodb_lock_waits  ## 锁等待的对应关系

select * from information_schema.innodb_trx;
```

![WX20180726-151803](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/blogImages/WX20180726-151803.png)



### 3.1.3、杀死线程Id

```sql
kill 29832；
```



## 3.2、锁和锁等待

```java

root@127.0.0.1 : information_schema 13:28:38> desc innodb_locks;
+————-+———————+——+—–+———+——-+
| Field       | Type                | Null | Key | Default | Extra |
+————-+———————+——+—–+———+——-+
| lock_id     | varchar(81)         | NO   |     |         |       |#锁ID
| lock_trx_id | varchar(18)         | NO   |     |         |       |#拥有锁的事务ID
| lock_mode   | varchar(32)         | NO   |     |         |       |#锁模式
| lock_type   | varchar(32)         | NO   |     |         |       |#锁类型
| lock_table  | varchar(1024)       | NO   |     |         |       |#被锁的表
| lock_index  | varchar(1024)       | YES  |     | NULL    |       |#被锁的索引
| lock_space  | bigint(21) unsigned | YES  |     | NULL    |       |#被锁的表空间号
| lock_page   | bigint(21) unsigned | YES  |     | NULL    |       |#被锁的页号
| lock_rec    | bigint(21) unsigned | YES  |     | NULL    |       |#被锁的记录号
| lock_data   | varchar(8192)       | YES  |     | NULL    |       |#被锁的数据
+————-+———————+——+—–+———+——-+
10 rows in set (0.00 sec)
   
root@127.0.0.1 : information_schema 13:28:56> desc innodb_lock_waits;
+——————-+————-+——+—–+———+——-+
| Field             | Type        | Null | Key | Default | Extra |
+——————-+————-+——+—–+———+——-+
| requesting_trx_id | varchar(18) | NO   |     |         |       |#请求锁的事务ID
| requested_lock_id | varchar(81) | NO   |     |         |       |#请求锁的锁ID
| blocking_trx_id   | varchar(18) | NO   |     |         |       |#当前拥有锁的事务ID
| blocking_lock_id  | varchar(81) | NO   |     |         |       |#当前拥有锁的锁ID
+——————-+————-+——+—–+———+——-+
4 rows in set (0.00 sec)
   
root@127.0.0.1 : information_schema 13:29:05> desc innodb_trx ;
+—————————-+———————+——+—–+———————+——-+
| Field                      | Type                | Null | Key | Default             | Extra |
+—————————-+———————+——+—–+———————+——-+
| trx_id                     | varchar(18)         | NO   |     |                     |       |#事务ID
| trx_state                  | varchar(13)         | NO   |     |                     |       |#事务状态：
| trx_started                | datetime            | NO   |     | 0000-00-00 00:00:00 |       |#事务开始时间；
| trx_requested_lock_id      | varchar(81)         | YES  |     | NULL                |       |#innodb_locks.lock_id
| trx_wait_started           | datetime            | YES  |     | NULL                |       |#事务开始等待的时间
| trx_weight                 | bigint(21) unsigned | NO   |     | 0                   |       |#
| trx_mysql_thread_id        | bigint(21) unsigned | NO   |     | 0                   |       |#事务线程ID
| trx_query                  | varchar(1024)       | YES  |     | NULL                |       |#具体SQL语句
| trx_operation_state        | varchar(64)         | YES  |     | NULL                |       |#事务当前操作状态
| trx_tables_in_use          | bigint(21) unsigned | NO   |     | 0                   |       |#事务中有多少个表被使用
| trx_tables_locked          | bigint(21) unsigned | NO   |     | 0                   |       |#事务拥有多少个锁
| trx_lock_structs           | bigint(21) unsigned | NO   |     | 0                   |       |#
| trx_lock_memory_bytes      | bigint(21) unsigned | NO   |     | 0                   |       |#事务锁住的内存大小（B）
| trx_rows_locked            | bigint(21) unsigned | NO   |     | 0                   |       |#事务锁住的行数
| trx_rows_modified          | bigint(21) unsigned | NO   |     | 0                   |       |#事务更改的行数
| trx_concurrency_tickets    | bigint(21) unsigned | NO   |     | 0                   |       |#事务并发票数
| trx_isolation_level        | varchar(16)         | NO   |     |                     |       |#事务隔离级别
| trx_unique_checks          | int(1)              | NO   |     | 0                   |       |#是否唯一性检查
| trx_foreign_key_checks     | int(1)              | NO   |     | 0                   |       |#是否外键检查
| trx_last_foreign_key_error | varchar(256)        | YES  |     | NULL                |       |#最后的外键错误
| trx_adaptive_hash_latched  | int(1)              | NO   |     | 0                   |       |#
| trx_adaptive_hash_timeout  | bigint(21) unsigned | NO   |     | 0                   |       |#
+—————————-+———————+——+—–+———————+——-+
22 rows in set (0.01 sec)

```



















![ContactAuthor](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/assets/img/artical_bottom.jpg)




<!-- Gitalk 评论 start  -->

<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script> 
<div id="gitalk-container"></div>    
 <script type="text/javascript">
    var gitalk = new Gitalk({
		clientID: `1d164cd85549874d0e3a`,
		clientSecret: `527c3d223d1e6608953e835b547061037d140355`,
		repo: `HealerJean.github.io`,
		owner: 'HealerJean',
		admin: ['HealerJean'],
		id: 'sVtG9yWYSIPvoieX',
    });
    gitalk.render('gitalk-container');
</script> 

<!-- Gitalk end -->


---
title: Redis的一些核心问题
date: 2018-10-11 03:33:00
tags: 
- Cache
category: 
- Cache
description: Redis的一些核心问题
---
**前言**     

 Github：[https://github.com/HealerJean](https://github.com/HealerJean)         

 博客：[http://blog.healerjean.com](http://HealerJean.github.io)         

​       

# 1、单线程Redis为什么那么快     

1、纯内存操作        

2、单线程操作，避免了资源的竞争         

3、采用了非阻塞I/O多路复用机制



# 2、如何应对缓存穿透和缓存雪崩问题

## 2.1、缓存穿透，

> 即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。

### 2.1.1、方案1、使用互斥锁排队   

> 业界比价普遍的一种做法，即根据key获取value值为空时，锁上，从数据库中load数据后再释放锁。若其它线程获取锁失败，则等待一段时间后重试。     
>
> 这里要注意，分布式环境中要使用分布式锁，单机的话用普通的锁（synchronized、Lock）就够了。(因为这样大量查询无效key访问不是很多，如果大量查询的肯定放到缓存里面去了)          




```java

public String getWithLock(String key, Jedis jedis, String lockKey, String uniqueId, long expireTime) {
    // 通过key获取value
    String value = redisService.get(key);
    if (StringUtil.isEmpty(value)) {
        // 分布式锁，详细可以参考https://blog.csdn.net/fanrenxiang/article/details/79803037
        //封装的tryDistributedLock包括setnx和expire两个功能，在低版本的redis中不支持
        try {
            boolean locked = redisService.tryDistributedLock(jedis, lockKey, uniqueId, expireTime);
            if (locked) {
                value = userService.getById(key);
                redisService.set(key, value);
                redisService.del(lockKey);
                return value;
            } else {
                // 其它线程进来了没获取到锁便等待50ms后重试
                Thread.sleep(50);
                getWithLock(key, jedis, lockKey, uniqueId, expireTime);
            }
        } catch (Exception e) {
            log.error("getWithLock exception=" + e);
            return value;
        } finally {
            redisService.releaseDistributedLock(jedis, lockKey, uniqueId);
        }
    }
    return value;


```



### 2.1.2、布隆过滤器

> `bloomfilte`r就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小，下面先来简单的实现下看看效果，我这里用guava实现的布隆过滤器：  



> 使用定时任务将数据库值放到布隆过滤器中，如果布隆过滤器有的话，则返回，没有的话就是没有


```xml


<dependencies>  
    <dependency>  
        <groupId>com.google.guava</groupId>  
        <artifactId>guava</artifactId>  
        <version>23.0</version>  
    </dependency>  
</dependencies> 

```


```java
public class BloomFilterTest {
 
    private static final int capacity = 1000000;
    private static final int key = 999998;
 
    private static BloomFilter<Integer> bloomFilter = BloomFilter.create(Funnels.integerFunnel(), capacity);
 
    static {
        for (int i = 0; i < capacity; i++) {
            bloomFilter.put(i);
        }
    }
 
    public static void main(String[] args) {
        /*返回计算机最精确的时间，单位微妙*/
        long start = System.nanoTime();
 
        if (bloomFilter.mightContain(key)) {
            System.out.println("成功过滤到" + key);
        }
        long end = System.nanoTime();
        System.out.println("布隆过滤器消耗时间:" + (end - start));
        int sum = 0;
        for (int i = capacity + 20000; i < capacity + 30000; i++) {
            if (bloomFilter.mightContain(i)) {
                sum = sum + 1;
            }
        }
        System.out.println("错判率为:" + sum);
    }
}



成功过滤到999998
布隆过滤器消耗时间:215518
错判率为:318

可以看到，100w个数据中只消耗了约0.2毫秒就匹配到了key，速度足够快。然后模拟了1w个不存在于布隆过滤器中的key，匹配错误率为318/10000，也就是说，出错率大概为3%，跟踪下BloomFilter的源码发现默认的容错率就是0.03：

public static <T> BloomFilter<T> create(Funnel<T> funnel, int expectedInsertions /* n */) {
  return create(funnel, expectedInsertions, 0.03); // FYI, for 3%, we always get 5 hash functions
}

```



## 3.2、缓存雪崩

>  即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。

方案1、也是像解决缓存穿透一样加锁排队，实现同上;      

方案2、建立备份缓存，缓存A和缓存B，A设置超时时间，B不设值超时时间，先从A读缓存，A没有读B，并且异步启动一个更新线程，更新A缓存和B缓存;    

方案3、设置缓存超时时间的时候加上一个随机的时间长度，比如这个缓存key的超时时间是固定的5分钟加上随机的2分钟，酱紫可从一定程度上避免雪崩问题；





# 3、Redis分布式锁和Zk分布式锁区别

## 3.1、Redis实现分布式锁

> 使用开源框架`Redisson `

1、Redisson 所有指令都通过 Lua 脚本执行，Redis 支持 Lua 脚本原子性执行。   

2、Redisson 设置一个 Key 的默认过期时间为 30s，如果某个客户端持有一个锁超过了 30s 怎么办？    

3、Redisson 中有一个 Watchdog 的概念，翻译过来就是看门狗，它会在你获取锁之后，每隔 10s 帮你把 Key 的超时时间设为 30s。

这样的话，就算一直持有锁也不会出现 Key 过期了，其他线程获取到锁的问题了。    

4、Redisson 的“看门狗”逻辑保证了没有死锁发生。(如果机器宕机了，看门狗也就没了。此时就不会延长 Key 的过期时间，到了 30s 之后就会自动过期了，其他线程可以获取到锁)



### 3.1.1、总结

1、Redis 的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮。   

2、Redis 分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能。     

3、如果是 redis 获取锁的那个客户端 出现 bug 挂了，那么只能等**待超时时间之后才能释放锁**；





另一方面使用 Redis 实现分布式锁在很多企业中非常常见，而且大部分情况下都不会遇到所谓的“极端复杂场景”，所以使用 Redis 作为分布式锁也不失为一种好的方案，最重要的一点是 Redis 的性能很高，可以支撑高并发的获取、释放锁操作。





## 3.2、Zk分布式锁

> ZK 的模型是这样的：ZK 包含一系列的节点，叫做 Znode，就好像文件系统一样，每个 Znode 表示一个目录。

然后 Znode 有一些特性：

**有序节点：**假如当前有一个父节点为 /lock，我们可以在这个父节点下面创建子节点，ZK 提供了一个可选的有序特性。

例如我们可以创建子节点“/lock/node-”并且指明有序，那么 ZK 在生成子节点时会根据当前的子节点数量自动添加整数序号。

也就是说，如果是第一个创建的子节点，那么生成的子节点为 /lock/node-0000000000，下一个节点则为 /lock/node-0000000001，依次类推。    

**临时节点：**客户端可以建立一个临时节点，在会话结束或者会话超时后，ZK 会自动删除该节点。    

**事件监听：**在读取数据时，我们可以同时对节点设置事件监听，当节点数据或结构变化时，ZK 会通知客户端。



### 3.2.1、ZK 实现分布式锁的落地方案：

1、使用 ZK 的临时节点和有序节点，**每个线程获取锁就是在 ZK 创建一个临时有序的节点**，比如在 /lock/ 目录下。    

2、创建节点成功后，获取 /lock 目录下的所有临时节点，**再判断当前线程创建的节点是否是所有的节点的序号最小的节点。**    

3、如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。    

4、如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。    

5、比如当前线程获取到的节点序号为 /lock/003，然后所有的节点列表为[/lock/001，/lock/002，/lock/003]，则对 /lock/002 这个节点添加一个事件监听器。

如果锁释放了，会唤醒下一个序号的节点，然后重新执行第 3 步，判断是否自己的节点序号是最小。比如 /lock/001 释放了，/lock/002 监听到时间，此时节点集合为[/lock/002，/lock/003]，则 /lock/002 为最小序号节点，获取到锁。



### 3.2.2、总结

1、ZK 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。       

2、如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。

3、而 zk 的话，因为创建的是临时 znode，**只要客户端挂了，znode 就没了，此时就自动释放锁。**



但是 ZK 也有其缺点：如果有较多的客户端频繁的申请加锁、释放锁，对于 ZK 集群的压力会比较大。

# 3、Redis过期策略

> redis设置过期时间：   （除了字符串自己独有设置过期时间的方法外，其他方法都需要依靠expire方法来设置时间）  
>
> 1、expire key time(以秒为单位)--这是最常用的方式         
>
> 2、setex(String key, int seconds, String value)--字符串独有的方式      
>
> 
>
> 如果没有设置时间，那缓存就是永不过期 -1      
>
> 如果设置了过期时间，之后又想让缓存永不过期，使用persist key



## 3.1、过期策略

### 3.1.1、定时删除

含义：在设置key的过期时间的同时，为该key创建一个定时器，让定时器在key的过期时间来临时，对key进行删除           

优点：保证内存被尽快释放        

缺点： 定时器的创建耗时，若为每一个设置过期时间的key创建一个定时器（将会有大量的定时器产生），性能影响严重 

### 3.1.2、懒汉式删除

含义：key过期的时候不删除，每次通过key获取值的时候去检查是否过期，若过期，则删除，返回null。         

优点：删除操作只发生在通过key取值的时候发生，而且只删除当前key，所以对CPU时间的占用是比较少的，而且此时的删除是已经到了非做不可的地步（如果此时还不删除的话，我们就会获取到了已经过期的key了）       

缺点：若大量的key在超出超时时间后，很久一段时间内，都没有被获取过，那么可能发生内存泄露（无用的垃圾占用了大量的内存）

### 3.1.3、定期删除

含义：每隔一段时间执行一次删除过期key操作         

优点：定期删除过期key--处理"懒汉式删除"的缺点，通过**限制删除操作的时长和频率**，来减少删除操作对CPU时间的占用--处理"定时删除"的缺点          

缺点：在内存友好方面，不如"定时删除"（会造成一定的物理内存占用，但是没有懒汉式那么占用内存）        

　　　在CPU时间友好方面，不如"懒汉式删除"（会定期的去进行比较和删除操作，cpu方面不如懒汉式，但是比定时好）             

难点：合理设置删除操作的**执行时长（每次删除执行多长时间）和执行频率（每隔多长时间做一次删除，默认每隔100ms检查）**（这个要根据服务器运行情况来定了），每次执行时间太长，或者执行频率太高对cpu都是一种压力。     

方法：       

```
1、遍历每个数据库（就是redis.conf中配置的"database"数量，默认为16）

2、redis默认每隔100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次    

3、检查当前库中的指定个数个key（默认是每个库检查20个key，注意相当于该循环执行20次，循环体是下边的描述）    
   如果当前库中没有一个key设置了过期时间，直接执行下一个库的遍历，随机获取一个设置了过期时间的key，检查该key是否过期，如果过期，删除key，判断定期删除操作是否已经达到指定时长，若已经达到，直接退出定期删除。每次进行定期删除操作执行之后，    


4、对于定期删除，在程序中有一个全局变量current_db来记录下一个将要遍历的库，假设有16个库，我们这一次定期删除遍历了10个，那此时的current_db就是11，下一次定期删除就从第11个库开始遍历，假设current_db等于15了，那么之后遍历就再从0号库开始（此时current_db==0）
```



## 3.2、Redis采用的过期策略

>     懒汉式删除+定期删除 

### 3.2.1、采用定期删除+惰性删除就没其他问题了么?

> **内存淘汰机制**：如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用

```
# maxmemory-policy volatile-lru

该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)
1）noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。应该没人用吧。
2）allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。推荐使用，目前项目在用这种。
3）allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。应该也没人用吧，你不删最少使用Key,去随机删。
4）volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。这种情况一般是把redis既当缓存，又做持久化存储的时候才用。不推荐
5）volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。依然不推荐
6）volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。不推荐
ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。

```





## 3.3、Redis内存淘汰机制：`LRU算法`

> **Least Recently Used,最近最久未使用法**，它是按照一个非常著名的计算机操作系统基础理论得来的：**最近使用的页面数据会在未来一段时期内仍然被使用,已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用**。        
>
> **基于这个思想,会存在一种缓存淘汰机制**，每次从内存中找到最久未使用的数据然后置换出来，从而存入新的数据！**它的主要衡量指标是使用的时间，附加指标是使用的次数。在计算机中大量使用了这个机制，它的合理性在于优先筛选热点数据，所谓热点数据，就是最近最多使用的数据！因为，利用LRU我们可以解决很多实际开发中的问题，并且很符合业务场景**。



案例：小王在A公司上班，有一天产品提出了一个需求：“咱们系统的用户啊，每天活跃的就那么多，有太多的僵尸用户，根本不登录，你能不能考虑做一个筛选机制把这些用户刨出去，并且给活跃的用户做一个排名，我们可以设计出一些奖励活动，提升咱们的用户粘性，咱们只需要关注些活跃的用户就行了。          

小王连忙点头，说可以啊，然而心里犯起嘀咕来了：这简单，**按照常规思路，给用户添加一个最近活跃时间长度和登录次数**，然后按照这两个数据计算他们的活跃度，最后直接排序就行了。嘿嘿，简直完美!不过！用户表字段已经很多了，又要加两个字段，然后还得遍历所有的数据排序？这样查询效率是不是会受影响啊？并且公司的服务器上次就蹦过一次，差点没忙出命来才调好。有没有更优雅的一种方式呢？小王面朝天空45°，陷入了无限的思考中.....           

当小王看到LRU的时候，瞬间感觉抓住了救命稻草，这个算法不是就完全契合产品的需求吗？只要把用户数据按照LRU去筛选，利用数据结构完成的事情，完全减少了自己存储、添加字段判断、排序的过程，这样对于提高服务器性能肯定有很大的帮助，岂不美哉！



### 3.3.1、利用双向链表实现

> 双向链表有一个特点就是它的链表是双路的，我们定义好头节点和尾节点，然后利用先进先出（FIFO），最近被放入的数据会最早被获取。其中主要涉及到添加、访问、修改、删除操作。    
>
> 添加：如果是新元素，直接放在链表头上面，其他的元素顺序往下移动；    
>
> 访问：在头节点的可以不用管，如果是在中间位置或者尾巴，就要将数据移动到头节点；   
>
> 修改：修改原值之后，再将数据移动到头部；   
>
> 删除：直接删除，其他元素顺序移动；



```java
public class Node {
    //键
    Object key;
    //值
    Object value;
    //上一个节点
    Node pre;
    //下一个节点
    Node next;

    public Node(Object key, Object value) {
        this.key = key;
        this.value = value;
    }
}


public class LRU<K, V> {
    private int capcity;//总容量
    private HashMap<K, Node> caches;//所有的node节点
    private Node first;//头节点
    private Node last;//尾节点

    public LRU(int size) {
        this.capcity = size;
        caches = new HashMap<>(size);
    }

    /**
     * 放入元素
     * @param key
     * @param value
     */
    public void put(K key, V value) {
        //1、从缓存中取
        Node node = caches.get(key);
        //2、如果新元素
        if (node == null) {
            //如果超过元素容纳量
            if (caches.size() >= capcity) {
                //移除最后一个节点
                caches.remove(last.key);
                removeLast();
            }
            //创建新节点
            node = new Node(key,value);
        }else{
            //已经存在的元素覆盖旧值
            node.value = value;
        }

        //把元素移动到首部
        moveToHead(node);
        caches.put(key, node);
    }

    /**
     * 通过key获取元素
     * @param key
     * @return
     */
    public Object get(K key) {
        Node node = caches.get(key);
        if (node == null) {
            return null;
        }
        //把访问的节点移动到首部
        moveToHead(node);
        return node.value;
    }

    /**
     * 根据key移除节点
     * @param key
     * @return
     */
    public Object remove(K key) {
        Node node = caches.get(key);
        if (node != null) {
            if (node.pre != null) {
                node.pre.next = node.next;
            }
            if (node.next != null) {
                node.next.pre = node.pre;
            }
            if (node == first) {
                first = node.next;
            }
            if (last  == node) {
                last = node.pre;
            }
        }
        return caches.remove(key);
    }

    /**
     * 清除所有节点
     */
    public void clear() {
        first = null;
        last = null;
        caches.clear();
    }

    /**
     * 把当前节点移动到首部
     * @param node
     */
    private void moveToHead(Node node) {
        //1、如果是第一个节点，则返回即可，不需要变化
        if (first == node) {
            return;
        }
        //2、如果是最后一个节点,则重置最后一个节点
        if (last == node) {
            last = last.pre;
        }

        //3、如果是中间节点，则改变他下一个节点的指针pre指针
        if (node.next != null) {
            node.next.pre = node.pre;
        }
        //3、如果是中间节点，则改变他上一个节点的指针next指针
        if (node.pre != null) {
            node.pre.next = node.next;
        }

        //如果首位节点都是null，则 当前节点就是first节点
        if (first == null || last == null) {
            first = last = node;
            return;
        }

        //此时讲节点设置为第一个节点
        node.next = first;
        first.pre = node;
        first = node;
        first.pre = null;
    }

    /**
     * 移除最后一个节点
     */
    private void removeLast() {
        if (last != null) {
            last = last.pre;
            //如果last等于null，说过该节点是第一个元素
            if (last == null) {
                first = null;
            } else {
                //如果不是则，讲last的nex设置null
                last.next = null;
            }
        }
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder();
        Node node = first;
        while (node != null) {
            sb.append(String.format("%s:%s ", node.key, node.value));
            node = node.next;
        }
        return sb.toString();
    }


    public static void main(String[] args) {
        LRU<Integer, String> lru = new LRU<Integer, String>(5);
        lru.put(1, "a");
        lru.put(2, "b");
        lru.put(3, "c");
        lru.put(4,"d");
        lru.put(5,"e");
        System.out.println("原始链表为:"+lru.toString());

        lru.get(4);
        System.out.println("获取key为4的元素之后的链表:"+lru.toString());

        lru.put(6,"f");
        System.out.println("新添加一个key为6之后的链表:"+lru.toString());

        lru.remove(3);
        System.out.println("移除key=3的之后的链表:"+lru.toString());
    }
}

```





### 3.3.2、使用`LinkedList实现`

```java
public class LRU<K, V> {
    private int capcity;//总容量
    private HashMap<K, Node> caches;//所有的node节点
    LinkedList<Node> linkedList = new LinkedList<>();
    public LRU(int capcity) {
        this.capcity = capcity;
        caches = new HashMap<>(capcity);
    }

    /**
     * 放入元素
     * @param key
     * @param value
     */
    public void put(K key, V value) {
        //1、从缓存中取
        Node node = caches.get(key);
        //2、如果新元素
        if (node == null) {
            //如果超过元素容纳量
            if (caches.size() >= capcity) {
                //移除最后一个节点
                caches.remove(linkedList.getLast().key);
                linkedList.removeLast();
            }
            //创建新节点
            node = new Node(key,value);
        }else{
            //已经存在的元素，先删除
            linkedList.remove(node);
            node.value = value;
        }
        //把元素移动到首部
        linkedList.addFirst(node);
        caches.put(key, node);
    }

    /**
     * 通过key获取元素
     * @param key
     * @return
     */
    public Object get(K key) {
        Node node = caches.get(key);
        if (node == null) {
            return null;
        }
        linkedList.remove(node);
        linkedList.addFirst(node);
        return node.value;
    }

    /**
     * 根据key移除节点
     * @param key
     * @return
     */
    public Object remove(K key) {
        Node node = caches.get(key);
        if (node != null) {
           linkedList.remove(node);
        }
        return caches.remove(key);
    }

    /**
     * 清除所有节点
     */
    public void clear() {
        caches.clear();
        linkedList.clear();
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder();
        if (!linkedList.isEmpty()){
            linkedList.stream().forEach(node ->{
                sb.append(String.format("%s:%s ", node.key, node.value));
            });
        }
        return sb.toString();
    }


    public static void main(String[] args) {
        LRU<Integer, String> lru = new LRU<Integer, String>(5);
        lru.put(1, "a");
        lru.put(2, "b");
        lru.put(3, "c");
        lru.put(4,"d");
        lru.put(5,"e");
        System.out.println("原始链表为:"+lru.toString());

        lru.get(4);
        System.out.println("获取key为4的元素之后的链表:"+lru.toString());

        lru.put(6,"f");
        System.out.println("新添加一个key为6之后的链表:"+lru.toString());

        lru.remove(3);
        System.out.println("移除key=3的之后的链表:"+lru.toString());
    }
}

class Node {
    //键
    Object key;
    //值
    Object value;
    public Node(Object key, Object value) {
        this.key = key;
        this.value = value;
    }
}

```





### 3.3.3、重写`LinkedHashMap`

> LinkedHashMap默认的构造参数是默认 插入顺序的，就是说你插入的是什么顺序，读出来的就是什么顺序，但是也有访问顺序，就是说你访问了一个key，这个key就跑到了最后面     
>
> `accessOrde`r：设置为false，表示不是访问顺序而是插入顺序存储的，这也是默认值，表示LinkedHashMap中存储的顺序是按照调用put方法插入的顺序进行排序的。LinkedHashMap也提供了可以设置accessOrder的构造方法，如下   
>
> `accessOrde`：设置为 true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。

```java
class LRU<K, V> extends LinkedHashMap<K, V> {

    private final int CACHE_SIZE;

    /**
     * true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。
     * cacheSize / 0.75 来源于 0.75 * capacity = cacheSize
     * Math.ceil()“向上取整”, 即小数部分直接舍去，因为舍去了小数部分所以 + 1
     *
     * capacity =  (int) Math.ceil(cacheSize / 0.75) + 1,
     */
    public LRU(int cacheSize) {
        super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);
        CACHE_SIZE = cacheSize;
    }

    /**
     * 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。
     */
    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        return super.size() > CACHE_SIZE;
    }

}
```













​    ![ContactAuthor](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/assets/img/artical_bottom.jpg)



<!-- Gitalk 评论 start  -->

<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script> 
<div id="gitalk-container"></div>    
 <script type="text/javascript">
    var gitalk = new Gitalk({
		clientID: `1d164cd85549874d0e3a`,
		clientSecret: `527c3d223d1e6608953e835b547061037d140355`,
		repo: `HealerJean.github.io`,
		owner: 'HealerJean',
		admin: ['HealerJean'],
		id: 'skDRFNjJPyg5QiV4',
    });
    gitalk.render('gitalk-container');
</script> 

<!-- Gitalk end -->


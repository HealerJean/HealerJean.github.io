---
title: Redis原理之_有备无患_主从同步
date: 2018-04-17 03:33:00
tags: 
- Redis
category: 
- Redis
description: Redis原理之_有备无患_主从同步
---



**前言**     

 Github：[https://github.com/HealerJean](https://github.com/HealerJean)         

 博客：[http://blog.healerjean.com](http://HealerJean.github.io)          



# 1、引入

> 很多企业都没有使用到 `Redis` 的集群，但是至少都做了主从。有了主从，当 `master` 挂 掉的时候，运维让从库过来接管，服务就可以继续，否则 `master` 需要经过数据恢复和重启 的过程，这就可能会拖很长的时间，影响线上业务的持续服务。           





## 1.1、最终一致

> `Redis`满足可用性：`Redis` 的主从数据是异步同步的，所以分布式的 `Redis` 系统并不满足「一致性」要求。 当客户端在 `Redis` 的主节点修改了数据后，立即返回，即使在主从网络断开的情况下，主节点依旧可以正常对外提供修改服务，所以 `Redis` 满足「可用性」。
>
> `Redis` 保证「最终一致性」:从节点会努力追赶主节点，最终从节点的状态会和主节点 的状态将保持一致。如果网络断开了，主从节点的数据将会出现大量不一致，一旦网络恢 复，从节点会采用多种策略努力追赶上落后的数据，继续尽力保持和主节点一致。



## 1.2、主从同步

> `Redis` 同步支持主从同步和从从同步，从从同步功能是 `Redis` 后续版本增加的功能，为 了减轻主库的同步负担。后面为了描述上的方便，统一理解为主从同步。



![image-20210601165711432](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/blogImages/image-20210601165711432.png)

## 1.3、增量同步

> `Redis` **同步的是指令流**    
>
> **1、主节点会将那些对自己的状态产生修改性影响的指令记录在本地的内存 `buffer` 中**      
>
> **2、然后异步将 `buffer` 中的指令同步到从节点，从节点一边执行同步的指令流来达到和主节点一样的状态，一遍向主节点反馈自己同步到哪里了 (偏移量)。**



**问题1：主从复制不及时，主节点`buffer`满了怎么办呢？**       

答案：因为内存的 `buffe`r 是有限的，所以 `Redis` 主库不能将所有的指令都记录在内存 `buffer` 中。`Redis` 的复制内存 `buffer` 是一个定长的环形数组（本质上是先进先出的队列），如果数组内容满了，就会从头开始覆 盖前面的内容。        



![image-20210601165905130](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/blogImages/image-20210601165905130.png)



**问题2：如果因为网络不好，长时间断开，导致`buffer`被后续指令覆盖掉，从节点将无法直接通过指令流来进行同步，怎么办呢？**     

答案： 快照同步：如果因为网络状况不好，从节点在短时间内无法和主节点进行同步，那么当网络状况恢 复时，`Redis` 的主节点中那些没有同步的指令在 `buffer` 中有可能已经被后续的指令覆盖掉 了，从节点将无法直接通过指令流来进行同步，这个时候就需要用到更加复杂的同步机制 — — 快照同步.。





## 1.5、快照同步

> 快照同步是一个非常耗费资源的操作    
>
> 1、它首先需要在主库上进行一次 `bgsave` 将当前内存的数据全部快照到磁盘文件中       
>
> 2、然后再将快照文件的内容全部传送到从节点。        
>
> 3、从节点将快照文件接受完毕后，立即执行一次全量加载，加载之前先要将当前内存的数据清空。加载完毕后通知主节点继续进行增量同步。    



问题1：如果快照同步时间过长，`buffer`又被覆盖了，怎么办？    

答案：务必配置一个合适的复制 `buffer` 大小参数，避免快照复制的死循环。     

在整个快照同步进行的过程中，主节点的复制 `buffer` 还在不停的往前移动，如果快照同步的时间过长或者复制 `buffer` 太小，都会导致同步期间的增量指令在复制 `buffer` 中被覆盖，这样就会导致快照同步完成后无法进行增量复制，然后会再次发起快照同步，如此极有 可能会陷入快照同步的死循环。    



![image-20210601170336213](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/blogImages/image-20210601170336213.png)

## 1.6、增加从节点

> 当从节点刚刚加入到集群时，它必须先要进行一次快照同步，同步完成后再继续进行增量同步。





## 1.7、无盘复制

**问题1：什么是无盘复制？**    

答案：`Redis`支持无盘复制，生成的`RDB`文件不保存到磁盘而是直接通过网络发送给从节点。无盘复制适用于主节点所在机器磁盘性能较差但网络宽带较充裕的场景。需要注意的是，无盘复制目前依然处于实验阶段。       



**问题2：无盘复制解决了什么问题？**     

答案：主节点在进行快照同步时，会进行很重的文件 `IO` 操作，特别是对于非 `SSD` 磁盘存储 时，快照会对系统的负载产生较大影响。特别是当系统正在进行 `AOF` 的 `fsync` 操作时如果发生快照，`fsync` 将会被推迟执行，这就会严重影响主节点的服务效率。     

所以从 `Redis 2.8.18` 版开始支持无盘复制。所谓无盘复制是指主服务器直接通过网络将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一遍将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中， 再进行一次性加载。





## 1.8、`Wait` 指令

> **`Redis` 的复制是异步进行的，`wait` 指令可以让异步复制变身同步复制**，确保系统的强一致性 (不严格)。`wait` 指令是 `Redis3.0` 版本以后才出现的。      
>
> > `wait` 提供两个参数，第一个参数是从库的数量 `N`，第二个参数是时间 `t`，以毫秒为单 位。表示等待 `wait` 指令之前的所有写操作同步到 `N` 个从库 (也就是确保 `N` 个从库的同 步没有滞后)，最多等待时间 `t`。     
> >
> > ⬤ 如果时间 `t` = `0`，表示无限等待直到 `N` 个从库同步完成达成 一致。     假设此时出现了网络异常，`wait` 指令第二个参数时间 `t` = `0`，主从同步无法继续进行， `wait` 指令会永远阻塞，`Redis` 服务器将丧失可用性。



```
> set key value 
OK
> wait 1 0
(integer) 1
```



## 1.9、总结：

1、主从复制是 `Redis` 分布式的基础，`Redis` 的高可用离开了主从复制将无从进行。分布式系统为了解决单点问题，通常会将数据复制成多个副本部署到其他机器。后面的哨兵，集群都是在这个基础上的。     

2、不过复制功能也不是必须的，如果你将 `Redis` 只用来做缓存，跟 memcache 一样来对 待，也就无需要从库做备份，挂掉了重新启动一下就行。**但是只要你使用了 `Redis` 的持久化 功能，就必须认真对待主从复制，它是系统数据安全的基础保障**。





# 2、`Redis`复制过程

## 2.1、三种复制拓扑结构

### 2.1.1、一主一从

>  > **当应用写命令并发量高且需要持久化时，当主节点出现死机时候，从节点提供故障转移**         
>
>  **为了提高性能，,当应用写命令并发量较高且需要持久化时，可以只在从节点上开启`AOF`。  当主节点关闭持久化功能的时候，如果主节点脱机要避免自动重启操作，因为主节点没有开启`AOF`自动重启后数据为空，这个时候从节点继续复制主节点会导致从节点数据也被情况。**            
>
>  **安全的做法:**      **在从节点上执行`slaveof no one `断开与主节点的复制关系，,再重启主节点 。从而避免这一问题。**   



### 2.1.2、一主多从   

> > **可利用多个从节点实现读写分离，对于读占比较大的场景，可以把读命令发送到从节点来分担主节点压力**         
>
> 同时在日常开发中如果需要执行一些比较耗时的读命令,如：`keys`、`sort`等,可以在其中一台从节点上执行。防止慢查询对主节点造成阻塞从而影响线上服务的稳定性；     
>
> **缺点：对于并发量高的场景，从节点过多，主节点写命令的对从节点发送多，过度消耗网络宽带，影响主节点的负载稳定性**   




### 2.1.3、树状主从结构（从从同步）

> > 当主节点需要挂载多个从节点时为了避免对主节点的性能干扰,可以采用树状主从结构降低主节点压力    
> 
>从节点不但可以复制主节点数据，同时可以作为其他从节点的主节点继续向下层复制，通过引入复制中间层，可以有效降低主节点负载和需要传送给从节点的数据量,，数据实现了一层一层的向下复制       
> 
>缺点：比较复杂





## 2.2、模拟建立主从复制

> > 准备工作，准备多个端口的`redis`，分为为`6379`主 `6380` `6381`     
>
> 配置方式有3种呢，常见的一种是配置文件，很简单的。第二重直接使用命令,下面就是     



### 2.2.1、建立主从复制关系

**1、`slaveof`都是从节点发起，下面这个为`6379`为主节点，6380为从节点**

```shell
127.0.0.1:6380> slaveof 127.0.0.1 6379
OK
```



**2、开始测试 6379 主节点 添加值** 

```shell
127.0.0.1:6379> set hello myson
OK
127.0.0.1:6379> get hello
"myson"
```



**3、从节点查值**

```shell
127.0.0.1:6380> slaveof 127.0.0.1 6379
OK
127.0.0.1:6380> get hello
"myson"
```



### 2.2.2、查看复制状态信息：`info replication`

> `info replication`



#### 2.2.2.1、主节点 复制状态信息

```shell
127.0.0.1:6379> info replication
# Replication
role:master
connected_slaves:1
slave0:ip=127.0.0.1,port=6380,state=online,offset=534,lag=1
master_replid:be3b2c4a26961f6a9795346a61f1530ab3663384
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:534
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:534
```



#### 2.2.2.2、从节点复制状态信息

```shell
127.0.0.1:6380> info replication
# Replication
role:slave
master_host:127.0.0.1
master_port:6379
master_link_status:up
master_last_io_seconds_ago:1
master_sync_in_progress:0
slave_repl_offset:506
slave_priority:100
slave_read_only:1
connected_slaves:0
master_replid:be3b2c4a26961f6a9795346a61f1530ab3663384
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:506
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:506
```



### 2.2.3、断开复制：`slaveof no one` 

>  `slaveof no one`     
>
>  > **注意：这种方式虽然断开了复制，但是从主节点之前过来的数据并没有删除,这个时候直接切换到其他节点`8081`作为主节点，而自己作为从节点**。**则数据这个时候不会自动删除，需要手动删除的**，**此时新的主节点可以使用之前没有删除的数据。这种情况不应该存在**


```shell
127.0.0.1:6380> slaveof no one
OK
127.0.0.1:6380> info replication
# Replication
role:master
connected_slaves:0
master_replid:721f4f4083c2ad6d85433f30002c49a2ec0f5180
master_replid2:be3b2c4a26961f6a9795346a61f1530ab3663384
master_repl_offset:772
second_repl_offset:773
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:772
127.0.0.1:6380> keys *
1) "hello"
```






### 2.2.4、主从传输延迟相关参数

> 主从节点一般部署在不同机器上，复制时的网络延迟就成为需要考虑的因此。       

`Redis`的`Replication`有一个配置“`repl-disable-tcp-nodelay`”，如下

```
repl-disable-tcp-nodelay no
```

`yes`：主节点会合并较小的`TCP`数据包从而节省宽带，默认发送时间间隔取决于`Linux`内核，一般默认40毫秒，这种配置节省了带宽。但是增大了主从直接的延迟，造成`master`与`slave`数据不一致 。适用于网络环境复杂的场景，如跨机房部署，   

`no`：则`redis master`会立即发送同步数据，没有延迟，适用于网络良好，如同机器或者同机房





## 2.3、复制流程

**1、保存主节点信息：**执行完`slaveof`命令后从节点只保存主节点的信息地址便返回，此时建立复制流程还未开始    



**2、主从建立`socke`t连接：**从节点内部通过每秒运行定时任务维护复制相关逻辑，当定时任务发现存在新的主节点后,会尝试与该节点建立网络连接,若无法建立连接，定时任务会无限重试直到连接成功或执行`slaveof no one`命令为止    



**3、发送`ping`命令：**用于检测主从之间网络套接字是否可用和主节点当前是否可接受处理命令,若从节点没收到主节点的`pong`回复或超时，则断开复制连接,下次定时任务会发起重连     



**4、权限验证：**若主节点设置了`requirepass`参数,则需要密码验证,从节点必须配置`masterauth`参数保证与主节点相同的密码才能通过验证,若验证失败则复制终止，从节点重新发起复制流程       



**5、快照同步：主从复制连接正常通信后,对于首次建立复制的场景,主节点会把持有的数据全部发送给从节点,这步操作耗时最长(`RDB`全量复制)**      



**6、增量同步：当主节点把当前的数据同步给从节点后,便完成复制的建立流程,接下来主节点会持续把写命令发送给从节点,保证主从数据一致性**







# 3、数据同步

> `psync`命令完成主从数据同步， 包括全量复制和部分复制；

全量复制:一般用于初次复制场景，当数据量大的时候，会造成很大开销，是第一次经历复制时候必须经历的阶段，     

部分复制：用于处理主从复制中因为网络中断等原因操作数据丢失场景， 从节点会想主节点要求补发丢失的命令数据，如果主节点的复制解压缓冲区内存在这部分数据则直接发给从节点。这样就能保证主从复制的一致性，补发的这部分数据一般远远小于全量数据，所以开销很少



## 3.1、复制偏移量

> 作用：通过判断主从节点的复制偏移量和判断主从节点数据是否一致    

**1、主节点都会维护自身的复制偏移量，主节点在处理完命令后，会把命令的长度做累加记录**       

**2、从节点在接收到主节点发送的命令后，也会累计增加自身的偏移量，统计信息在`slave_repl_offset`**        

**3、从节点每秒上报自身的复制偏移量给主节点，因此主节点也会保存从节点复制偏移量。**       



## 3.2、复制积压缓冲区

> 复制积压缓冲区是保存主节点上一个固定长度的队列（我理解其实就是上面的那个），默认大学为`1MB`，当主节点有连接的从节点`slave`时被创建，这时主节点`master`响应写命令时，不但会将命令发送给从节点，还会复制积压缓冲区



缓冲区本质上是先进先出的队列，所以能够实现最近已复制数据的功能，用于部分复制和复制数据丢失的补救，复制缓冲区统计信息保存在主节点的`info replicatio`n中

```
repl_backlog_active:1 //开启复制缓冲区
repl_backlog_size:1048576 //缓冲区最大长度
repl_backlog_first_byte_offset:1 //起始偏移量，计算当前缓冲区可用范围
repl_backlog_histlen:6088 //已保存数据的有效长度
```



通过查看 `sync_partial_err` 变量的次数来决定是否需要扩大积压缓冲区，它表示主从半同步复制失败的次数。

```shell
\> redis-cli info stats | grep sync sync_full:0
 sync_partial_ok:0
 sync_partial_err:0 # 半同步失败次数
```





## 3.3、节点运行`ID`

> 每个`Redis`节点启动后都会动态分配一个`40`位的十六进制，运行`id`主要功能是唯一识别`Redis`节点，比如从节点保存主节点运行`id`识别自己正在复制的是哪个主节点。   
>
> 注意：当`redis`关闭再重启之后，运行`Id`会随着改变（个人理解：关闭再重启，主从属性都说不定改变了，留着干嘛，害人吗？）





# 4、开发和运维



**问题1：第一次建立复制，无法规避时全量复制，怎么把伤害降低？**

答案：从节点没有任何主节点数据，因此必须进行全量复制才能完成数据同步，对于这种情况全量复制无法避免，当数据量较大且流量高的时候，添加从节点时，建议在低峰时候进行操作。或者尽量规避使用大数据量的Redis节点。      



**问题2：主节点重启后，节点运行`id`变了，怎么避免全量复制**

**答案：提升从节点为主节点：**当主从关系建立后，节点会保存主节点运行ID，如果此时主节点因故障重启，那么他的运行Id就会改变，**当从节点发现主节点运行Id不匹配的时候，就会以为这是一个新的主节点，就会发生全量复制。这种情况是一定需要解决的，当主节点发送故障，手动提升从节点为主节点或者采用支持自动故障转移的哨兵或集群方案**         









![ContactAuthor](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/assets/img/artical_bottom.jpg)



<!-- Gitalk 评论 start  -->

<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">

<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script> 
<div id="gitalk-container"></div>    
 <script type="text/javascript">
    var gitalk = new Gitalk({
		clientID: `1d164cd85549874d0e3a`,
		clientSecret: `527c3d223d1e6608953e835b547061037d140355`,
		repo: `HealerJean.github.io`,
		owner: 'HealerJean',
		admin: ['HealerJean'],
		id: '30LmsxEyOYkHAjKW',
    });
    gitalk.render('gitalk-container');
</script> 




<!-- Gitalk end -->




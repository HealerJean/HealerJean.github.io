---
title: 四两拨千斤_HyperLogLog
date: 2018-04-04 03:33:00
tags: 
- Redis
category: 
- Redis
description: 四两拨千斤_HyperLogLog
---

**前言**     

 Github：[https://github.com/HealerJean](https://github.com/HealerJean)         

 博客：[http://blog.healerjean.com](http://HealerJean.github.io)          





# 1、引入

**问题：如果你负责开发维护一个大型的 网站，有一天老板找产品经理要网站每个网页每天的 `PV`、`UV` 数据，然后让你来开发这个统计模 块，你会如何实现?**    



1、`PV`统计：给每个网页一个独立的 `Redis` 计数器就可以了，这个计数器 的 `key` 后缀加上当天的日期。这样来一个请求，`incrby` 一次，最终就可以统计出所有的 `PV` 数据。     

2、`UV`统计： 无脑解决方案：那就是为每一个页面一个独立的 `set` 集合来存储所 有当天访问过此页面的用户 `ID`。当一个请求过来时，我们使用 `sadd` 将用户 `ID` 塞进去就可以了。通过 `scard` 可以取出这个集合的大小，这个数字就是这个页面的 `UV` 数据。没错，这 是一个非常简单的方案。      



**以上解决方案带来带来的问题有哪些？**

**问题1：`PV`上面的方案是没有问题的，但是`UV`就有些low了？**      

答案：因为，如果你的页面访问量非常大，比如一个爆款页面几千万的 `UV`，你需要一个很大 的 `set` 集合来统计，这就非常浪费空间。 如果这样的页面很多，那所需要的存储空间是惊人 的。     



**问题2：为这样一个去重功能就耗费这样多的存储空间，值得么?**      

答案：当然不值得，如果数量很大很大，需要的数据基本上不需要太精确，差不多就行，`105w` 和 `106w` 这两个数字对于老板们来说并没有多大区别，     



**问题3：So，有没有更好的解决方案呢?**              

答案：`Redis` 提供了`位图`、   `HyperLogLog` 数据结构就是用来解决这种统计问题的。        

**1、`redis`位图**     

`bitmap`同样是一种可以统计基数的方法，可以理解为用`bit`数组存储元素，例如`01101001`，表示的是[1,2,4,8]，`bitmap`中1的个数就是基数。`bitmap`也可以轻松合并多个集合，只需要将多个数组进行异或操作就可以了。    

`bitmap`相比于`Set`也大大节省了内存，我们来粗略计算一下，统计`1`亿个数据的基数，需要的内存是：`100000000/8/1024/1024` ≈ `12M`。      

虽然`bitmap`在节省空间方面已经有了不错的表现，但是如果需要统计`1000`个对象，就需要大约`12G`的内存，显然这个结果仍然不能令我们满意。在这种情况下，`HyperLogLog`将会出来拯救我们。



**2、`HyperLogLog`**      

**`HyperLogLog` 提供不精确的去重计数方案，虽然不精确但是也不是非常不精确，标准误差是 `0.81%`，这样的精确度已经可以满足上面的 `UV` 统计需求了**。      

`HyperLogLog` 数据结构是 `Redis` 的高级数据结构，它非常有用，但是令人感到意外的 是，使用过它的人非常少。



# 2、使用方法

> `HyperLogLog` 提供了两个指令 `pfadd` 和 `pfcount`，根据字面意义很好理解，一个是增加 计数，一个是获取计数。   
>
> > ◯ `pfadd` 用法和 `set` 集合的 `sadd` 是一样的，来一个用户 `ID`，就将用 户 `ID` 塞进去就是。      
> >
> > ◯ `pfcount` 和 `scard` 用法是一样的，直接获取计数值。



```shell
127.0.0.1:6379> pfadd codehole user1 
(integer) 1
127.0.0.1:6379> pfcount codehole 
(integer) 1

127.0.0.1:6379> pfadd codehole user2
(integer) 1
127.0.0.1:6379> pfcount codehole 
(integer) 2

127.0.0.1:6379> pfadd codehole user3 
(integer) 1
127.0.0.1:6379> pfcount codehole 
(integer) 3

127.0.0.1:6379> pfadd codehole user4 
(integer) 1
127.0.0.1:6379> pfcount codehole 
(integer) 4

127.0.0.1:6379> pfadd codehole user5 
(integer) 1
127.0.0.1:6379> pfcount codehole
(integer) 5

127.0.0.1:6379> pfadd codehole user6 
(integer) 1
127.0.0.1:6379> pfcount codehole
(integer) 6

127.0.0.1:6379> pfadd codehole user7 user8 user9 user10 
(integer) 1
127.0.0.1:6379> pfcount codehole
(integer) 10
```



# 3、验证

## 3.1、`1000`个数据

> 验证1000个数据，多久出现不一致    

### 3.1.1、实例代码

```java
@Test
public void test() {
  Jedis jedis = new Jedis("127.0.0.1", 6379);
  for (int i = 0; i < 1000; i++) {
    jedis.pfadd("codehole", "user" + i);

    long total = jedis.pfcount("codehole");
    if (total != i + 1) {
      log.info("total: {}, actually: {}", total, i + 1);
      break;
    }
  }
  jedis.close();
}



total: 99, actually: 100
```

### 3.1.2、归纳总结

> 当我们加入第 `100` 个元素时，结果开始出现了不一致，接下来我们将数据增加到 10w 个，看看总量差距有多大。



## 3.2、`10w`个数据

### 3.2.1、实例代码

```java
@Test
public void test1000000() {
  Jedis jedis = new Jedis("127.0.0.1", 6379);
  for (int i = 0; i < 100000; i++) {
    jedis.pfadd("codehole", "user" + i);
  }
  long total = jedis.pfcount("codehole");
  log.info("total: {}, actually: {}", total, 100000);
  jedis.close();
}



total: 99725, actually: 100000
```



### 3.2.2、归纳总结

> 差了 `275` 个，按百分比是 `0.275%`，对于上面的 `UV` 统计需求来说，误差率也不算高。         
>
> **然后我们把上面的脚本再跑一边，也就相当于将数据重复加入一边，查看输出，可以发现， `pfcount` 的结果没有任何改变，还是 `99725`，说明它确实具备去重功能。**



# 4、`pfmerge`

> `HyperLogLog` 除了上面的 `pfadd` 和 `pfcount` 之外，还提供了第三个指令 `pfmerge`，用于 将多个 `p`f 计数值累加在一起形成一个新的 `pf` 值。
>
> 比如在网站中我们有两个内容差不多的页面，运营说需要这两个页面的数据进行合并。 其中页面的 `UV` 访问量也需要合并，那这个时候 `pfmerge` 就可以派上用场了。



```shell
127.0.0.1:6379> pfadd h1 user1 user2 user3 user4 user5
(integer) 1
127.0.0.1:6379> pfcount h1
(integer) 5

127.0.0.1:6379> pfadd h2 user4 user5 user6
(integer) 1
127.0.0.1:6379> pfcount h2
(integer) 3
127.0.0.1:6379>


127.0.0.1:6379> pfmerge h3 h1 h2
OK
127.0.0.1:6379> pfcount h3
(integer) 6
127.0.0.1:6379>
```



# 5、`HyperLogLog` 原理   

> `HyperLogLog`，下面简称为`HLL`，它是 `LogLog` 算法的升级版，作用是能够提供不精确的去重计数。存在以下的特点：

1、代码实现较难。    

**2、能够使用极少的内存来统计巨量的数据，在 `Redis` 中实现的 `HyperLogLog`，只需要`12K`内存就能统计`2^64`个数据**。     

3、计数存在一定的误差，误差率整体较低。标准误差为 0.81% 。      

3、误差可以被设置`辅助计算因子`进行降低。



**问题：2^64个数据是多少k呢？**            

答案：取 `Java` 语言来说，一般`long`占用`8`字节，而一字节有`8`位，即：`1 byte` = `8 bit`，即`long`数据类型最大可以表示的数是：`2^63-1`。对应上面的`2^64`个数，     

假设此时有`2^63-1`这么多个数，从 `0 ~ 2^63-1`，按照`long`以及`1k = 1024字节`的规则来计算内存总数，就是：`((2^63-1) * 8/1024)K`，这是很庞大的一个数，存储空间远远超过`12K`。而 `HyperLogLog` 却可以用 `12K` 就能统计完。



## 5.1、注意事项

> **`HyperLogLog` 它需要占据 一定 `12k` 的存储空间(`1k`=`1024B`(字节)，一个英文占一个字节)，所以它不适合统计单个用户相关的数据。** **因为如果你的用户上亿，可以算算，这个空间成本是非常惊人的**。    
>
> 不过你也不必过于担心，因为 `Redis` 对 `HyperLogLog` 的存储进行了优化，
>
> > 1、在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小     
> >
> > 2、仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 `12k` 的空间。



## 5.2、原理分析

### 5.2.1、伯努利试验

> 在认识为什么`HyperLogLog`能够使用极少的内存来统计巨量的数据之前，要先认识下`伯努利试验`。`伯努利试验`是数学`概率论`中的一部分内容，它的典故来源于`抛硬币`。    
>
> > `伯努利试验`：硬币拥有正反两面，一次的上抛至落下，最终出现正反面的概率都是`50%`。假设一直抛硬币，直到它出现正面为止，我们记录为一次完整的试验，中间可能抛了一次就出现了正面，也可能抛了4次才出现正面。无论抛了多少次，只要出现了正面，就记录为一次试验。这个试验就是`伯努利试验`。



1、那么对于多次的`伯努利试验`，假设这个多次为`n`次。就意味着出现了`n`次的正面。      

2、假设每次`伯努利试验`所经历了的抛掷次数为`k`。第一次`伯努利试验`，次数设为`k1`，以此类推，第`n`次对应的是`kn`。      

其中，对于这`n`次`伯努利试验`中，必然会有一个最大的抛掷次数`k`，例如抛了`12`次才出现正面，那么称这个为`k_max`，代表抛了最多的次数。        



`伯努利试验`容易得出有以下结论：     

1、`n` 次伯努利过程的投掷次数都不大于 `k_max`。    

2、`n` 次伯努利过程，至少有一次投掷次数等于 `k_max`       

最终结合极大似然估算的方法，发现在 `n` 和 `k_max` 中存在估算关联：`n = 2^(k_max)` 。这种通过局部信息预估整体数据流特性的方法似乎有些超出我们的基本认知，需要用概率和统计的方法才能推导和验证这种关联关系。      例如下面的样子：

```log
第一次试验: 抛了3次才出现正面，此时 k=3，n=1
第二次试验: 抛了2次才出现正面，此时 k=2，n=2
第三次试验: 抛了6次才出现正面，此时 k=6，n=3
第n 次试验：抛了12次才出现正面，此时我们估算， n = 2^12
```

假设上面例子中实验组数共3组，那么 `k_max` = 6，最终 `n=3`，我们放进估算公式中去，明显： `3 ≠ 2^6` 。也即是说，当试验次数很小的时候，这种估算方法的误差是很大的。



⬤ **在一次伯努利过程中，投掷次数大于`k`的概率为`(1/2)^k`，也就是投了`k`次反面的概率**。       

因此，一次过程中投掷次数不大于`k`的概率为`1−(1/2)^k`           

因此  `n`次伯努利过程所有投掷次数都不大于`k`的概率为 `P( x <= k_max)` = `(1−(1/2)^k_max)n`    



⬤ 进行 `n` 次伯努利过程，至少有一次大于等于 `k_max` 的概率：`P( x  >= k_max)` = `1−(1−1/2^k_max−1)n`       

从上述公式中可得出结论：    

1、当 `n ` 远小于`2^k_max`时，`P (x ≥ k_max)` ≈ `0` ，即所有投掷次数都小于`k`；     

2、当 `n` 远大于`2^k_max`时，`P( X ≤ k_max)` ≈ `0`，即所有投掷次数都大于`k`。      

因此，我们似乎就可以用`2^kmax`的值来粗略估计`n`的大小。 以上结论可以总结为：     

进行了`n`次抛硬币实验，每次分别记录下第一次抛到正面的抛掷次数`k`，那么可以用n次实验中最大的抛掷次数 `k_max ` 来预估实验组数量：`n = 2^k_max`



### 5.2.2、比特串的基数估计

> **在`UV`统计里，我们需要统计一组集合中不重复元素的个数。可以利用哈希算法将集合中的数据转换成 `0` 和 `1` 构成的二进制数串，那么一个二进制串可以类比为一次抛硬币实验，`1 `是抛到正面，`0` 是反面**。              
>
> > 通过`hash`函数，将数据转为`比特串`，例如输入5，便转为：101。为什么要这样转化呢？
> >
> > 是因为要和抛硬币对应上，`比特串`中，0 代表了反面，1 代表了正面，如果一个数据最终被转化了 `10010000`，那么从右往左，从低位往高位看，我们可以认为，首次出现 1 的时候，就是正面。
> >
> > 那么基于上面的估算结论，我们可以通过多次抛硬币实验的最大抛到正面的次数来预估总共进行了多少次实验，同样也就可以根据存入数据中，转化后的出现了 1 的最大的位置 k_max 来估算存入了多少数据。
>
> >   `Redis` 里使用 `MurmurHash2 ` 算法来计算集合数据的哈希值，该算法有很好的均匀性，即使输入集合数据按规律排列，哈希之后仍能保证数据随机分布，因此可以保证每`bit` 出现 `0` 或 `1` 的概率均为 `1/2`，`Redis`中采用的是 `MurmurHash2` 固定 `64` 比特版本，另外该算法的计算速度也较快。



![image-20210430161852845](/Users/healerjean/Desktop/HealerJean/HCode/HealerJean.github.io/blogImages/image-20210430161852845.png)



`HLL` 算法思想的核心就在于通过保留少量的比特信息，来估计或观察消息流。二进制串中从低位开始第一个`1`出现的位置可以理解为抛硬币试验中第一次出现正面的抛掷次数 `k`，那么基于上面的结论，我们可以通过多次抛硬币实验的最大抛到正面的次数来预估总共进行了多少次实验，同样可以通过第一个`1`出现位置的最大值 `kmax`来预估总共有多少个不同的数字（整体基数）。

网上很多博客或文章统计的都是末尾 `0`的个数而非第一个 `1` 出现的位置，这样是有失准确的；关于 `k` 的值，`Redis` 源码中（hllPatLen函数内部）也有备注，





> 



#### 5.2.21、比特串

> 通过`hash`函数，将数据转为`比特串`，例如输入`5`，便转为：`101`。   

**问题：为什么要这样转化呢？**     

是因为要和抛硬币对应上，`比特串`中，`0` 代表了反面，`1` 代表了正面，如果一个数据最终被转化了 `10010000`，那么从右往左，从低位往高位看，我们可以认为，首次出现 `1` 的时候，就是正面。

那么基于上面的估算结论，我们可以通过多次抛硬币实验的最大抛到正面的次数来预估总共进行了多少次实验，同样也就可以根据存入数据中，转化后的出现了`1` 的最大的位置 `k_max` 来估算存入了多少数据。















![ContactAuthor](https://raw.githubusercontent.com/HealerJean/HealerJean.github.io/master/assets/img/artical_bottom.jpg)



<!-- Gitalk 评论 start  -->

<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">

<script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script> 
<div id="gitalk-container"></div>    
 <script type="text/javascript">
    var gitalk = new Gitalk({
		clientID: `1d164cd85549874d0e3a`,
		clientSecret: `527c3d223d1e6608953e835b547061037d140355`,
		repo: `HealerJean.github.io`,
		owner: 'HealerJean',
		admin: ['HealerJean'],
		id: 'm3kz2KQLGNUtVIxb',
    });
    gitalk.render('gitalk-container');
</script> 




<!-- Gitalk end -->



